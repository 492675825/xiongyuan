{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天猫用户重复购买预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_column\",100)\n",
    "pd.set_option(\"expand_frame_repr\",False)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (一)读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1--读取数据\n",
    "test_data=pd.read_csv(r'D:\\文件\\学习\\数据集\\天猫用户复购\\data_format1\\test_format1.csv')\n",
    "train_data=pd.read_csv(r'D:\\文件\\学习\\数据集\\天猫用户复购\\data_format1\\train_format1.csv')\n",
    "user_info=pd.read_csv(r'D:\\文件\\学习\\数据集\\天猫用户复购\\data_format1\\user_info_format1.csv')\n",
    "user_log=pd.read_csv(r'D:\\文件\\学习\\数据集\\天猫用户复购\\data_format1\\user_log_format1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label\n",
       "0    34176         3906      0\n",
       "1    34176          121      0\n",
       "2    34176         4356      1\n",
       "3    34176         2217      0\n",
       "4   230784         4818      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163968</td>\n",
       "      <td>4605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360576</td>\n",
       "      <td>1581</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98688</td>\n",
       "      <td>1964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98688</td>\n",
       "      <td>3645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295296</td>\n",
       "      <td>3361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  prob\n",
       "0   163968         4605   NaN\n",
       "1   360576         1581   NaN\n",
       "2    98688         1964   NaN\n",
       "3    98688         3645   NaN\n",
       "4   295296         3361   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376517</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>234512</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>344532</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30230</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age_range  gender\n",
       "0   376517        6.0     1.0\n",
       "1   234512        5.0     0.0\n",
       "2   344532        5.0     0.0\n",
       "3   186135        5.0     0.0\n",
       "4    30230        5.0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>action_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328862</td>\n",
       "      <td>323294</td>\n",
       "      <td>833</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328862</td>\n",
       "      <td>844400</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328862</td>\n",
       "      <td>575153</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>328862</td>\n",
       "      <td>996875</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328862</td>\n",
       "      <td>1086186</td>\n",
       "      <td>1271</td>\n",
       "      <td>1253</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  cat_id  seller_id  brand_id  time_stamp  action_type\n",
       "0   328862   323294     833       2882    2661.0         829            0\n",
       "1   328862   844400    1271       2882    2661.0         829            0\n",
       "2   328862   575153    1271       2882    2661.0         829            0\n",
       "3   328862   996875    1271       2882    2661.0         829            0\n",
       "4   328862  1086186    1271       1253    1049.0         829            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())\n",
    "display(user_info.head())\n",
    "display(user_log.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260864 entries, 0 to 260863\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype\n",
      "---  ------       --------------   -----\n",
      " 0   user_id      260864 non-null  int64\n",
      " 1   merchant_id  260864 non-null  int64\n",
      " 2   label        260864 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 6.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261477 entries, 0 to 261476\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   user_id      261477 non-null  int64  \n",
      " 1   merchant_id  261477 non-null  int64  \n",
      " 2   prob         0 non-null       float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 6.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424170 entries, 0 to 424169\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    424170 non-null  int64  \n",
      " 1   age_range  421953 non-null  float64\n",
      " 2   gender     417734 non-null  float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.7 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54925330 entries, 0 to 54925329\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   user_id      int64  \n",
      " 1   item_id      int64  \n",
      " 2   cat_id       int64  \n",
      " 3   seller_id    int64  \n",
      " 4   brand_id     float64\n",
      " 5   time_stamp   int64  \n",
      " 6   action_type  int64  \n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 2.9 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.info())\n",
    "display(test_data.info())\n",
    "display(user_info.info())\n",
    "display(user_log.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (二)查看缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005226677982884221"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看user_info中age_range字段缺失比例\n",
    "user_info[\"age_range\"].isnull().sum()/user_info.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#age_range缺失数量\n",
    "user_info[\"age_range\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    111654\n",
       "0.0     92914\n",
       "4.0     79991\n",
       "2.0     52871\n",
       "5.0     40777\n",
       "6.0     35464\n",
       "7.0      6992\n",
       "8.0      1266\n",
       "1.0        24\n",
       "Name: age_range, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看age_range分布\n",
    "user_info[\"age_range\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01517316170403376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看user_info中gender字段确实比例\n",
    "user_info[\"gender\"].isnull().sum()/user_info.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6436"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看gender确实数量\n",
    "user_info[\"gender\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    285638\n",
       "1.0    121670\n",
       "2.0     10426\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看gender分布\n",
    "user_info[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id            0\n",
       "item_id            0\n",
       "cat_id             0\n",
       "seller_id          0\n",
       "brand_id       91015\n",
       "time_stamp         0\n",
       "action_type        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看user_log缺失情况\n",
    "user_log.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>424170.000000</td>\n",
       "      <td>421953.000000</td>\n",
       "      <td>417734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>212085.500000</td>\n",
       "      <td>2.930262</td>\n",
       "      <td>0.341179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>122447.476178</td>\n",
       "      <td>1.942978</td>\n",
       "      <td>0.524112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>106043.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>212085.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>318127.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>424170.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id      age_range         gender\n",
       "count  424170.000000  421953.000000  417734.000000\n",
       "mean   212085.500000       2.930262       0.341179\n",
       "std    122447.476178       1.942978       0.524112\n",
       "min         1.000000       0.000000       0.000000\n",
       "25%    106043.250000       2.000000       0.000000\n",
       "50%    212085.500000       3.000000       0.000000\n",
       "75%    318127.750000       4.000000       1.000000\n",
       "max    424170.000000       8.000000       2.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>action_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.492533e+07</td>\n",
       "      <td>5.492533e+07</td>\n",
       "      <td>5.492533e+07</td>\n",
       "      <td>5.492533e+07</td>\n",
       "      <td>5.483432e+07</td>\n",
       "      <td>5.492533e+07</td>\n",
       "      <td>5.492533e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.121568e+05</td>\n",
       "      <td>5.538613e+05</td>\n",
       "      <td>8.770308e+02</td>\n",
       "      <td>2.470941e+03</td>\n",
       "      <td>4.153348e+03</td>\n",
       "      <td>9.230953e+02</td>\n",
       "      <td>2.854458e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.222872e+05</td>\n",
       "      <td>3.221459e+05</td>\n",
       "      <td>4.486269e+02</td>\n",
       "      <td>1.473310e+03</td>\n",
       "      <td>2.397679e+03</td>\n",
       "      <td>1.954305e+02</td>\n",
       "      <td>8.075806e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.110000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.063360e+05</td>\n",
       "      <td>2.731680e+05</td>\n",
       "      <td>5.550000e+02</td>\n",
       "      <td>1.151000e+03</td>\n",
       "      <td>2.027000e+03</td>\n",
       "      <td>7.300000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.126540e+05</td>\n",
       "      <td>5.555290e+05</td>\n",
       "      <td>8.210000e+02</td>\n",
       "      <td>2.459000e+03</td>\n",
       "      <td>4.065000e+03</td>\n",
       "      <td>1.010000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.177500e+05</td>\n",
       "      <td>8.306890e+05</td>\n",
       "      <td>1.252000e+03</td>\n",
       "      <td>3.760000e+03</td>\n",
       "      <td>6.196000e+03</td>\n",
       "      <td>1.109000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.241700e+05</td>\n",
       "      <td>1.113166e+06</td>\n",
       "      <td>1.671000e+03</td>\n",
       "      <td>4.995000e+03</td>\n",
       "      <td>8.477000e+03</td>\n",
       "      <td>1.112000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id       item_id        cat_id     seller_id      brand_id    time_stamp   action_type\n",
       "count  5.492533e+07  5.492533e+07  5.492533e+07  5.492533e+07  5.483432e+07  5.492533e+07  5.492533e+07\n",
       "mean   2.121568e+05  5.538613e+05  8.770308e+02  2.470941e+03  4.153348e+03  9.230953e+02  2.854458e-01\n",
       "std    1.222872e+05  3.221459e+05  4.486269e+02  1.473310e+03  2.397679e+03  1.954305e+02  8.075806e-01\n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  5.110000e+02  0.000000e+00\n",
       "25%    1.063360e+05  2.731680e+05  5.550000e+02  1.151000e+03  2.027000e+03  7.300000e+02  0.000000e+00\n",
       "50%    2.126540e+05  5.555290e+05  8.210000e+02  2.459000e+03  4.065000e+03  1.010000e+03  0.000000e+00\n",
       "75%    3.177500e+05  8.306890e+05  1.252000e+03  3.760000e+03  6.196000e+03  1.109000e+03  0.000000e+00\n",
       "max    4.241700e+05  1.113166e+06  1.671000e+03  4.995000e+03  8.477000e+03  1.112000e+03  3.000000e+00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_gp=train_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    244912\n",
       "1     15952\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#查看样本不均衡情况并可视化\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(label_gp,autopct=\"%1.1f%%\",explode=[0,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (三)统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label\n",
       "0    34176         3906      0\n",
       "1    34176          121      0\n",
       "2    34176         4356      1\n",
       "3    34176         2217      0\n",
       "4   230784         4818      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看购买次数前5的店铺的ID号\n",
    "train_data_merchant=train_data[\"merchant_id\"].value_counts().head(5) #value_counts会根据结果默认降序排列\n",
    "train_data_merchant=pd.DataFrame(train_data_merchant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>3379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>3254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>2483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      merchant_id\n",
       "4044         3379\n",
       "3828         3254\n",
       "4173         2542\n",
       "1102         2483\n",
       "4976         1925"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看购买次数前五的店铺的复购总次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_4044=train_data[train_data[\"merchant_id\"]==4044]\n",
    "merchant_3828=train_data[train_data[\"merchant_id\"]==3828]\n",
    "merchant_4173=train_data[train_data[\"merchant_id\"]==4173]\n",
    "merchant_1102=train_data[train_data[\"merchant_id\"]==1102]\n",
    "merchant_4976=train_data[train_data[\"merchant_id\"]==4976]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>315264</td>\n",
       "      <td>4044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>153984</td>\n",
       "      <td>4044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>28032</td>\n",
       "      <td>4044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>76929</td>\n",
       "      <td>4044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>280449</td>\n",
       "      <td>4044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259980</th>\n",
       "      <td>893</td>\n",
       "      <td>4976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260343</th>\n",
       "      <td>262526</td>\n",
       "      <td>4976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260349</th>\n",
       "      <td>1406</td>\n",
       "      <td>4976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260737</th>\n",
       "      <td>75647</td>\n",
       "      <td>4976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260823</th>\n",
       "      <td>25727</td>\n",
       "      <td>4976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13583 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id  label\n",
       "101      315264         4044      0\n",
       "279      153984         4044      0\n",
       "305       28032         4044      1\n",
       "565       76929         4044      0\n",
       "612      280449         4044      0\n",
       "...         ...          ...    ...\n",
       "259980      893         4976      0\n",
       "260343   262526         4976      0\n",
       "260349     1406         4976      0\n",
       "260737    75647         4976      0\n",
       "260823    25727         4976      0\n",
       "\n",
       "[13583 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_id=pd.concat([merchant_4044,merchant_3828,merchant_4173,merchant_1102,merchant_4976],axis=0)\n",
    "merchant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>529518675</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>687154793</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>716175866</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>539581960</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>399349634</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id  label\n",
       "merchant_id                  \n",
       "1102         529518675    207\n",
       "3828         687154793    410\n",
       "4044         716175866    209\n",
       "4173         539581960    173\n",
       "4976         399349634    113"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_id_groupby=merchant_id.groupby(\"merchant_id\").sum()\n",
    "merchant_id_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#查看销量前5的商户的复购数量\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.bar(x=range(1,6),height=train_data_merchant[\"merchant_id\"],tick_label=train_data_merchant.index,label=\"count\")\n",
    "plt.bar(x=range(1,6),height=merchant_id_groupby[\"label\"],tick_label=merchant_id_groupby.index,label=\"buy again\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index              128\n",
       "user_id        2086912\n",
       "merchant_id    2086912\n",
       "label          2086912\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （二）特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import gc \n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、数据内存压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    #定义起始内存显示\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #定义一个数据类型的列表\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        #定义col_type接受数据集各个字段的数据类型\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            #显示字段中单个数据占用的最小字节\n",
    "            c_min = df[col].min()\n",
    "            #显示字段中单个数据占用的最大字节\n",
    "            c_max = df[col].max()\n",
    "            #截取数据类型的前三位数\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                #当前字段占用的最小字节数量和最大字节数量在int8类型的范围内，则将当前字段的数据类型转换成int8\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                #当前字段占用的最小字节数量和最大字节数量在float16类型的范围内，则将当前字段的数据类型转换成float16\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    #定义结束时的内存显示               \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1.74 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage after optimization is: 3.49 MB\n",
      "Decreased by 41.7%\n",
      "Memory usage after optimization is: 3.24 MB\n",
      "Decreased by 66.7%\n",
      "Memory usage after optimization is: 890.48 MB\n",
      "Decreased by 69.6%\n"
     ]
    }
   ],
   "source": [
    "#调用内存压缩函数\n",
    "train_data=reduce_mem_usage(train_data)\n",
    "test_data=reduce_mem_usage(test_data)\n",
    "user_info=reduce_mem_usage(user_info)\n",
    "user_log=reduce_mem_usage(user_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5007"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进⾏内存回收并显示回收的数量\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、合并用户数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并train_data,test_data,user_info三个表\n",
    "all_data=train_data.append(test_data)\n",
    "all_data=all_data.merge(user_info,on=[\"user_id\"],how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、用户行为日志按时间排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>action_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23288890</th>\n",
       "      <td>1</td>\n",
       "      <td>181459</td>\n",
       "      <td>276</td>\n",
       "      <td>2245</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23288891</th>\n",
       "      <td>1</td>\n",
       "      <td>779078</td>\n",
       "      <td>276</td>\n",
       "      <td>2245</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23288892</th>\n",
       "      <td>1</td>\n",
       "      <td>779078</td>\n",
       "      <td>276</td>\n",
       "      <td>2245</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23288893</th>\n",
       "      <td>1</td>\n",
       "      <td>452837</td>\n",
       "      <td>276</td>\n",
       "      <td>2245</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23288894</th>\n",
       "      <td>1</td>\n",
       "      <td>543397</td>\n",
       "      <td>276</td>\n",
       "      <td>2245</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id  cat_id  seller_id  brand_id  time_stamp  action_type\n",
       "23288890        1   181459     276       2245    4752.0        1009            0\n",
       "23288891        1   779078     276       2245    4752.0        1009            0\n",
       "23288892        1   779078     276       2245    4752.0        1009            0\n",
       "23288893        1   452837     276       2245    4752.0        1009            0\n",
       "23288894        1   543397     276       2245    4752.0        1009            0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log=user_log.sort_values([\"user_id\",\"time_stamp\"])\n",
    "user_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、合并user_log表中相同user_id的各个字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_join_func=lambda x:\" \".join([str(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义groupby的聚合方法\n",
    "agg_dict={\n",
    "    \"item_id\":list_join_func,\n",
    "    \"cat_id\":list_join_func,\n",
    "    \"seller_id\":list_join_func,\n",
    "    \"brand_id\":list_join_func,\n",
    "    \"time_stamp\":list_join_func,\n",
    "    \"action_type\":list_join_func\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义字段名称重命名\n",
    "rename_dict={\n",
    "    \"item_id\":\"item_path\",\n",
    "    \"cat_id\":\"cat_path\",\n",
    "    \"seller_id\":\"seller_path\",\n",
    "    \"brand_id\":\"brand_path\",\n",
    "    \"time_stamp\":\"time_stamp_path\",\n",
    "    \"action_type\":\"action_type_path\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>181459 779078 779078 452837 543397 504149 5041...</td>\n",
       "      <td>276 276 276 276 276 1023 1023 1023 1023 1252 1...</td>\n",
       "      <td>2245 2245 2245 2245 2245 925 925 925 925 4026 ...</td>\n",
       "      <td>4752.0 4752.0 4752.0 4752.0 4752.0 7400.0 7400...</td>\n",
       "      <td>1009 1009 1009 1009 1009 1011 1011 1011 1011 1...</td>\n",
       "      <td>0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>348983 749563 239288 751744 239288 714176 1972...</td>\n",
       "      <td>177 177 602 602 602 1213 602 602 602 1213 1213...</td>\n",
       "      <td>2223 2223 420 420 420 420 420 420 420 420 420 ...</td>\n",
       "      <td>3272.0 3272.0 4952.0 4952.0 4952.0 4058.0 4952...</td>\n",
       "      <td>527 527 626 626 626 626 626 626 626 626 626 62...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>895754 895754 182882 182882 985337 175397 9463...</td>\n",
       "      <td>1505 1505 1271 1271 1271 662 1134 1134 1134 45...</td>\n",
       "      <td>795 795 2123 2123 4925 1102 4461 4461 4461 474...</td>\n",
       "      <td>3608.0 3608.0 4796.0 4796.0 8004.0 1214.0 905....</td>\n",
       "      <td>516 516 627 627 627 727 819 819 820 906 906 90...</td>\n",
       "      <td>2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>836727 243874 185489 95474 30073 790055 790055...</td>\n",
       "      <td>612 1577 1505 1505 1505 1505 1505 1505 1505 15...</td>\n",
       "      <td>1221 1221 1221 1221 1221 1221 1221 1221 1221 1...</td>\n",
       "      <td>7736.0 7736.0 7736.0 7736.0 7736.0 7736.0 7736...</td>\n",
       "      <td>527 527 527 527 527 527 527 527 527 527 527 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>511956 728354 568450 754044 1011255 741215 362...</td>\n",
       "      <td>302 351 812 1213 142 464 1028 35 1213 351 142 ...</td>\n",
       "      <td>3098 3215 641 3736 1483 176 4848 641 3736 4547...</td>\n",
       "      <td>5544.0 5480.0 4264.0 3124.0 4640.0 6664.0 2804...</td>\n",
       "      <td>519 520 520 520 520 520 520 520 520 520 520 52...</td>\n",
       "      <td>3 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path\n",
       "0        1  181459 779078 779078 452837 543397 504149 5041...  276 276 276 276 276 1023 1023 1023 1023 1252 1...  2245 2245 2245 2245 2245 925 925 925 925 4026 ...  4752.0 4752.0 4752.0 4752.0 4752.0 7400.0 7400...  1009 1009 1009 1009 1009 1011 1011 1011 1011 1...  0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 ...\n",
       "1        2  348983 749563 239288 751744 239288 714176 1972...  177 177 602 602 602 1213 602 602 602 1213 1213...  2223 2223 420 420 420 420 420 420 420 420 420 ...  3272.0 3272.0 4952.0 4952.0 4952.0 4058.0 4952...  527 527 626 626 626 626 626 626 626 626 626 62...  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 ...\n",
       "2        3  895754 895754 182882 182882 985337 175397 9463...  1505 1505 1271 1271 1271 662 1134 1134 1134 45...  795 795 2123 2123 4925 1102 4461 4461 4461 474...  3608.0 3608.0 4796.0 4796.0 8004.0 1214.0 905....  516 516 627 627 627 727 819 819 820 906 906 90...  2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "3        4  836727 243874 185489 95474 30073 790055 790055...  612 1577 1505 1505 1505 1505 1505 1505 1505 15...  1221 1221 1221 1221 1221 1221 1221 1221 1221 1...  7736.0 7736.0 7736.0 7736.0 7736.0 7736.0 7736...  527 527 527 527 527 527 527 527 527 527 527 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "4        5  511956 728354 568450 754044 1011255 741215 362...  302 351 812 1213 142 464 1028 35 1213 351 142 ...  3098 3215 641 3736 1483 176 4848 641 3736 4547...  5544.0 5480.0 4264.0 3124.0 4640.0 6664.0 2804...  519 520 520 520 520 520 520 520 520 520 520 52...  3 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log_path=user_log.groupby(\"user_id\").agg(agg_dict).reset_index().rename(columns=rename_dict)\n",
    "\n",
    "user_log_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>181459 779078 779078 452837 543397 504149 5041...</td>\n",
       "      <td>276 276 276 276 276 1023 1023 1023 1023 1252 1...</td>\n",
       "      <td>2245 2245 2245 2245 2245 925 925 925 925 4026 ...</td>\n",
       "      <td>4752.0 4752.0 4752.0 4752.0 4752.0 7400.0 7400...</td>\n",
       "      <td>1009 1009 1009 1009 1009 1011 1011 1011 1011 1...</td>\n",
       "      <td>0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>348983 749563 239288 751744 239288 714176 1972...</td>\n",
       "      <td>177 177 602 602 602 1213 602 602 602 1213 1213...</td>\n",
       "      <td>2223 2223 420 420 420 420 420 420 420 420 420 ...</td>\n",
       "      <td>3272.0 3272.0 4952.0 4952.0 4952.0 4058.0 4952...</td>\n",
       "      <td>527 527 626 626 626 626 626 626 626 626 626 62...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>895754 895754 182882 182882 985337 175397 9463...</td>\n",
       "      <td>1505 1505 1271 1271 1271 662 1134 1134 1134 45...</td>\n",
       "      <td>795 795 2123 2123 4925 1102 4461 4461 4461 474...</td>\n",
       "      <td>3608.0 3608.0 4796.0 4796.0 8004.0 1214.0 905....</td>\n",
       "      <td>516 516 627 627 627 727 819 819 820 906 906 90...</td>\n",
       "      <td>2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>836727 243874 185489 95474 30073 790055 790055...</td>\n",
       "      <td>612 1577 1505 1505 1505 1505 1505 1505 1505 15...</td>\n",
       "      <td>1221 1221 1221 1221 1221 1221 1221 1221 1221 1...</td>\n",
       "      <td>7736.0 7736.0 7736.0 7736.0 7736.0 7736.0 7736...</td>\n",
       "      <td>527 527 527 527 527 527 527 527 527 527 527 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>511956 728354 568450 754044 1011255 741215 362...</td>\n",
       "      <td>302 351 812 1213 142 464 1028 35 1213 351 142 ...</td>\n",
       "      <td>3098 3215 641 3736 1483 176 4848 641 3736 4547...</td>\n",
       "      <td>5544.0 5480.0 4264.0 3124.0 4640.0 6664.0 2804...</td>\n",
       "      <td>519 520 520 520 520 520 520 520 520 520 520 52...</td>\n",
       "      <td>3 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path\n",
       "0        1  181459 779078 779078 452837 543397 504149 5041...  276 276 276 276 276 1023 1023 1023 1023 1252 1...  2245 2245 2245 2245 2245 925 925 925 925 4026 ...  4752.0 4752.0 4752.0 4752.0 4752.0 7400.0 7400...  1009 1009 1009 1009 1009 1011 1011 1011 1011 1...  0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 ...\n",
       "1        2  348983 749563 239288 751744 239288 714176 1972...  177 177 602 602 602 1213 602 602 602 1213 1213...  2223 2223 420 420 420 420 420 420 420 420 420 ...  3272.0 3272.0 4952.0 4952.0 4952.0 4058.0 4952...  527 527 626 626 626 626 626 626 626 626 626 62...  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 ...\n",
       "2        3  895754 895754 182882 182882 985337 175397 9463...  1505 1505 1271 1271 1271 662 1134 1134 1134 45...  795 795 2123 2123 4925 1102 4461 4461 4461 474...  3608.0 3608.0 4796.0 4796.0 8004.0 1214.0 905....  516 516 627 627 627 727 819 819 820 906 906 90...  2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "3        4  836727 243874 185489 95474 30073 790055 790055...  612 1577 1505 1505 1505 1505 1505 1505 1505 15...  1221 1221 1221 1221 1221 1221 1221 1221 1221 1...  7736.0 7736.0 7736.0 7736.0 7736.0 7736.0 7736...  527 527 527 527 527 527 527 527 527 527 527 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "4        5  511956 728354 568450 754044 1011255 741215 362...  302 351 812 1213 142 464 1028 35 1213 351 142 ...  3098 3215 641 3736 1483 176 4848 641 3736 4547...  5544.0 5480.0 4264.0 3124.0 4640.0 6664.0 2804...  519 520 520 520 520 520 520 520 520 520 520 52...  3 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#合并user_log表和all_data表\n",
    "all_data_path=all_data.merge(user_log_path,on=\"user_id\")\n",
    "all_data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除内存中的user_log表并回收内存\n",
    "# del user_log\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、定义数据统计函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)定义统计函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计数据的总数\n",
    "def cnt_(x):\n",
    "    try:\n",
    "        return len(x.split(\" \"))\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计唯一数据总数\n",
    "def nunique_(x):\n",
    "    try:\n",
    "        return len(set(x.split(\" \")))\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计数据最大值\n",
    "def max_(x):\n",
    "    try:\n",
    "        return np.max([int(i) for i in x.split(\" \")])\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计数据最小值\n",
    "def min_(x):\n",
    "    try:\n",
    "        return np.min([int(i) for i in x.split(\" \")])\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计数据的标准差\n",
    "def std_(x):\n",
    "    try:\n",
    "        return np.std([float(i) for i in x.split(\" \")])\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计数据中top N的数据\n",
    "def most_n(x,n):\n",
    "    try:\n",
    "        return Counter(x.split(\" \")).most_common(n)[n-1][0]\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计数据中top N数据的总数\n",
    "def most_n_cnt(x,n):\n",
    "    try:\n",
    "        return Counter(x.split(\" \")).most_common(n)[n-1][1]\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)调用统计函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用统计函数\n",
    "def user_cnt(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(cnt_)\n",
    "    return df_data\n",
    "\n",
    "def user_nunique(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(nunique_)\n",
    "    return df_data\n",
    "    \n",
    "def user_max(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(max_)\n",
    "    return df_data\n",
    "\n",
    "def user_min(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(min_)\n",
    "    return df_data\n",
    "    \n",
    "def user_std(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(std_)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n_cnt(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n_cnt(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、提取商铺的基本统计特征(特征创造)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前2000行作为测试样本(学习时使用，避免全量数据耗时过多)\n",
    "all_data_test=all_data_path.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#总次数\n",
    "all_data_test=user_cnt(all_data_test,\"seller_path\",\"user_cnt\")\n",
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt  seller_nunique\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54              20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#不同店铺个数\n",
    "all_data_test=user_nunique(all_data_test,\"seller_path\",\"seller_nunique\")\n",
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>action_type_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt  seller_nunique  cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  action_type_nunique\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54              20           17             19            31                  16                    2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同品类个数\n",
    "all_data_test = user_nunique(all_data_test,  'cat_path', 'cat_nunique')\n",
    "# 不同品牌个数\n",
    "all_data_test = user_nunique(all_data_test,  'brand_path', 'brand_nunique')\n",
    "# 不同商品个数\n",
    "all_data_test = user_nunique(all_data_test,  'item_path', 'item_nunique')\n",
    "# 活跃天数\n",
    "all_data_test = user_nunique(all_data_test,  'time_stamp_path', 'time_stamp_nunique')\n",
    "# 不用行为种数\n",
    "all_data_test = user_nunique(all_data_test,  'action_type_path', 'action_type_nunique')\n",
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>action_type_nunique</th>\n",
       "      <th>time_stamp_max</th>\n",
       "      <th>time_stamp_min</th>\n",
       "      <th>time_stamp_std</th>\n",
       "      <th>time_stamp_range</th>\n",
       "      <th>seller_most_1</th>\n",
       "      <th>cat_most_1</th>\n",
       "      <th>brand_most_1</th>\n",
       "      <th>action_type_1</th>\n",
       "      <th>seller_most_1_cnt</th>\n",
       "      <th>cat_most_1_cnt</th>\n",
       "      <th>brand_most_1_cnt</th>\n",
       "      <th>action_type_1_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671791</td>\n",
       "      <td>2</td>\n",
       "      <td>3556</td>\n",
       "      <td>407</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt  seller_nunique  cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  action_type_nunique  time_stamp_max  time_stamp_min  time_stamp_std  time_stamp_range seller_most_1 cat_most_1 brand_most_1 action_type_1  seller_most_1_cnt  cat_most_1_cnt  brand_most_1_cnt  action_type_1_cnt\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54              20           17             19            31                  16                    2               2               0        0.671791                 2          3556        407       1236.0             0                 10               9                10                 47"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最晚时间\n",
    "all_data_test = user_max(all_data_test,  'action_type_path', 'time_stamp_max')\n",
    "# 最早时间\n",
    "all_data_test = user_min(all_data_test,  'action_type_path', 'time_stamp_min')\n",
    "# 活跃天数方差\n",
    "all_data_test = user_std(all_data_test,  'action_type_path', 'time_stamp_std')\n",
    "# 最早和最晚相差天数\n",
    "all_data_test['time_stamp_range'] = all_data_test['time_stamp_max'] - all_data_test['time_stamp_min']\n",
    "# 用户最喜欢的店铺\n",
    "all_data_test = user_most_n(all_data_test, 'seller_path', 'seller_most_1', n=1)\n",
    "# 最喜欢的类目\n",
    "all_data_test = user_most_n(all_data_test, 'cat_path', 'cat_most_1', n=1)\n",
    "# 最喜欢的品牌\n",
    "all_data_test = user_most_n(all_data_test, 'brand_path', 'brand_most_1', n=1)\n",
    "# 最常见的行为动作\n",
    "all_data_test = user_most_n(all_data_test, 'action_type_path', 'action_type_1', n=1)\n",
    "# 用户最喜欢的店铺 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'seller_path', 'seller_most_1_cnt', n=1)\n",
    "# 最喜欢的类目 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'cat_path', 'cat_most_1_cnt', n=1)\n",
    "# 最喜欢的品牌 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'brand_path', 'brand_most_1_cnt', n=1)\n",
    "# 最常见的行为动作 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'action_type_path', 'action_type_1_cnt', n=1)\n",
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、分开统计用户的点击、加购、购买、收藏特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同行为的业务函数定义\n",
    "def col_cnt_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type != None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "            data_out.append(data_txt)\n",
    "\n",
    "        return len(data_out)  \n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def col_nuique_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type != None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "            data_out.append(data_txt)\n",
    "\n",
    "        return len(set(data_out))\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def user_col_cnt(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_cnt_(x, columns_list, action_type), axis=1)\n",
    "    return df_data\n",
    "\n",
    "def user_col_nunique(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_nuique_(x, columns_list, action_type), axis=1)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>action_type_nunique</th>\n",
       "      <th>time_stamp_max</th>\n",
       "      <th>time_stamp_min</th>\n",
       "      <th>time_stamp_std</th>\n",
       "      <th>time_stamp_range</th>\n",
       "      <th>seller_most_1</th>\n",
       "      <th>cat_most_1</th>\n",
       "      <th>brand_most_1</th>\n",
       "      <th>action_type_1</th>\n",
       "      <th>seller_most_1_cnt</th>\n",
       "      <th>cat_most_1_cnt</th>\n",
       "      <th>brand_most_1_cnt</th>\n",
       "      <th>action_type_1_cnt</th>\n",
       "      <th>user_cnt_0</th>\n",
       "      <th>user_cnt_1</th>\n",
       "      <th>user_cnt_2</th>\n",
       "      <th>user_cnt_3</th>\n",
       "      <th>seller_nunique_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671791</td>\n",
       "      <td>2</td>\n",
       "      <td>3556</td>\n",
       "      <td>407</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt  seller_nunique  cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  action_type_nunique  time_stamp_max  time_stamp_min  time_stamp_std  time_stamp_range seller_most_1 cat_most_1 brand_most_1 action_type_1  seller_most_1_cnt  cat_most_1_cnt  brand_most_1_cnt  action_type_1_cnt  user_cnt_0  user_cnt_1  user_cnt_2  user_cnt_3  seller_nunique_0\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               107\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               107\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               107\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               107\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54              20           17             19            31                  16                    2               2               0        0.671791                 2          3556        407       1236.0             0                 10               9                10                 47          54          54          54          54                21"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 点击次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '0', 'user_cnt_0')\n",
    "# 加购次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '1', 'user_cnt_1')\n",
    "# 购买次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '2', 'user_cnt_2')\n",
    "# 收藏次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '3', 'user_cnt_3')\n",
    "# 不同店铺个数\n",
    "all_data_test = user_col_nunique(all_data_test,  ['seller_path'], '0', 'seller_nunique_0')\n",
    "\n",
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、组合特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点击次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path', 'item_path'], '0', 'user_cnt_0')\n",
    "\n",
    "# 不同店铺个数\n",
    "all_data_test = user_col_nunique(all_data_test,  ['seller_path', 'item_path'], '0', 'seller_nunique_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>action_type_nunique</th>\n",
       "      <th>time_stamp_max</th>\n",
       "      <th>time_stamp_min</th>\n",
       "      <th>time_stamp_std</th>\n",
       "      <th>time_stamp_range</th>\n",
       "      <th>seller_most_1</th>\n",
       "      <th>cat_most_1</th>\n",
       "      <th>brand_most_1</th>\n",
       "      <th>action_type_1</th>\n",
       "      <th>seller_most_1_cnt</th>\n",
       "      <th>cat_most_1_cnt</th>\n",
       "      <th>brand_most_1_cnt</th>\n",
       "      <th>action_type_1_cnt</th>\n",
       "      <th>user_cnt_0</th>\n",
       "      <th>user_cnt_1</th>\n",
       "      <th>user_cnt_2</th>\n",
       "      <th>user_cnt_3</th>\n",
       "      <th>seller_nunique_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671791</td>\n",
       "      <td>2</td>\n",
       "      <td>3556</td>\n",
       "      <td>407</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt  seller_nunique  cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  action_type_nunique  time_stamp_max  time_stamp_min  time_stamp_std  time_stamp_range seller_most_1 cat_most_1 brand_most_1 action_type_1  seller_most_1_cnt  cat_most_1_cnt  brand_most_1_cnt  action_type_1_cnt  user_cnt_0  user_cnt_1  user_cnt_2  user_cnt_3  seller_nunique_0\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54              20           17             19            31                  16                    2               2               0        0.671791                 2          3556        407       1236.0             0                 10               9                10                 47          54          54          54          54                31"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、查看提取的特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'merchant_id', 'label', 'prob', 'age_range', 'gender',\n",
       "       'item_path', 'cat_path', 'seller_path', 'brand_path', 'time_stamp_path',\n",
       "       'action_type_path', 'user_cnt', 'seller_nunique', 'cat_nunique',\n",
       "       'brand_nunique', 'item_nunique', 'time_stamp_nunique',\n",
       "       'action_type_nunique', 'time_stamp_max', 'time_stamp_min',\n",
       "       'time_stamp_std', 'time_stamp_range', 'seller_most_1', 'cat_most_1',\n",
       "       'brand_most_1', 'action_type_1', 'seller_most_1_cnt', 'cat_most_1_cnt',\n",
       "       'brand_most_1_cnt', 'action_type_1_cnt', 'user_cnt_0', 'user_cnt_1',\n",
       "       'user_cnt_2', 'user_cnt_3', 'seller_nunique_0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'merchant_id',\n",
       " 'label',\n",
       " 'prob',\n",
       " 'age_range',\n",
       " 'gender',\n",
       " 'item_path',\n",
       " 'cat_path',\n",
       " 'seller_path',\n",
       " 'brand_path',\n",
       " 'time_stamp_path',\n",
       " 'action_type_path',\n",
       " 'user_cnt',\n",
       " 'seller_nunique',\n",
       " 'cat_nunique',\n",
       " 'brand_nunique',\n",
       " 'item_nunique',\n",
       " 'time_stamp_nunique',\n",
       " 'action_type_nunique',\n",
       " 'time_stamp_max',\n",
       " 'time_stamp_min',\n",
       " 'time_stamp_std',\n",
       " 'time_stamp_range',\n",
       " 'seller_most_1',\n",
       " 'cat_most_1',\n",
       " 'brand_most_1',\n",
       " 'action_type_1',\n",
       " 'seller_most_1_cnt',\n",
       " 'cat_most_1_cnt',\n",
       " 'brand_most_1_cnt',\n",
       " 'action_type_1_cnt',\n",
       " 'user_cnt_0',\n",
       " 'user_cnt_1',\n",
       " 'user_cnt_2',\n",
       " 'user_cnt_3',\n",
       " 'seller_nunique_0']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_data_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9、利用countvector,TF-IDF提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取特征\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from scipy import sparse\n",
    "# cntVec = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 1), max_features=100)\n",
    "tfidfVec = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 1), max_features=100)\n",
    "\n",
    "\n",
    "# columns_list = ['seller_path', 'cat_path', 'brand_path', 'action_type_path', 'item_path', 'time_stamp_path']\n",
    "columns_list = ['seller_path']\n",
    "for i, col in enumerate(columns_list):\n",
    "    all_data_test[col] = all_data_test[col].astype(str)\n",
    "    tfidfVec.fit(all_data_test[col])\n",
    "    data_ = tfidfVec.transform(all_data_test[col])\n",
    "    if i == 0:\n",
    "        data_cat = data_\n",
    "    else:\n",
    "        data_cat = sparse.hstack((data_cat, data_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征重命名，特征合并\n",
    "df_tfidf = pd.DataFrame(data_cat.toarray())\n",
    "df_tfidf.columns = ['tfidf_' + str(i) for i in df_tfidf.columns]\n",
    "all_data_test = pd.concat([all_data_test, df_tfidf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>seller_nunique</th>\n",
       "      <th>cat_nunique</th>\n",
       "      <th>brand_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>time_stamp_nunique</th>\n",
       "      <th>action_type_nunique</th>\n",
       "      <th>time_stamp_max</th>\n",
       "      <th>time_stamp_min</th>\n",
       "      <th>time_stamp_std</th>\n",
       "      <th>time_stamp_range</th>\n",
       "      <th>seller_most_1</th>\n",
       "      <th>cat_most_1</th>\n",
       "      <th>brand_most_1</th>\n",
       "      <th>action_type_1</th>\n",
       "      <th>seller_most_1_cnt</th>\n",
       "      <th>cat_most_1_cnt</th>\n",
       "      <th>brand_most_1_cnt</th>\n",
       "      <th>action_type_1_cnt</th>\n",
       "      <th>user_cnt_0</th>\n",
       "      <th>user_cnt_1</th>\n",
       "      <th>user_cnt_2</th>\n",
       "      <th>user_cnt_3</th>\n",
       "      <th>seller_nunique_0</th>\n",
       "      <th>tfidf_0</th>\n",
       "      <th>tfidf_1</th>\n",
       "      <th>tfidf_2</th>\n",
       "      <th>tfidf_3</th>\n",
       "      <th>tfidf_4</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_8</th>\n",
       "      <th>tfidf_9</th>\n",
       "      <th>tfidf_10</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_12</th>\n",
       "      <th>tfidf_13</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_50</th>\n",
       "      <th>tfidf_51</th>\n",
       "      <th>tfidf_52</th>\n",
       "      <th>tfidf_53</th>\n",
       "      <th>tfidf_54</th>\n",
       "      <th>tfidf_55</th>\n",
       "      <th>tfidf_56</th>\n",
       "      <th>tfidf_57</th>\n",
       "      <th>tfidf_58</th>\n",
       "      <th>tfidf_59</th>\n",
       "      <th>tfidf_60</th>\n",
       "      <th>tfidf_61</th>\n",
       "      <th>tfidf_62</th>\n",
       "      <th>tfidf_63</th>\n",
       "      <th>tfidf_64</th>\n",
       "      <th>tfidf_65</th>\n",
       "      <th>tfidf_66</th>\n",
       "      <th>tfidf_67</th>\n",
       "      <th>tfidf_68</th>\n",
       "      <th>tfidf_69</th>\n",
       "      <th>tfidf_70</th>\n",
       "      <th>tfidf_71</th>\n",
       "      <th>tfidf_72</th>\n",
       "      <th>tfidf_73</th>\n",
       "      <th>tfidf_74</th>\n",
       "      <th>tfidf_75</th>\n",
       "      <th>tfidf_76</th>\n",
       "      <th>tfidf_77</th>\n",
       "      <th>tfidf_78</th>\n",
       "      <th>tfidf_79</th>\n",
       "      <th>tfidf_80</th>\n",
       "      <th>tfidf_81</th>\n",
       "      <th>tfidf_82</th>\n",
       "      <th>tfidf_83</th>\n",
       "      <th>tfidf_84</th>\n",
       "      <th>tfidf_85</th>\n",
       "      <th>tfidf_86</th>\n",
       "      <th>tfidf_87</th>\n",
       "      <th>tfidf_88</th>\n",
       "      <th>tfidf_89</th>\n",
       "      <th>tfidf_90</th>\n",
       "      <th>tfidf_91</th>\n",
       "      <th>tfidf_92</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>tfidf_94</th>\n",
       "      <th>tfidf_95</th>\n",
       "      <th>tfidf_96</th>\n",
       "      <th>tfidf_97</th>\n",
       "      <th>tfidf_98</th>\n",
       "      <th>tfidf_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.186124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173224</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199454</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234063</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.186124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173224</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199454</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234063</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.186124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173224</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199454</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234063</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "      <td>451</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>3</td>\n",
       "      <td>331</td>\n",
       "      <td>662</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>98</td>\n",
       "      <td>70</td>\n",
       "      <td>410</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.186124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173224</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199454</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234063</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671791</td>\n",
       "      <td>2</td>\n",
       "      <td>3556</td>\n",
       "      <td>407</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.860915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender                                          item_path                                           cat_path                                        seller_path                                         brand_path                                    time_stamp_path                                   action_type_path  user_cnt  seller_nunique  cat_nunique  brand_nunique  item_nunique  time_stamp_nunique  action_type_nunique  time_stamp_max  time_stamp_min  time_stamp_std  time_stamp_range seller_most_1 cat_most_1 brand_most_1 action_type_1  seller_most_1_cnt  cat_most_1_cnt  brand_most_1_cnt  action_type_1_cnt  user_cnt_0  user_cnt_1  user_cnt_2  user_cnt_3  seller_nunique_0  tfidf_0  tfidf_1   tfidf_2   tfidf_3  tfidf_4   tfidf_5   tfidf_6  tfidf_7  tfidf_8   tfidf_9  tfidf_10  tfidf_11  tfidf_12  tfidf_13  ...  tfidf_50  tfidf_51  tfidf_52  tfidf_53  tfidf_54  tfidf_55  tfidf_56  tfidf_57  tfidf_58  tfidf_59  tfidf_60  tfidf_61  tfidf_62  tfidf_63  tfidf_64  tfidf_65  tfidf_66  tfidf_67  tfidf_68  tfidf_69  tfidf_70  tfidf_71  tfidf_72  tfidf_73  tfidf_74  tfidf_75  tfidf_76  tfidf_77  tfidf_78  tfidf_79  tfidf_80  tfidf_81  tfidf_82  tfidf_83  tfidf_84  tfidf_85  tfidf_86  tfidf_87  tfidf_88  tfidf_89  tfidf_90  tfidf_91  tfidf_92  tfidf_93  tfidf_94  tfidf_95  tfidf_96  tfidf_97  tfidf_98  tfidf_99\n",
       "0    34176         3906    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251      0.0      0.0  0.009531  0.186124      0.0  0.173224  0.036434      0.0      0.0  0.012205       0.0       0.0       0.0       0.0  ...  0.865332       0.0       0.0       0.0  0.010166       0.0       0.0       0.0  0.011752       0.0       0.0       0.0  0.199454  0.057178       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.234063  0.026766  0.011404  0.000000  0.031593       0.0       0.0  0.059432       0.0       0.0  0.010496       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.012666  0.011178       0.0       0.0       0.0       0.0  0.012925       0.0\n",
       "1    34176          121    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251      0.0      0.0  0.009531  0.186124      0.0  0.173224  0.036434      0.0      0.0  0.012205       0.0       0.0       0.0       0.0  ...  0.865332       0.0       0.0       0.0  0.010166       0.0       0.0       0.0  0.011752       0.0       0.0       0.0  0.199454  0.057178       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.234063  0.026766  0.011404  0.000000  0.031593       0.0       0.0  0.059432       0.0       0.0  0.010496       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.012666  0.011178       0.0       0.0       0.0       0.0  0.012925       0.0\n",
       "2    34176         4356    1.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251      0.0      0.0  0.009531  0.186124      0.0  0.173224  0.036434      0.0      0.0  0.012205       0.0       0.0       0.0       0.0  ...  0.865332       0.0       0.0       0.0  0.010166       0.0       0.0       0.0  0.011752       0.0       0.0       0.0  0.199454  0.057178       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.234063  0.026766  0.011404  0.000000  0.031593       0.0       0.0  0.059432       0.0       0.0  0.010496       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.012666  0.011178       0.0       0.0       0.0       0.0  0.012925       0.0\n",
       "3    34176         2217    0.0   NaN        6.0     0.0  581818 879005 581818 581818 1011673 52343 2773...  1505 662 1505 1505 1505 662 1095 1505 662 1095...  416 3606 416 416 416 3760 3606 416 1926 3004 4...  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...  521 521 521 521 521 521 521 521 521 521 521 52...  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...       451             109           45            106           256                  47                    3               3               0        0.634270                 3           331        662       4094.0             0                 70              98                70                410         451         451         451         451               251      0.0      0.0  0.009531  0.186124      0.0  0.173224  0.036434      0.0      0.0  0.012205       0.0       0.0       0.0       0.0  ...  0.865332       0.0       0.0       0.0  0.010166       0.0       0.0       0.0  0.011752       0.0       0.0       0.0  0.199454  0.057178       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.234063  0.026766  0.011404  0.000000  0.031593       0.0       0.0  0.059432       0.0       0.0  0.010496       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.012666  0.011178       0.0       0.0       0.0       0.0  0.012925       0.0\n",
       "4   230784         4818    0.0   NaN        0.0     0.0  191923 191923 191923 191923 964906 229470 2294...  1023 1023 1023 1023 662 664 664 1544 664 662 6...  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...  601 601 601 601 614 614 614 614 614 614 618 61...  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...        54              20           17             19            31                  16                    2               2               0        0.671791                 2          3556        407       1236.0             0                 10               9                10                 47          54          54          54          54                31      0.0      0.0  0.000000  0.000000      0.0  0.000000  0.000000      0.0      0.0  0.000000       0.0       0.0       0.0       0.0  ...  0.000000       0.0       0.0       0.0  0.000000       0.0       0.0       0.0  0.000000       0.0       0.0       0.0  0.000000  0.000000       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.000000  0.000000  0.000000  0.860915  0.000000       0.0       0.0  0.000000       0.0       0.0  0.000000       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  0.000000  0.000000       0.0       0.0       0.0       0.0  0.000000       0.0\n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10、embeeding特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Train Word2Vec model\n",
    "\n",
    "model = gensim.models.Word2Vec(all_data_test['seller_path'].apply(lambda x: x.split(' ')), size=100, window=5, min_count=5, workers=4)\n",
    "# model.save(\"product2vec.model\")\n",
    "# model = gensim.models.Word2Vec.load(\"product2vec.model\")\n",
    "\n",
    "def mean_w2v_(x, model, size=100):\n",
    "    try:\n",
    "        i = 0\n",
    "        for word in x.split(' '):\n",
    "            if word in model.wv.vocab:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    vec = np.zeros(size)\n",
    "                vec += model.wv[word]\n",
    "        return vec / i \n",
    "    except:\n",
    "        return  np.zeros(size)\n",
    "\n",
    "\n",
    "def get_mean_w2v(df_data, columns, model, size):\n",
    "    data_array = []\n",
    "    for index, row in df_data.iterrows():\n",
    "        w2v = mean_w2v_(row[columns], model, size)\n",
    "        data_array.append(w2v)\n",
    "    return pd.DataFrame(data_array)\n",
    "\n",
    "df_embeeding = get_mean_w2v(all_data_test, 'seller_path', model, 100)\n",
    "df_embeeding.columns = ['embeeding_' + str(i) for i in df_embeeding.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeeding特征和原始特征合并\n",
    "all_data_test = pd.concat([all_data_test, df_embeeding],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11、stacking特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss,mean_absolute_error,mean_squared_error\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking回归特征\n",
    "def stacking_reg(clf,train_x,train_y,test_x,clf_name,kf,label_split=None):\n",
    "    train=np.zeros((train_x.shape[0],1))\n",
    "    test=np.zeros((test_x.shape[0],1))\n",
    "    test_pre=np.empty((folds,test_x.shape[0],1))\n",
    "    cv_scores=[]\n",
    "    for i,(train_index,test_index) in enumerate(kf.split(train_x,label_split)):       \n",
    "        tr_x=train_x[train_index]\n",
    "        tr_y=train_y[train_index]\n",
    "        te_x=train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "        if clf_name in [\"rf\",\"ada\",\"gb\",\"et\",\"lr\"]:\n",
    "            clf.fit(tr_x,tr_y)\n",
    "            pre=clf.predict(te_x).reshape(-1,1)\n",
    "            train[test_index]=pre\n",
    "            test_pre[i,:]=clf.predict(test_x).reshape(-1,1)\n",
    "            cv_scores.append(mean_squared_error(te_y, pre))\n",
    "        elif clf_name in [\"xgb\"]:\n",
    "            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-1)\n",
    "            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-1)\n",
    "            z = clf.DMatrix(test_x, label=te_y, missing=-1)\n",
    "            params = {'booster': 'gbtree',\n",
    "                      'eval_metric': 'rmse',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      'nthread': 12\n",
    "                      }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            watchlist = [(train_matrix, 'train'),\n",
    "                         (test_matrix, 'eval')\n",
    "                         ]\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "                train[test_index]=pre\n",
    "                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "                cv_scores.append(mean_squared_error(te_y, pre))\n",
    "\n",
    "        elif clf_name in [\"lgb\"]:\n",
    "            train_matrix = clf.Dataset(tr_x, label=tr_y)\n",
    "            test_matrix = clf.Dataset(te_x, label=te_y)\n",
    "            params = {\n",
    "                      'boosting_type': 'gbdt',\n",
    "                      'objective': 'regression_l2',\n",
    "                      'metric': 'mse',\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'num_leaves': 2**5,\n",
    "                      'lambda_l2': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'learning_rate': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      'nthread': 12,\n",
    "                      'silent': True,\n",
    "                      }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(te_x,num_iteration=model.best_iteration).reshape(-1,1)\n",
    "                train[test_index]=pre\n",
    "                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration).reshape(-1,1)\n",
    "                cv_scores.append(mean_squared_error(te_y, pre))\n",
    "        else:\n",
    "            raise IOError(\"Please add new clf.\")\n",
    "        print(\"%s now score is:\"%clf_name,cv_scores)\n",
    "    test[:]=test_pre.mean(axis=0)\n",
    "    print(\"%s_score_list:\"%clf_name,cv_scores)\n",
    "    print(\"%s_score_mean:\"%clf_name,np.mean(cv_scores))\n",
    "    return train.reshape(-1,1),test.reshape(-1,1)\n",
    "\n",
    "def rf_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    randomforest = RandomForestRegressor(n_estimators=600, max_depth=20, n_jobs=-1, random_state=2017, max_features=\"auto\",verbose=1)\n",
    "    rf_train, rf_test = stacking_reg(randomforest, x_train, y_train, x_valid, \"rf\", kf, label_split=label_split)\n",
    "    return rf_train, rf_test,\"rf_reg\"\n",
    "\n",
    "def ada_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    adaboost = AdaBoostRegressor(n_estimators=30, random_state=2017, learning_rate=0.01)\n",
    "    ada_train, ada_test = stacking_reg(adaboost, x_train, y_train, x_valid, \"ada\", kf, label_split=label_split)\n",
    "    return ada_train, ada_test,\"ada_reg\"\n",
    "\n",
    "def gb_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    gbdt = GradientBoostingRegressor(learning_rate=0.04, n_estimators=100, subsample=0.8, random_state=2017,max_depth=5,verbose=1)\n",
    "    gbdt_train, gbdt_test = stacking_reg(gbdt, x_train, y_train, x_valid, \"gb\", kf, label_split=label_split)\n",
    "    return gbdt_train, gbdt_test,\"gb_reg\"\n",
    "\n",
    "def et_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    extratree = ExtraTreesRegressor(n_estimators=600, max_depth=35, max_features=\"auto\", n_jobs=-1, random_state=2017,verbose=1)\n",
    "    et_train, et_test = stacking_reg(extratree, x_train, y_train, x_valid, \"et\", kf, label_split=label_split)\n",
    "    return et_train, et_test,\"et_reg\"\n",
    "\n",
    "def lr_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    lr_reg=LinearRegression(n_jobs=-1)\n",
    "    lr_train, lr_test = stacking_reg(lr_reg, x_train, y_train, x_valid, \"lr\", kf, label_split=label_split)\n",
    "    return lr_train, lr_test, \"lr_reg\"\n",
    "\n",
    "def xgb_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_reg(xgboost, x_train, y_train, x_valid, \"xgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test,\"xgb_reg\"\n",
    "\n",
    "def lgb_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    lgb_train, lgb_test = stacking_reg(lightgbm, x_train, y_train, x_valid, \"lgb\", kf, label_split=label_split)\n",
    "    return lgb_train, lgb_test,\"lgb_reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking分类特征\n",
    "def stacking_clf(clf,train_x,train_y,test_x,clf_name,kf,label_split=None):\n",
    "    train=np.zeros((train_x.shape[0],1))\n",
    "    test=np.zeros((test_x.shape[0],1))\n",
    "    test_pre=np.empty((folds,test_x.shape[0],1))\n",
    "    cv_scores=[]\n",
    "    for i,(train_index,test_index) in enumerate(kf.split(train_x,label_split)):       \n",
    "        tr_x=train_x[train_index]\n",
    "        tr_y=train_y[train_index]\n",
    "        te_x=train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "\n",
    "        if clf_name in [\"rf\",\"ada\",\"gb\",\"et\",\"lr\",\"knn\",\"gnb\"]:\n",
    "            clf.fit(tr_x,tr_y)\n",
    "            pre=clf.predict_proba(te_x)\n",
    "            \n",
    "            train[test_index]=pre[:,0].reshape(-1,1)\n",
    "            test_pre[i,:]=clf.predict_proba(test_x)[:,0].reshape(-1,1)\n",
    "            \n",
    "            cv_scores.append(log_loss(te_y, pre[:,0].reshape(-1,1)))\n",
    "        elif clf_name in [\"xgb\"]:\n",
    "            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-1)\n",
    "            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-1)\n",
    "            z = clf.DMatrix(test_x)\n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'multi:softprob',\n",
    "                      'eval_metric': 'mlogloss',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      \"num_class\": 2\n",
    "                      }\n",
    "\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            watchlist = [(train_matrix, 'train'),\n",
    "                         (test_matrix, 'eval')\n",
    "                         ]\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit)\n",
    "                train[test_index]=pre[:,0].reshape(-1,1)\n",
    "                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit)[:,0].reshape(-1,1)\n",
    "                cv_scores.append(log_loss(te_y, pre[:,0].reshape(-1,1)))\n",
    "        elif clf_name in [\"lgb\"]:\n",
    "            train_matrix = clf.Dataset(tr_x, label=tr_y)\n",
    "            test_matrix = clf.Dataset(te_x, label=te_y)\n",
    "            params = {\n",
    "                      'boosting_type': 'gbdt',\n",
    "                      #'boosting_type': 'dart',\n",
    "                      'objective': 'multiclass',\n",
    "                      'metric': 'multi_logloss',\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'num_leaves': 2**5,\n",
    "                      'lambda_l2': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'learning_rate': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      \"num_class\": 2,\n",
    "                      'silent': True,\n",
    "                      }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(te_x,num_iteration=model.best_iteration)\n",
    "                train[test_index]=pre[:,0].reshape(-1,1)\n",
    "                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration)[:,0].reshape(-1,1)\n",
    "                cv_scores.append(log_loss(te_y, pre[:,0].reshape(-1,1)))\n",
    "        else:\n",
    "            raise IOError(\"Please add new clf.\")\n",
    "        print(\"%s now score is:\"%clf_name,cv_scores)\n",
    "    test[:]=test_pre.mean(axis=0)\n",
    "    print(\"%s_score_list:\"%clf_name,cv_scores)\n",
    "    print(\"%s_score_mean:\"%clf_name,np.mean(cv_scores))\n",
    "    return train.reshape(-1,1),test.reshape(-1,1)\n",
    "\n",
    "def rf_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    randomforest = RandomForestClassifier(n_estimators=1200, max_depth=20, n_jobs=-1, random_state=2017, max_features=\"auto\",verbose=1)\n",
    "    rf_train, rf_test = stacking_clf(randomforest, x_train, y_train, x_valid, \"rf\", kf, label_split=label_split)\n",
    "    return rf_train, rf_test,\"rf\"\n",
    "\n",
    "def ada_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    adaboost = AdaBoostClassifier(n_estimators=50, random_state=2017, learning_rate=0.01)\n",
    "    ada_train, ada_test = stacking_clf(adaboost, x_train, y_train, x_valid, \"ada\", kf, label_split=label_split)\n",
    "    return ada_train, ada_test,\"ada\"\n",
    "\n",
    "def gb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    gbdt = GradientBoostingClassifier(learning_rate=0.04, n_estimators=100, subsample=0.8, random_state=2017,max_depth=5,verbose=1)\n",
    "    gbdt_train, gbdt_test = stacking_clf(gbdt, x_train, y_train, x_valid, \"gb\", kf, label_split=label_split)\n",
    "    return gbdt_train, gbdt_test,\"gb\"\n",
    "\n",
    "def et_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    extratree = ExtraTreesClassifier(n_estimators=1200, max_depth=35, max_features=\"auto\", n_jobs=-1, random_state=2017,verbose=1)\n",
    "    et_train, et_test = stacking_clf(extratree, x_train, y_train, x_valid, \"et\", kf, label_split=label_split)\n",
    "    return et_train, et_test,\"et\"\n",
    "\n",
    "def xgb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_clf(xgboost, x_train, y_train, x_valid, \"xgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test,\"xgb\"\n",
    "\n",
    "def lgb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_clf(lightgbm, x_train, y_train, x_valid, \"lgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test,\"lgb\"\n",
    "\n",
    "def gnb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    gnb=GaussianNB()\n",
    "    gnb_train, gnb_test = stacking_clf(gnb, x_train, y_train, x_valid, \"gnb\", kf, label_split=label_split)\n",
    "    return gnb_train, gnb_test,\"gnb\"\n",
    "\n",
    "def lr_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    logisticregression=LogisticRegression(n_jobs=-1,random_state=2017,C=0.1,max_iter=200)\n",
    "    lr_train, lr_test = stacking_clf(logisticregression, x_train, y_train, x_valid, \"lr\", kf, label_split=label_split)\n",
    "    return lr_train, lr_test, \"lr\"\n",
    "\n",
    "def knn_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    kneighbors=KNeighborsClassifier(n_neighbors=200,n_jobs=-1)\n",
    "    knn_train, knn_test = stacking_clf(kneighbors, x_train, y_train, x_valid, \"lr\", kf, label_split=label_split)\n",
    "    return knn_train, knn_test, \"knn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取训练和验证数据（为stacking特征做准备）\n",
    "features_columns = [c for c in all_data_test.columns if c not in ['label', 'prob', 'seller_path', 'cat_path', 'brand_path', 'action_type_path', 'item_path', 'time_stamp_path']]\n",
    "x_train = all_data_test[~all_data_test['label'].isna()][features_columns].values\n",
    "y_train = all_data_test[~all_data_test['label'].isna()]['label'].values\n",
    "x_valid = all_data_test[all_data_test['label'].isna()][features_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理函数值inf以及nan情况\n",
    "def get_matrix(data):\n",
    "    where_are_nan = np.isnan(data)\n",
    "    where_are_inf = np.isinf(data)\n",
    "    data[where_are_nan] = 0\n",
    "    data[where_are_inf] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.float_(get_matrix(np.float_(x_train)))\n",
    "y_train = np.int_(y_train)\n",
    "x_valid = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入划分数据函数，设stacking特征为5折\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "folds = 5\n",
    "seed = 1\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用lgb和xgb分类模型构造stacking特征\n",
    "clf_list = [lgb_clf, xgb_clf]\n",
    "clf_list_col = ['lgb_clf', 'xgb_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 225\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.066541\n",
      "[LightGBM] [Info] Start training from score -2.743030\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.240511\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.240463\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's multi_logloss: 0.24085\n",
      "[4]\tvalid_0's multi_logloss: 0.241294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's multi_logloss: 0.241294\n",
      "[6]\tvalid_0's multi_logloss: 0.241829\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's multi_logloss: 0.241824\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's multi_logloss: 0.241778\n",
      "[9]\tvalid_0's multi_logloss: 0.24205\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.242334\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's multi_logloss: 0.242559\n",
      "[12]\tvalid_0's multi_logloss: 0.242622\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's multi_logloss: 0.242745\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's multi_logloss: 0.243112\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's multi_logloss: 0.243395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's multi_logloss: 0.243183\n",
      "[17]\tvalid_0's multi_logloss: 0.243132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's multi_logloss: 0.242749\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's multi_logloss: 0.243221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.243604\n",
      "[21]\tvalid_0's multi_logloss: 0.243928\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's multi_logloss: 0.244123\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's multi_logloss: 0.244457\n",
      "[24]\tvalid_0's multi_logloss: 0.24428\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's multi_logloss: 0.244667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's multi_logloss: 0.244995\n",
      "[27]\tvalid_0's multi_logloss: 0.245238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's multi_logloss: 0.245515\n",
      "[29]\tvalid_0's multi_logloss: 0.245469\n",
      "[30]\tvalid_0's multi_logloss: 0.245857\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's multi_logloss: 0.245905\n",
      "[32]\tvalid_0's multi_logloss: 0.245855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.246118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's multi_logloss: 0.246639\n",
      "[35]\tvalid_0's multi_logloss: 0.2466\n",
      "[36]\tvalid_0's multi_logloss: 0.247074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's multi_logloss: 0.2477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's multi_logloss: 0.247847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's multi_logloss: 0.247812\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.248198\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's multi_logloss: 0.248601\n",
      "[42]\tvalid_0's multi_logloss: 0.248825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's multi_logloss: 0.24912\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's multi_logloss: 0.249382\n",
      "[45]\tvalid_0's multi_logloss: 0.249704\n",
      "[46]\tvalid_0's multi_logloss: 0.249994\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.250301\n",
      "[48]\tvalid_0's multi_logloss: 0.250635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's multi_logloss: 0.250816\n",
      "[50]\tvalid_0's multi_logloss: 0.250959\n",
      "[51]\tvalid_0's multi_logloss: 0.251253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's multi_logloss: 0.251651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's multi_logloss: 0.252189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 0.252342\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.252776\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's multi_logloss: 0.253151\n",
      "[57]\tvalid_0's multi_logloss: 0.253506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 0.25372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's multi_logloss: 0.254185\n",
      "[60]\tvalid_0's multi_logloss: 0.254485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 0.254368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's multi_logloss: 0.254853\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's multi_logloss: 0.2551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's multi_logloss: 0.255483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's multi_logloss: 0.255645\n",
      "[66]\tvalid_0's multi_logloss: 0.255959\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 0.256348\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.2566\n",
      "[69]\tvalid_0's multi_logloss: 0.256773\n",
      "[70]\tvalid_0's multi_logloss: 0.256874\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.257353\n",
      "[72]\tvalid_0's multi_logloss: 0.257577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's multi_logloss: 0.257609\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 0.257977\n",
      "[75]\tvalid_0's multi_logloss: 0.258123\n",
      "[76]\tvalid_0's multi_logloss: 0.25825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's multi_logloss: 0.258285\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's multi_logloss: 0.258617\n",
      "[79]\tvalid_0's multi_logloss: 0.258887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.259079\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.25936\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's multi_logloss: 0.259505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's multi_logloss: 0.259837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tvalid_0's multi_logloss: 0.259805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's multi_logloss: 0.260133\n",
      "[86]\tvalid_0's multi_logloss: 0.26031\n",
      "[87]\tvalid_0's multi_logloss: 0.260518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.260738\n",
      "[89]\tvalid_0's multi_logloss: 0.260982\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.261506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\tvalid_0's multi_logloss: 0.261526\n",
      "[92]\tvalid_0's multi_logloss: 0.261844\n",
      "[93]\tvalid_0's multi_logloss: 0.261996\n",
      "[94]\tvalid_0's multi_logloss: 0.262074\n",
      "[95]\tvalid_0's multi_logloss: 0.262211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's multi_logloss: 0.262288\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tvalid_0's multi_logloss: 0.262523\n",
      "[98]\tvalid_0's multi_logloss: 0.262809\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tvalid_0's multi_logloss: 0.262937\n",
      "[100]\tvalid_0's multi_logloss: 0.263207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's multi_logloss: 0.263439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[102]\tvalid_0's multi_logloss: 0.263805\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 0.240463\n",
      "lgb now score is: [2.5773079632811675]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32148\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 226\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.062541\n",
      "[LightGBM] [Info] Start training from score -2.803048\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.281569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's multi_logloss: 0.282089\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's multi_logloss: 0.282428\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's multi_logloss: 0.282916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's multi_logloss: 0.283126\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's multi_logloss: 0.283095\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's multi_logloss: 0.283499\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's multi_logloss: 0.283857\n",
      "[9]\tvalid_0's multi_logloss: 0.284187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.284283\n",
      "[11]\tvalid_0's multi_logloss: 0.285006\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's multi_logloss: 0.2854\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's multi_logloss: 0.285509\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's multi_logloss: 0.285643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's multi_logloss: 0.286029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's multi_logloss: 0.286199\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's multi_logloss: 0.286522\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's multi_logloss: 0.286599\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's multi_logloss: 0.28709\n",
      "[20]\tvalid_0's multi_logloss: 0.287461\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's multi_logloss: 0.287831\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's multi_logloss: 0.288221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's multi_logloss: 0.288927\n",
      "[24]\tvalid_0's multi_logloss: 0.289204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's multi_logloss: 0.289542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's multi_logloss: 0.289787\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's multi_logloss: 0.290206\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's multi_logloss: 0.29034\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's multi_logloss: 0.290869\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's multi_logloss: 0.291456\n",
      "[31]\tvalid_0's multi_logloss: 0.291771\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's multi_logloss: 0.292297\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.292918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's multi_logloss: 0.29358\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's multi_logloss: 0.293847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's multi_logloss: 0.294367\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's multi_logloss: 0.294915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's multi_logloss: 0.295159\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's multi_logloss: 0.29564\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.29584\n",
      "[41]\tvalid_0's multi_logloss: 0.296042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's multi_logloss: 0.296579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's multi_logloss: 0.296796\n",
      "[44]\tvalid_0's multi_logloss: 0.297092\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's multi_logloss: 0.297563\n",
      "[46]\tvalid_0's multi_logloss: 0.297517\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.297922\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's multi_logloss: 0.298188\n",
      "[49]\tvalid_0's multi_logloss: 0.298515\n",
      "[50]\tvalid_0's multi_logloss: 0.298419\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's multi_logloss: 0.298893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's multi_logloss: 0.299034\n",
      "[53]\tvalid_0's multi_logloss: 0.299457\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 0.299761\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.300028\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's multi_logloss: 0.300389\n",
      "[57]\tvalid_0's multi_logloss: 0.300643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 0.300952\n",
      "[59]\tvalid_0's multi_logloss: 0.301196\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.301586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 0.30194\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's multi_logloss: 0.302087\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's multi_logloss: 0.302445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's multi_logloss: 0.302499\n",
      "[65]\tvalid_0's multi_logloss: 0.302721\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 0.303105\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 0.303445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.303923\n",
      "[69]\tvalid_0's multi_logloss: 0.304148\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.304423\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.305038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's multi_logloss: 0.305473\n",
      "[73]\tvalid_0's multi_logloss: 0.305697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 0.306116\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.306568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 0.30687\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's multi_logloss: 0.307335\n",
      "[78]\tvalid_0's multi_logloss: 0.307607\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's multi_logloss: 0.308199\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.308447\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.30864\n",
      "[82]\tvalid_0's multi_logloss: 0.309113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's multi_logloss: 0.309169\n",
      "[84]\tvalid_0's multi_logloss: 0.3095\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's multi_logloss: 0.309877\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tvalid_0's multi_logloss: 0.310165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tvalid_0's multi_logloss: 0.310508\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.311008\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tvalid_0's multi_logloss: 0.311352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.311864\n",
      "[91]\tvalid_0's multi_logloss: 0.312518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\tvalid_0's multi_logloss: 0.312943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's multi_logloss: 0.313378\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\tvalid_0's multi_logloss: 0.313805\n",
      "[95]\tvalid_0's multi_logloss: 0.313916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's multi_logloss: 0.314048\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tvalid_0's multi_logloss: 0.31459\n",
      "[98]\tvalid_0's multi_logloss: 0.315159\n",
      "[99]\tvalid_0's multi_logloss: 0.315436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.31591\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's multi_logloss: 0.316241\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 0.281569\n",
      "lgb now score is: [2.5773079632811675, 2.5900790225749835]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32124\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 225\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.065205\n",
      "[LightGBM] [Info] Start training from score -2.762638\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.254167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's multi_logloss: 0.254313\n",
      "[3]\tvalid_0's multi_logloss: 0.254389\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's multi_logloss: 0.254317\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's multi_logloss: 0.254432\n",
      "[6]\tvalid_0's multi_logloss: 0.254388\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's multi_logloss: 0.25436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's multi_logloss: 0.254622\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's multi_logloss: 0.254921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.255056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\tvalid_0's multi_logloss: 0.255134\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's multi_logloss: 0.255216\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's multi_logloss: 0.255317\n",
      "[14]\tvalid_0's multi_logloss: 0.255736\n",
      "[15]\tvalid_0's multi_logloss: 0.255884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's multi_logloss: 0.255881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's multi_logloss: 0.255988\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's multi_logloss: 0.256062\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's multi_logloss: 0.25616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.256461\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's multi_logloss: 0.256837\n",
      "[22]\tvalid_0's multi_logloss: 0.257068\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's multi_logloss: 0.257367\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's multi_logloss: 0.257376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's multi_logloss: 0.257615\n",
      "[26]\tvalid_0's multi_logloss: 0.257655\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's multi_logloss: 0.257937\n",
      "[28]\tvalid_0's multi_logloss: 0.258212\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's multi_logloss: 0.258259\n",
      "[30]\tvalid_0's multi_logloss: 0.258498\n",
      "[31]\tvalid_0's multi_logloss: 0.258715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's multi_logloss: 0.258873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.259139\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's multi_logloss: 0.259055\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's multi_logloss: 0.259185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's multi_logloss: 0.259376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's multi_logloss: 0.259351\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's multi_logloss: 0.259392\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's multi_logloss: 0.259787\n",
      "[40]\tvalid_0's multi_logloss: 0.25983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's multi_logloss: 0.259924\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's multi_logloss: 0.260056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's multi_logloss: 0.260503\n",
      "[44]\tvalid_0's multi_logloss: 0.260676\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's multi_logloss: 0.260705\n",
      "[46]\tvalid_0's multi_logloss: 0.261009\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.261034\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's multi_logloss: 0.26126\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's multi_logloss: 0.261403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.261657\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's multi_logloss: 0.261673\n",
      "[52]\tvalid_0's multi_logloss: 0.262019\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's multi_logloss: 0.262257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 0.262348\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.262396\n",
      "[56]\tvalid_0's multi_logloss: 0.262811\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's multi_logloss: 0.263007\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 0.263376\n",
      "[59]\tvalid_0's multi_logloss: 0.263556\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.263621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 0.263835\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's multi_logloss: 0.264315\n",
      "[63]\tvalid_0's multi_logloss: 0.264616\n",
      "[64]\tvalid_0's multi_logloss: 0.264752\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's multi_logloss: 0.264769\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 0.265025\n",
      "[67]\tvalid_0's multi_logloss: 0.265315\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.265646\n",
      "[69]\tvalid_0's multi_logloss: 0.26592\n",
      "[70]\tvalid_0's multi_logloss: 0.266225\n",
      "[71]\tvalid_0's multi_logloss: 0.266445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's multi_logloss: 0.266625\n",
      "[73]\tvalid_0's multi_logloss: 0.266829\n",
      "[74]\tvalid_0's multi_logloss: 0.266749\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.267037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 0.267223\n",
      "[77]\tvalid_0's multi_logloss: 0.267622\n",
      "[78]\tvalid_0's multi_logloss: 0.267678\n",
      "[79]\tvalid_0's multi_logloss: 0.267715\n",
      "[80]\tvalid_0's multi_logloss: 0.26773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.267761\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's multi_logloss: 0.268105\n",
      "[83]\tvalid_0's multi_logloss: 0.268519\n",
      "[84]\tvalid_0's multi_logloss: 0.268599\n",
      "[85]\tvalid_0's multi_logloss: 0.26864\n",
      "[86]\tvalid_0's multi_logloss: 0.268881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tvalid_0's multi_logloss: 0.26919\n",
      "[88]\tvalid_0's multi_logloss: 0.269481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tvalid_0's multi_logloss: 0.26977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.269982\n",
      "[91]\tvalid_0's multi_logloss: 0.270187\n",
      "[92]\tvalid_0's multi_logloss: 0.270302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's multi_logloss: 0.270678\n",
      "[94]\tvalid_0's multi_logloss: 0.270795\n",
      "[95]\tvalid_0's multi_logloss: 0.270977\n",
      "[96]\tvalid_0's multi_logloss: 0.27132\n",
      "[97]\tvalid_0's multi_logloss: 0.271528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's multi_logloss: 0.271949\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tvalid_0's multi_logloss: 0.272056\n",
      "[100]\tvalid_0's multi_logloss: 0.27221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's multi_logloss: 0.272458\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 0.254167\n",
      "lgb now score is: [2.5773079632811675, 2.5900790225749835, 2.5788078245266832]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.069886\n",
      "[LightGBM] [Info] Start training from score -2.695628\n",
      "[1]\tvalid_0's multi_logloss: 0.207518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's multi_logloss: 0.207222\n",
      "[3]\tvalid_0's multi_logloss: 0.207387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's multi_logloss: 0.207411\n",
      "[5]\tvalid_0's multi_logloss: 0.207354\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's multi_logloss: 0.207277\n",
      "[7]\tvalid_0's multi_logloss: 0.207555\n",
      "[8]\tvalid_0's multi_logloss: 0.207332\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's multi_logloss: 0.207025\n",
      "[10]\tvalid_0's multi_logloss: 0.206797\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's multi_logloss: 0.206569\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's multi_logloss: 0.206591\n",
      "[13]\tvalid_0's multi_logloss: 0.206726\n",
      "[14]\tvalid_0's multi_logloss: 0.206901\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's multi_logloss: 0.206635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's multi_logloss: 0.206609\n",
      "[17]\tvalid_0's multi_logloss: 0.206551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's multi_logloss: 0.206463\n",
      "[19]\tvalid_0's multi_logloss: 0.206489\n",
      "[20]\tvalid_0's multi_logloss: 0.206188\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's multi_logloss: 0.205804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's multi_logloss: 0.205965\n",
      "[23]\tvalid_0's multi_logloss: 0.206162\n",
      "[24]\tvalid_0's multi_logloss: 0.206113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's multi_logloss: 0.20645\n",
      "[26]\tvalid_0's multi_logloss: 0.206281\n",
      "[27]\tvalid_0's multi_logloss: 0.20619\n",
      "[28]\tvalid_0's multi_logloss: 0.206447\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's multi_logloss: 0.206428\n",
      "[30]\tvalid_0's multi_logloss: 0.20666\n",
      "[31]\tvalid_0's multi_logloss: 0.20696\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's multi_logloss: 0.207449\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.207602\n",
      "[34]\tvalid_0's multi_logloss: 0.207647\n",
      "[35]\tvalid_0's multi_logloss: 0.207901\n",
      "[36]\tvalid_0's multi_logloss: 0.208042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's multi_logloss: 0.208223\n",
      "[38]\tvalid_0's multi_logloss: 0.208292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's multi_logloss: 0.208248\n",
      "[40]\tvalid_0's multi_logloss: 0.208564\n",
      "[41]\tvalid_0's multi_logloss: 0.208888\n",
      "[42]\tvalid_0's multi_logloss: 0.209164\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's multi_logloss: 0.20933\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's multi_logloss: 0.209194\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's multi_logloss: 0.208744\n",
      "[46]\tvalid_0's multi_logloss: 0.208989\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.209039\n",
      "[48]\tvalid_0's multi_logloss: 0.20919\n",
      "[49]\tvalid_0's multi_logloss: 0.209409\n",
      "[50]\tvalid_0's multi_logloss: 0.209553\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's multi_logloss: 0.20984\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's multi_logloss: 0.210047\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's multi_logloss: 0.210331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 0.210499\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.210742\n",
      "[56]\tvalid_0's multi_logloss: 0.210813\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's multi_logloss: 0.211125\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 0.211353\n",
      "[59]\tvalid_0's multi_logloss: 0.211563\n",
      "[60]\tvalid_0's multi_logloss: 0.211684\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 0.211879\n",
      "[62]\tvalid_0's multi_logloss: 0.212042\n",
      "[63]\tvalid_0's multi_logloss: 0.212348\n",
      "[64]\tvalid_0's multi_logloss: 0.212495\n",
      "[65]\tvalid_0's multi_logloss: 0.212681\n",
      "[66]\tvalid_0's multi_logloss: 0.212868\n",
      "[67]\tvalid_0's multi_logloss: 0.213237\n",
      "[68]\tvalid_0's multi_logloss: 0.213537\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's multi_logloss: 0.213833\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.213995\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.214124\n",
      "[72]\tvalid_0's multi_logloss: 0.214331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's multi_logloss: 0.214425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 0.214715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.214851\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 0.215258\n",
      "[77]\tvalid_0's multi_logloss: 0.215356\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's multi_logloss: 0.21577\n",
      "[79]\tvalid_0's multi_logloss: 0.2159\n",
      "[80]\tvalid_0's multi_logloss: 0.216367\n",
      "[81]\tvalid_0's multi_logloss: 0.216641\n",
      "[82]\tvalid_0's multi_logloss: 0.216755\n",
      "[83]\tvalid_0's multi_logloss: 0.217091\n",
      "[84]\tvalid_0's multi_logloss: 0.217271\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's multi_logloss: 0.2174\n",
      "[86]\tvalid_0's multi_logloss: 0.217517\n",
      "[87]\tvalid_0's multi_logloss: 0.217708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.21805\n",
      "[89]\tvalid_0's multi_logloss: 0.218215\n",
      "[90]\tvalid_0's multi_logloss: 0.218532\n",
      "[91]\tvalid_0's multi_logloss: 0.218984\n",
      "[92]\tvalid_0's multi_logloss: 0.21918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's multi_logloss: 0.21977\n",
      "[94]\tvalid_0's multi_logloss: 0.219848\n",
      "[95]\tvalid_0's multi_logloss: 0.219944\n",
      "[96]\tvalid_0's multi_logloss: 0.220269\n",
      "[97]\tvalid_0's multi_logloss: 0.220599\n",
      "[98]\tvalid_0's multi_logloss: 0.220778\n",
      "[99]\tvalid_0's multi_logloss: 0.220917\n",
      "[100]\tvalid_0's multi_logloss: 0.221214\n",
      "[101]\tvalid_0's multi_logloss: 0.221229\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[102]\tvalid_0's multi_logloss: 0.221369\n",
      "[103]\tvalid_0's multi_logloss: 0.221546\n",
      "[104]\tvalid_0's multi_logloss: 0.22175\n",
      "[105]\tvalid_0's multi_logloss: 0.22189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[106]\tvalid_0's multi_logloss: 0.222171\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[107]\tvalid_0's multi_logloss: 0.22249\n",
      "[108]\tvalid_0's multi_logloss: 0.222745\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[109]\tvalid_0's multi_logloss: 0.223085\n",
      "[110]\tvalid_0's multi_logloss: 0.22325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[111]\tvalid_0's multi_logloss: 0.223655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[112]\tvalid_0's multi_logloss: 0.223864\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[113]\tvalid_0's multi_logloss: 0.224039\n",
      "[114]\tvalid_0's multi_logloss: 0.224241\n",
      "[115]\tvalid_0's multi_logloss: 0.224583\n",
      "[116]\tvalid_0's multi_logloss: 0.224805\n",
      "[117]\tvalid_0's multi_logloss: 0.225033\n",
      "[118]\tvalid_0's multi_logloss: 0.225218\n",
      "[119]\tvalid_0's multi_logloss: 0.225493\n",
      "[120]\tvalid_0's multi_logloss: 0.225882\n",
      "[121]\tvalid_0's multi_logloss: 0.226036\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 0.205804\n",
      "lgb now score is: [2.5773079632811675, 2.5900790225749835, 2.5788078245266832, 2.651874893223334]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32040\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 225\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.069216\n",
      "[LightGBM] [Info] Start training from score -2.704930\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.213743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's multi_logloss: 0.213117\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's multi_logloss: 0.212833\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's multi_logloss: 0.212865\n",
      "[5]\tvalid_0's multi_logloss: 0.212675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's multi_logloss: 0.212648\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's multi_logloss: 0.212592\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's multi_logloss: 0.212878\n",
      "[9]\tvalid_0's multi_logloss: 0.213091\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.213159\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's multi_logloss: 0.213505\n",
      "[12]\tvalid_0's multi_logloss: 0.21373\n",
      "[13]\tvalid_0's multi_logloss: 0.213814\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's multi_logloss: 0.213888\n",
      "[15]\tvalid_0's multi_logloss: 0.213582\n",
      "[16]\tvalid_0's multi_logloss: 0.213701\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's multi_logloss: 0.213702\n",
      "[18]\tvalid_0's multi_logloss: 0.214025\n",
      "[19]\tvalid_0's multi_logloss: 0.214061\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.214286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's multi_logloss: 0.214136\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's multi_logloss: 0.214439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's multi_logloss: 0.214802\n",
      "[24]\tvalid_0's multi_logloss: 0.214546\n",
      "[25]\tvalid_0's multi_logloss: 0.214618\n",
      "[26]\tvalid_0's multi_logloss: 0.214537\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's multi_logloss: 0.214545\n",
      "[28]\tvalid_0's multi_logloss: 0.214979\n",
      "[29]\tvalid_0's multi_logloss: 0.214793\n",
      "[30]\tvalid_0's multi_logloss: 0.214832\n",
      "[31]\tvalid_0's multi_logloss: 0.215023\n",
      "[32]\tvalid_0's multi_logloss: 0.215181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.215392\n",
      "[34]\tvalid_0's multi_logloss: 0.215358\n",
      "[35]\tvalid_0's multi_logloss: 0.215345\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's multi_logloss: 0.215582\n",
      "[37]\tvalid_0's multi_logloss: 0.215528\n",
      "[38]\tvalid_0's multi_logloss: 0.215398\n",
      "[39]\tvalid_0's multi_logloss: 0.215474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.215624\n",
      "[41]\tvalid_0's multi_logloss: 0.215602\n",
      "[42]\tvalid_0's multi_logloss: 0.215598\n",
      "[43]\tvalid_0's multi_logloss: 0.215989\n",
      "[44]\tvalid_0's multi_logloss: 0.2158\n",
      "[45]\tvalid_0's multi_logloss: 0.215752\n",
      "[46]\tvalid_0's multi_logloss: 0.215794\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.216155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's multi_logloss: 0.216126\n",
      "[49]\tvalid_0's multi_logloss: 0.21602\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.215905\n",
      "[51]\tvalid_0's multi_logloss: 0.216195\n",
      "[52]\tvalid_0's multi_logloss: 0.216373\n",
      "[53]\tvalid_0's multi_logloss: 0.216414\n",
      "[54]\tvalid_0's multi_logloss: 0.216381\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.216801\n",
      "[56]\tvalid_0's multi_logloss: 0.216825\n",
      "[57]\tvalid_0's multi_logloss: 0.2169\n",
      "[58]\tvalid_0's multi_logloss: 0.216875\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's multi_logloss: 0.217073\n",
      "[60]\tvalid_0's multi_logloss: 0.217155\n",
      "[61]\tvalid_0's multi_logloss: 0.217209\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's multi_logloss: 0.217287\n",
      "[63]\tvalid_0's multi_logloss: 0.217318\n",
      "[64]\tvalid_0's multi_logloss: 0.217511\n",
      "[65]\tvalid_0's multi_logloss: 0.217546\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 0.217416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 0.217562\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.217709\n",
      "[69]\tvalid_0's multi_logloss: 0.217783\n",
      "[70]\tvalid_0's multi_logloss: 0.217677\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.217968\n",
      "[72]\tvalid_0's multi_logloss: 0.218227\n",
      "[73]\tvalid_0's multi_logloss: 0.218255\n",
      "[74]\tvalid_0's multi_logloss: 0.21822\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.218394\n",
      "[76]\tvalid_0's multi_logloss: 0.218462\n",
      "[77]\tvalid_0's multi_logloss: 0.218427\n",
      "[78]\tvalid_0's multi_logloss: 0.218412\n",
      "[79]\tvalid_0's multi_logloss: 0.218512\n",
      "[80]\tvalid_0's multi_logloss: 0.218509\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.218517\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's multi_logloss: 0.218665\n",
      "[83]\tvalid_0's multi_logloss: 0.218791\n",
      "[84]\tvalid_0's multi_logloss: 0.21897\n",
      "[85]\tvalid_0's multi_logloss: 0.219043\n",
      "[86]\tvalid_0's multi_logloss: 0.219172\n",
      "[87]\tvalid_0's multi_logloss: 0.219427\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.219671\n",
      "[89]\tvalid_0's multi_logloss: 0.219632\n",
      "[90]\tvalid_0's multi_logloss: 0.219705\n",
      "[91]\tvalid_0's multi_logloss: 0.219812\n",
      "[92]\tvalid_0's multi_logloss: 0.219761\n",
      "[93]\tvalid_0's multi_logloss: 0.219933\n",
      "[94]\tvalid_0's multi_logloss: 0.220223\n",
      "[95]\tvalid_0's multi_logloss: 0.220473\n",
      "[96]\tvalid_0's multi_logloss: 0.220663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\tvalid_0's multi_logloss: 0.220782\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's multi_logloss: 0.221094\n",
      "[99]\tvalid_0's multi_logloss: 0.221146\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.221029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's multi_logloss: 0.221202\n",
      "[102]\tvalid_0's multi_logloss: 0.221469\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[103]\tvalid_0's multi_logloss: 0.221696\n",
      "[104]\tvalid_0's multi_logloss: 0.221909\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[105]\tvalid_0's multi_logloss: 0.222119\n",
      "[106]\tvalid_0's multi_logloss: 0.222592\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[107]\tvalid_0's multi_logloss: 0.22272\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's multi_logloss: 0.212592\n",
      "lgb now score is: [2.5773079632811675, 2.5900790225749835, 2.5788078245266832, 2.651874893223334, 2.5975077451305744]\n",
      "lgb_score_list: [2.5773079632811675, 2.5900790225749835, 2.5788078245266832, 2.651874893223334, 2.5975077451305744]\n",
      "lgb_score_mean: 2.5991154897473487\n",
      "[0]\ttrain-mlogloss:0.67067\teval-mlogloss:0.67116\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.64975\teval-mlogloss:0.65067\n",
      "[2]\ttrain-mlogloss:0.62998\teval-mlogloss:0.63133\n",
      "[3]\ttrain-mlogloss:0.61120\teval-mlogloss:0.61317\n",
      "[4]\ttrain-mlogloss:0.59348\teval-mlogloss:0.59569\n",
      "[5]\ttrain-mlogloss:0.57659\teval-mlogloss:0.57895\n",
      "[6]\ttrain-mlogloss:0.56076\teval-mlogloss:0.56370\n",
      "[7]\ttrain-mlogloss:0.54543\teval-mlogloss:0.54880\n",
      "[8]\ttrain-mlogloss:0.53111\teval-mlogloss:0.53490\n",
      "[9]\ttrain-mlogloss:0.51714\teval-mlogloss:0.52133\n",
      "[10]\ttrain-mlogloss:0.50394\teval-mlogloss:0.50864\n",
      "[11]\ttrain-mlogloss:0.49145\teval-mlogloss:0.49678\n",
      "[12]\ttrain-mlogloss:0.47960\teval-mlogloss:0.48531\n",
      "[13]\ttrain-mlogloss:0.46832\teval-mlogloss:0.47466\n",
      "[14]\ttrain-mlogloss:0.45738\teval-mlogloss:0.46413\n",
      "[15]\ttrain-mlogloss:0.44732\teval-mlogloss:0.45462\n",
      "[16]\ttrain-mlogloss:0.43755\teval-mlogloss:0.44515\n",
      "[17]\ttrain-mlogloss:0.42808\teval-mlogloss:0.43608\n",
      "[18]\ttrain-mlogloss:0.41899\teval-mlogloss:0.42759\n",
      "[19]\ttrain-mlogloss:0.41020\teval-mlogloss:0.41915\n",
      "[20]\ttrain-mlogloss:0.40186\teval-mlogloss:0.41111\n",
      "[21]\ttrain-mlogloss:0.39406\teval-mlogloss:0.40372\n",
      "[22]\ttrain-mlogloss:0.38640\teval-mlogloss:0.39648\n",
      "[23]\ttrain-mlogloss:0.37914\teval-mlogloss:0.38971\n",
      "[24]\ttrain-mlogloss:0.37221\teval-mlogloss:0.38313\n",
      "[25]\ttrain-mlogloss:0.36558\teval-mlogloss:0.37700\n",
      "[26]\ttrain-mlogloss:0.35914\teval-mlogloss:0.37122\n",
      "[27]\ttrain-mlogloss:0.35310\teval-mlogloss:0.36543\n",
      "[28]\ttrain-mlogloss:0.34720\teval-mlogloss:0.35995\n",
      "[29]\ttrain-mlogloss:0.34165\teval-mlogloss:0.35477\n",
      "[30]\ttrain-mlogloss:0.33615\teval-mlogloss:0.34975\n",
      "[31]\ttrain-mlogloss:0.33103\teval-mlogloss:0.34510\n",
      "[32]\ttrain-mlogloss:0.32604\teval-mlogloss:0.34062\n",
      "[33]\ttrain-mlogloss:0.32125\teval-mlogloss:0.33626\n",
      "[34]\ttrain-mlogloss:0.31661\teval-mlogloss:0.33203\n",
      "[35]\ttrain-mlogloss:0.31216\teval-mlogloss:0.32816\n",
      "[36]\ttrain-mlogloss:0.30783\teval-mlogloss:0.32440\n",
      "[37]\ttrain-mlogloss:0.30378\teval-mlogloss:0.32083\n",
      "[38]\ttrain-mlogloss:0.29989\teval-mlogloss:0.31739\n",
      "[39]\ttrain-mlogloss:0.29607\teval-mlogloss:0.31377\n",
      "[40]\ttrain-mlogloss:0.29231\teval-mlogloss:0.31077\n",
      "[41]\ttrain-mlogloss:0.28882\teval-mlogloss:0.30784\n",
      "[42]\ttrain-mlogloss:0.28542\teval-mlogloss:0.30497\n",
      "[43]\ttrain-mlogloss:0.28210\teval-mlogloss:0.30217\n",
      "[44]\ttrain-mlogloss:0.27904\teval-mlogloss:0.29957\n",
      "[45]\ttrain-mlogloss:0.27563\teval-mlogloss:0.29694\n",
      "[46]\ttrain-mlogloss:0.27268\teval-mlogloss:0.29449\n",
      "[47]\ttrain-mlogloss:0.26989\teval-mlogloss:0.29234\n",
      "[48]\ttrain-mlogloss:0.26707\teval-mlogloss:0.28998\n",
      "[49]\ttrain-mlogloss:0.26447\teval-mlogloss:0.28788\n",
      "[50]\ttrain-mlogloss:0.26172\teval-mlogloss:0.28578\n",
      "[51]\ttrain-mlogloss:0.25897\teval-mlogloss:0.28405\n",
      "[52]\ttrain-mlogloss:0.25668\teval-mlogloss:0.28226\n",
      "[53]\ttrain-mlogloss:0.25422\teval-mlogloss:0.28041\n",
      "[54]\ttrain-mlogloss:0.25194\teval-mlogloss:0.27876\n",
      "[55]\ttrain-mlogloss:0.24971\teval-mlogloss:0.27727\n",
      "[56]\ttrain-mlogloss:0.24746\teval-mlogloss:0.27578\n",
      "[57]\ttrain-mlogloss:0.24515\teval-mlogloss:0.27437\n",
      "[58]\ttrain-mlogloss:0.24314\teval-mlogloss:0.27304\n",
      "[59]\ttrain-mlogloss:0.24112\teval-mlogloss:0.27184\n",
      "[60]\ttrain-mlogloss:0.23931\teval-mlogloss:0.27047\n",
      "[61]\ttrain-mlogloss:0.23752\teval-mlogloss:0.26922\n",
      "[62]\ttrain-mlogloss:0.23557\teval-mlogloss:0.26808\n",
      "[63]\ttrain-mlogloss:0.23378\teval-mlogloss:0.26702\n",
      "[64]\ttrain-mlogloss:0.23190\teval-mlogloss:0.26598\n",
      "[65]\ttrain-mlogloss:0.23024\teval-mlogloss:0.26504\n",
      "[66]\ttrain-mlogloss:0.22859\teval-mlogloss:0.26388\n",
      "[67]\ttrain-mlogloss:0.22687\teval-mlogloss:0.26308\n",
      "[68]\ttrain-mlogloss:0.22510\teval-mlogloss:0.26244\n",
      "[69]\ttrain-mlogloss:0.22339\teval-mlogloss:0.26151\n",
      "[70]\ttrain-mlogloss:0.22196\teval-mlogloss:0.26070\n",
      "[71]\ttrain-mlogloss:0.22053\teval-mlogloss:0.25978\n",
      "[72]\ttrain-mlogloss:0.21903\teval-mlogloss:0.25905\n",
      "[73]\ttrain-mlogloss:0.21775\teval-mlogloss:0.25844\n",
      "[74]\ttrain-mlogloss:0.21636\teval-mlogloss:0.25784\n",
      "[75]\ttrain-mlogloss:0.21493\teval-mlogloss:0.25707\n",
      "[76]\ttrain-mlogloss:0.21350\teval-mlogloss:0.25642\n",
      "[77]\ttrain-mlogloss:0.21216\teval-mlogloss:0.25604\n",
      "[78]\ttrain-mlogloss:0.21084\teval-mlogloss:0.25546\n",
      "[79]\ttrain-mlogloss:0.20950\teval-mlogloss:0.25513\n",
      "[80]\ttrain-mlogloss:0.20811\teval-mlogloss:0.25462\n",
      "[81]\ttrain-mlogloss:0.20680\teval-mlogloss:0.25434\n",
      "[82]\ttrain-mlogloss:0.20562\teval-mlogloss:0.25366\n",
      "[83]\ttrain-mlogloss:0.20450\teval-mlogloss:0.25295\n",
      "[84]\ttrain-mlogloss:0.20317\teval-mlogloss:0.25257\n",
      "[85]\ttrain-mlogloss:0.20191\teval-mlogloss:0.25228\n",
      "[86]\ttrain-mlogloss:0.20078\teval-mlogloss:0.25223\n",
      "[87]\ttrain-mlogloss:0.19957\teval-mlogloss:0.25193\n",
      "[88]\ttrain-mlogloss:0.19822\teval-mlogloss:0.25151\n",
      "[89]\ttrain-mlogloss:0.19714\teval-mlogloss:0.25128\n",
      "[90]\ttrain-mlogloss:0.19599\teval-mlogloss:0.25083\n",
      "[91]\ttrain-mlogloss:0.19501\teval-mlogloss:0.25037\n",
      "[92]\ttrain-mlogloss:0.19392\teval-mlogloss:0.25039\n",
      "[93]\ttrain-mlogloss:0.19282\teval-mlogloss:0.25035\n",
      "[94]\ttrain-mlogloss:0.19180\teval-mlogloss:0.25004\n",
      "[95]\ttrain-mlogloss:0.19089\teval-mlogloss:0.25023\n",
      "[96]\ttrain-mlogloss:0.19004\teval-mlogloss:0.25004\n",
      "[97]\ttrain-mlogloss:0.18891\teval-mlogloss:0.24971\n",
      "[98]\ttrain-mlogloss:0.18778\teval-mlogloss:0.24959\n",
      "[99]\ttrain-mlogloss:0.18681\teval-mlogloss:0.24945\n",
      "[100]\ttrain-mlogloss:0.18564\teval-mlogloss:0.24940\n",
      "[101]\ttrain-mlogloss:0.18474\teval-mlogloss:0.24926\n",
      "[102]\ttrain-mlogloss:0.18401\teval-mlogloss:0.24901\n",
      "[103]\ttrain-mlogloss:0.18322\teval-mlogloss:0.24889\n",
      "[104]\ttrain-mlogloss:0.18234\teval-mlogloss:0.24870\n",
      "[105]\ttrain-mlogloss:0.18153\teval-mlogloss:0.24877\n",
      "[106]\ttrain-mlogloss:0.18064\teval-mlogloss:0.24856\n",
      "[107]\ttrain-mlogloss:0.17977\teval-mlogloss:0.24854\n",
      "[108]\ttrain-mlogloss:0.17893\teval-mlogloss:0.24851\n",
      "[109]\ttrain-mlogloss:0.17808\teval-mlogloss:0.24858\n",
      "[110]\ttrain-mlogloss:0.17718\teval-mlogloss:0.24878\n",
      "[111]\ttrain-mlogloss:0.17628\teval-mlogloss:0.24878\n",
      "[112]\ttrain-mlogloss:0.17539\teval-mlogloss:0.24873\n",
      "[113]\ttrain-mlogloss:0.17443\teval-mlogloss:0.24904\n",
      "[114]\ttrain-mlogloss:0.17361\teval-mlogloss:0.24903\n",
      "[115]\ttrain-mlogloss:0.17268\teval-mlogloss:0.24894\n",
      "[116]\ttrain-mlogloss:0.17179\teval-mlogloss:0.24893\n",
      "[117]\ttrain-mlogloss:0.17107\teval-mlogloss:0.24897\n",
      "[118]\ttrain-mlogloss:0.17027\teval-mlogloss:0.24885\n",
      "[119]\ttrain-mlogloss:0.16944\teval-mlogloss:0.24899\n",
      "[120]\ttrain-mlogloss:0.16867\teval-mlogloss:0.24893\n",
      "[121]\ttrain-mlogloss:0.16789\teval-mlogloss:0.24893\n",
      "[122]\ttrain-mlogloss:0.16704\teval-mlogloss:0.24891\n",
      "[123]\ttrain-mlogloss:0.16620\teval-mlogloss:0.24897\n",
      "[124]\ttrain-mlogloss:0.16553\teval-mlogloss:0.24895\n",
      "[125]\ttrain-mlogloss:0.16477\teval-mlogloss:0.24927\n",
      "[126]\ttrain-mlogloss:0.16419\teval-mlogloss:0.24924\n",
      "[127]\ttrain-mlogloss:0.16342\teval-mlogloss:0.24923\n",
      "[128]\ttrain-mlogloss:0.16268\teval-mlogloss:0.24923\n",
      "[129]\ttrain-mlogloss:0.16207\teval-mlogloss:0.24926\n",
      "[130]\ttrain-mlogloss:0.16133\teval-mlogloss:0.24925\n",
      "[131]\ttrain-mlogloss:0.16061\teval-mlogloss:0.24940\n",
      "[132]\ttrain-mlogloss:0.15987\teval-mlogloss:0.24951\n",
      "[133]\ttrain-mlogloss:0.15908\teval-mlogloss:0.24965\n",
      "[134]\ttrain-mlogloss:0.15839\teval-mlogloss:0.24935\n",
      "[135]\ttrain-mlogloss:0.15781\teval-mlogloss:0.24941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136]\ttrain-mlogloss:0.15709\teval-mlogloss:0.24955\n",
      "[137]\ttrain-mlogloss:0.15629\teval-mlogloss:0.24956\n",
      "[138]\ttrain-mlogloss:0.15551\teval-mlogloss:0.24968\n",
      "[139]\ttrain-mlogloss:0.15487\teval-mlogloss:0.25006\n",
      "[140]\ttrain-mlogloss:0.15432\teval-mlogloss:0.24991\n",
      "[141]\ttrain-mlogloss:0.15369\teval-mlogloss:0.25002\n",
      "[142]\ttrain-mlogloss:0.15310\teval-mlogloss:0.25012\n",
      "[143]\ttrain-mlogloss:0.15220\teval-mlogloss:0.25023\n",
      "[144]\ttrain-mlogloss:0.15153\teval-mlogloss:0.25036\n",
      "[145]\ttrain-mlogloss:0.15088\teval-mlogloss:0.25058\n",
      "[146]\ttrain-mlogloss:0.15025\teval-mlogloss:0.25093\n",
      "[147]\ttrain-mlogloss:0.14969\teval-mlogloss:0.25075\n",
      "[148]\ttrain-mlogloss:0.14913\teval-mlogloss:0.25078\n",
      "[149]\ttrain-mlogloss:0.14854\teval-mlogloss:0.25113\n",
      "[150]\ttrain-mlogloss:0.14804\teval-mlogloss:0.25103\n",
      "[151]\ttrain-mlogloss:0.14735\teval-mlogloss:0.25124\n",
      "[152]\ttrain-mlogloss:0.14680\teval-mlogloss:0.25117\n",
      "[153]\ttrain-mlogloss:0.14617\teval-mlogloss:0.25116\n",
      "[154]\ttrain-mlogloss:0.14549\teval-mlogloss:0.25124\n",
      "[155]\ttrain-mlogloss:0.14494\teval-mlogloss:0.25127\n",
      "[156]\ttrain-mlogloss:0.14442\teval-mlogloss:0.25153\n",
      "[157]\ttrain-mlogloss:0.14386\teval-mlogloss:0.25133\n",
      "[158]\ttrain-mlogloss:0.14330\teval-mlogloss:0.25148\n",
      "[159]\ttrain-mlogloss:0.14281\teval-mlogloss:0.25158\n",
      "[160]\ttrain-mlogloss:0.14234\teval-mlogloss:0.25163\n",
      "[161]\ttrain-mlogloss:0.14181\teval-mlogloss:0.25192\n",
      "[162]\ttrain-mlogloss:0.14130\teval-mlogloss:0.25185\n",
      "[163]\ttrain-mlogloss:0.14081\teval-mlogloss:0.25199\n",
      "[164]\ttrain-mlogloss:0.14024\teval-mlogloss:0.25205\n",
      "[165]\ttrain-mlogloss:0.13957\teval-mlogloss:0.25226\n",
      "[166]\ttrain-mlogloss:0.13893\teval-mlogloss:0.25228\n",
      "[167]\ttrain-mlogloss:0.13842\teval-mlogloss:0.25221\n",
      "[168]\ttrain-mlogloss:0.13788\teval-mlogloss:0.25220\n",
      "[169]\ttrain-mlogloss:0.13737\teval-mlogloss:0.25241\n",
      "[170]\ttrain-mlogloss:0.13686\teval-mlogloss:0.25214\n",
      "[171]\ttrain-mlogloss:0.13641\teval-mlogloss:0.25190\n",
      "[172]\ttrain-mlogloss:0.13602\teval-mlogloss:0.25204\n",
      "[173]\ttrain-mlogloss:0.13558\teval-mlogloss:0.25184\n",
      "[174]\ttrain-mlogloss:0.13512\teval-mlogloss:0.25178\n",
      "[175]\ttrain-mlogloss:0.13472\teval-mlogloss:0.25188\n",
      "[176]\ttrain-mlogloss:0.13411\teval-mlogloss:0.25212\n",
      "[177]\ttrain-mlogloss:0.13367\teval-mlogloss:0.25215\n",
      "[178]\ttrain-mlogloss:0.13314\teval-mlogloss:0.25244\n",
      "[179]\ttrain-mlogloss:0.13267\teval-mlogloss:0.25249\n",
      "[180]\ttrain-mlogloss:0.13223\teval-mlogloss:0.25266\n",
      "[181]\ttrain-mlogloss:0.13184\teval-mlogloss:0.25274\n",
      "[182]\ttrain-mlogloss:0.13135\teval-mlogloss:0.25308\n",
      "[183]\ttrain-mlogloss:0.13089\teval-mlogloss:0.25304\n",
      "[184]\ttrain-mlogloss:0.13037\teval-mlogloss:0.25329\n",
      "[185]\ttrain-mlogloss:0.12993\teval-mlogloss:0.25342\n",
      "[186]\ttrain-mlogloss:0.12955\teval-mlogloss:0.25357\n",
      "[187]\ttrain-mlogloss:0.12914\teval-mlogloss:0.25378\n",
      "[188]\ttrain-mlogloss:0.12870\teval-mlogloss:0.25374\n",
      "[189]\ttrain-mlogloss:0.12825\teval-mlogloss:0.25392\n",
      "[190]\ttrain-mlogloss:0.12789\teval-mlogloss:0.25390\n",
      "[191]\ttrain-mlogloss:0.12750\teval-mlogloss:0.25376\n",
      "[192]\ttrain-mlogloss:0.12709\teval-mlogloss:0.25401\n",
      "[193]\ttrain-mlogloss:0.12675\teval-mlogloss:0.25426\n",
      "[194]\ttrain-mlogloss:0.12633\teval-mlogloss:0.25436\n",
      "[195]\ttrain-mlogloss:0.12595\teval-mlogloss:0.25461\n",
      "[196]\ttrain-mlogloss:0.12560\teval-mlogloss:0.25452\n",
      "[197]\ttrain-mlogloss:0.12526\teval-mlogloss:0.25458\n",
      "[198]\ttrain-mlogloss:0.12491\teval-mlogloss:0.25474\n",
      "[199]\ttrain-mlogloss:0.12462\teval-mlogloss:0.25496\n",
      "[200]\ttrain-mlogloss:0.12425\teval-mlogloss:0.25517\n",
      "[201]\ttrain-mlogloss:0.12396\teval-mlogloss:0.25530\n",
      "[202]\ttrain-mlogloss:0.12359\teval-mlogloss:0.25536\n",
      "[203]\ttrain-mlogloss:0.12321\teval-mlogloss:0.25554\n",
      "[204]\ttrain-mlogloss:0.12280\teval-mlogloss:0.25566\n",
      "[205]\ttrain-mlogloss:0.12242\teval-mlogloss:0.25559\n",
      "[206]\ttrain-mlogloss:0.12203\teval-mlogloss:0.25546\n",
      "[207]\ttrain-mlogloss:0.12162\teval-mlogloss:0.25546\n",
      "[208]\ttrain-mlogloss:0.12128\teval-mlogloss:0.25540\n",
      "Stopping. Best iteration:\n",
      "[108]\ttrain-mlogloss:0.17893\teval-mlogloss:0.24851\n",
      "\n",
      "xgb now score is: [2.4376569647714494]\n",
      "[0]\ttrain-mlogloss:0.67049\teval-mlogloss:0.67211\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.64900\teval-mlogloss:0.65198\n",
      "[2]\ttrain-mlogloss:0.62906\teval-mlogloss:0.63322\n",
      "[3]\ttrain-mlogloss:0.61001\teval-mlogloss:0.61548\n",
      "[4]\ttrain-mlogloss:0.59193\teval-mlogloss:0.59870\n",
      "[5]\ttrain-mlogloss:0.57465\teval-mlogloss:0.58285\n",
      "[6]\ttrain-mlogloss:0.55843\teval-mlogloss:0.56793\n",
      "[7]\ttrain-mlogloss:0.54290\teval-mlogloss:0.55363\n",
      "[8]\ttrain-mlogloss:0.52805\teval-mlogloss:0.54015\n",
      "[9]\ttrain-mlogloss:0.51400\teval-mlogloss:0.52701\n",
      "[10]\ttrain-mlogloss:0.50101\teval-mlogloss:0.51512\n",
      "[11]\ttrain-mlogloss:0.48817\teval-mlogloss:0.50343\n",
      "[12]\ttrain-mlogloss:0.47613\teval-mlogloss:0.49242\n",
      "[13]\ttrain-mlogloss:0.46454\teval-mlogloss:0.48206\n",
      "[14]\ttrain-mlogloss:0.45367\teval-mlogloss:0.47208\n",
      "[15]\ttrain-mlogloss:0.44321\teval-mlogloss:0.46280\n",
      "[16]\ttrain-mlogloss:0.43328\teval-mlogloss:0.45383\n",
      "[17]\ttrain-mlogloss:0.42372\teval-mlogloss:0.44532\n",
      "[18]\ttrain-mlogloss:0.41456\teval-mlogloss:0.43742\n",
      "[19]\ttrain-mlogloss:0.40586\teval-mlogloss:0.42963\n",
      "[20]\ttrain-mlogloss:0.39745\teval-mlogloss:0.42238\n",
      "[21]\ttrain-mlogloss:0.38941\teval-mlogloss:0.41557\n",
      "[22]\ttrain-mlogloss:0.38185\teval-mlogloss:0.40902\n",
      "[23]\ttrain-mlogloss:0.37460\teval-mlogloss:0.40256\n",
      "[24]\ttrain-mlogloss:0.36760\teval-mlogloss:0.39657\n",
      "[25]\ttrain-mlogloss:0.36085\teval-mlogloss:0.39082\n",
      "[26]\ttrain-mlogloss:0.35430\teval-mlogloss:0.38539\n",
      "[27]\ttrain-mlogloss:0.34802\teval-mlogloss:0.38017\n",
      "[28]\ttrain-mlogloss:0.34203\teval-mlogloss:0.37511\n",
      "[29]\ttrain-mlogloss:0.33616\teval-mlogloss:0.37036\n",
      "[30]\ttrain-mlogloss:0.33046\teval-mlogloss:0.36558\n",
      "[31]\ttrain-mlogloss:0.32508\teval-mlogloss:0.36137\n",
      "[32]\ttrain-mlogloss:0.31987\teval-mlogloss:0.35713\n",
      "[33]\ttrain-mlogloss:0.31498\teval-mlogloss:0.35329\n",
      "[34]\ttrain-mlogloss:0.31035\teval-mlogloss:0.34949\n",
      "[35]\ttrain-mlogloss:0.30583\teval-mlogloss:0.34611\n",
      "[36]\ttrain-mlogloss:0.30160\teval-mlogloss:0.34270\n",
      "[37]\ttrain-mlogloss:0.29746\teval-mlogloss:0.33941\n",
      "[38]\ttrain-mlogloss:0.29342\teval-mlogloss:0.33638\n",
      "[39]\ttrain-mlogloss:0.28950\teval-mlogloss:0.33324\n",
      "[40]\ttrain-mlogloss:0.28568\teval-mlogloss:0.33044\n",
      "[41]\ttrain-mlogloss:0.28204\teval-mlogloss:0.32793\n",
      "[42]\ttrain-mlogloss:0.27866\teval-mlogloss:0.32564\n",
      "[43]\ttrain-mlogloss:0.27546\teval-mlogloss:0.32325\n",
      "[44]\ttrain-mlogloss:0.27205\teval-mlogloss:0.32095\n",
      "[45]\ttrain-mlogloss:0.26896\teval-mlogloss:0.31886\n",
      "[46]\ttrain-mlogloss:0.26577\teval-mlogloss:0.31665\n",
      "[47]\ttrain-mlogloss:0.26280\teval-mlogloss:0.31473\n",
      "[48]\ttrain-mlogloss:0.25998\teval-mlogloss:0.31293\n",
      "[49]\ttrain-mlogloss:0.25731\teval-mlogloss:0.31116\n",
      "[50]\ttrain-mlogloss:0.25482\teval-mlogloss:0.30962\n",
      "[51]\ttrain-mlogloss:0.25240\teval-mlogloss:0.30788\n",
      "[52]\ttrain-mlogloss:0.24982\teval-mlogloss:0.30633\n",
      "[53]\ttrain-mlogloss:0.24744\teval-mlogloss:0.30506\n",
      "[54]\ttrain-mlogloss:0.24498\teval-mlogloss:0.30363\n",
      "[55]\ttrain-mlogloss:0.24255\teval-mlogloss:0.30236\n",
      "[56]\ttrain-mlogloss:0.24042\teval-mlogloss:0.30140\n",
      "[57]\ttrain-mlogloss:0.23815\teval-mlogloss:0.30002\n",
      "[58]\ttrain-mlogloss:0.23604\teval-mlogloss:0.29890\n",
      "[59]\ttrain-mlogloss:0.23386\teval-mlogloss:0.29782\n",
      "[60]\ttrain-mlogloss:0.23193\teval-mlogloss:0.29691\n",
      "[61]\ttrain-mlogloss:0.22993\teval-mlogloss:0.29597\n",
      "[62]\ttrain-mlogloss:0.22802\teval-mlogloss:0.29510\n",
      "[63]\ttrain-mlogloss:0.22612\teval-mlogloss:0.29419\n",
      "[64]\ttrain-mlogloss:0.22440\teval-mlogloss:0.29360\n",
      "[65]\ttrain-mlogloss:0.22247\teval-mlogloss:0.29303\n",
      "[66]\ttrain-mlogloss:0.22070\teval-mlogloss:0.29221\n",
      "[67]\ttrain-mlogloss:0.21918\teval-mlogloss:0.29169\n",
      "[68]\ttrain-mlogloss:0.21761\teval-mlogloss:0.29112\n",
      "[69]\ttrain-mlogloss:0.21612\teval-mlogloss:0.29043\n",
      "[70]\ttrain-mlogloss:0.21478\teval-mlogloss:0.29002\n",
      "[71]\ttrain-mlogloss:0.21331\teval-mlogloss:0.28929\n",
      "[72]\ttrain-mlogloss:0.21195\teval-mlogloss:0.28892\n",
      "[73]\ttrain-mlogloss:0.21021\teval-mlogloss:0.28848\n",
      "[74]\ttrain-mlogloss:0.20885\teval-mlogloss:0.28811\n",
      "[75]\ttrain-mlogloss:0.20743\teval-mlogloss:0.28784\n",
      "[76]\ttrain-mlogloss:0.20588\teval-mlogloss:0.28775\n",
      "[77]\ttrain-mlogloss:0.20444\teval-mlogloss:0.28754\n",
      "[78]\ttrain-mlogloss:0.20299\teval-mlogloss:0.28727\n",
      "[79]\ttrain-mlogloss:0.20177\teval-mlogloss:0.28717\n",
      "[80]\ttrain-mlogloss:0.20057\teval-mlogloss:0.28702\n",
      "[81]\ttrain-mlogloss:0.19929\teval-mlogloss:0.28680\n",
      "[82]\ttrain-mlogloss:0.19780\teval-mlogloss:0.28657\n",
      "[83]\ttrain-mlogloss:0.19657\teval-mlogloss:0.28624\n",
      "[84]\ttrain-mlogloss:0.19533\teval-mlogloss:0.28606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttrain-mlogloss:0.19415\teval-mlogloss:0.28596\n",
      "[86]\ttrain-mlogloss:0.19284\teval-mlogloss:0.28615\n",
      "[87]\ttrain-mlogloss:0.19168\teval-mlogloss:0.28626\n",
      "[88]\ttrain-mlogloss:0.19047\teval-mlogloss:0.28633\n",
      "[89]\ttrain-mlogloss:0.18930\teval-mlogloss:0.28647\n",
      "[90]\ttrain-mlogloss:0.18826\teval-mlogloss:0.28628\n",
      "[91]\ttrain-mlogloss:0.18708\teval-mlogloss:0.28624\n",
      "[92]\ttrain-mlogloss:0.18603\teval-mlogloss:0.28614\n",
      "[93]\ttrain-mlogloss:0.18473\teval-mlogloss:0.28619\n",
      "[94]\ttrain-mlogloss:0.18369\teval-mlogloss:0.28631\n",
      "[95]\ttrain-mlogloss:0.18267\teval-mlogloss:0.28618\n",
      "[96]\ttrain-mlogloss:0.18168\teval-mlogloss:0.28623\n",
      "[97]\ttrain-mlogloss:0.18058\teval-mlogloss:0.28632\n",
      "[98]\ttrain-mlogloss:0.17965\teval-mlogloss:0.28636\n",
      "[99]\ttrain-mlogloss:0.17876\teval-mlogloss:0.28643\n",
      "[100]\ttrain-mlogloss:0.17782\teval-mlogloss:0.28659\n",
      "[101]\ttrain-mlogloss:0.17674\teval-mlogloss:0.28680\n",
      "[102]\ttrain-mlogloss:0.17578\teval-mlogloss:0.28695\n",
      "[103]\ttrain-mlogloss:0.17480\teval-mlogloss:0.28739\n",
      "[104]\ttrain-mlogloss:0.17385\teval-mlogloss:0.28779\n",
      "[105]\ttrain-mlogloss:0.17302\teval-mlogloss:0.28804\n",
      "[106]\ttrain-mlogloss:0.17218\teval-mlogloss:0.28834\n",
      "[107]\ttrain-mlogloss:0.17127\teval-mlogloss:0.28870\n",
      "[108]\ttrain-mlogloss:0.17036\teval-mlogloss:0.28902\n",
      "[109]\ttrain-mlogloss:0.16933\teval-mlogloss:0.28906\n",
      "[110]\ttrain-mlogloss:0.16841\teval-mlogloss:0.28927\n",
      "[111]\ttrain-mlogloss:0.16764\teval-mlogloss:0.28930\n",
      "[112]\ttrain-mlogloss:0.16684\teval-mlogloss:0.28949\n",
      "[113]\ttrain-mlogloss:0.16605\teval-mlogloss:0.28961\n",
      "[114]\ttrain-mlogloss:0.16527\teval-mlogloss:0.28994\n",
      "[115]\ttrain-mlogloss:0.16440\teval-mlogloss:0.28961\n",
      "[116]\ttrain-mlogloss:0.16371\teval-mlogloss:0.28964\n",
      "[117]\ttrain-mlogloss:0.16295\teval-mlogloss:0.28978\n",
      "[118]\ttrain-mlogloss:0.16234\teval-mlogloss:0.29000\n",
      "[119]\ttrain-mlogloss:0.16146\teval-mlogloss:0.29027\n",
      "[120]\ttrain-mlogloss:0.16060\teval-mlogloss:0.29048\n",
      "[121]\ttrain-mlogloss:0.15978\teval-mlogloss:0.29072\n",
      "[122]\ttrain-mlogloss:0.15897\teval-mlogloss:0.29093\n",
      "[123]\ttrain-mlogloss:0.15821\teval-mlogloss:0.29120\n",
      "[124]\ttrain-mlogloss:0.15756\teval-mlogloss:0.29149\n",
      "[125]\ttrain-mlogloss:0.15686\teval-mlogloss:0.29174\n",
      "[126]\ttrain-mlogloss:0.15621\teval-mlogloss:0.29192\n",
      "[127]\ttrain-mlogloss:0.15561\teval-mlogloss:0.29245\n",
      "[128]\ttrain-mlogloss:0.15479\teval-mlogloss:0.29270\n",
      "[129]\ttrain-mlogloss:0.15399\teval-mlogloss:0.29295\n",
      "[130]\ttrain-mlogloss:0.15324\teval-mlogloss:0.29338\n",
      "[131]\ttrain-mlogloss:0.15260\teval-mlogloss:0.29377\n",
      "[132]\ttrain-mlogloss:0.15193\teval-mlogloss:0.29390\n",
      "[133]\ttrain-mlogloss:0.15129\teval-mlogloss:0.29395\n",
      "[134]\ttrain-mlogloss:0.15068\teval-mlogloss:0.29406\n",
      "[135]\ttrain-mlogloss:0.14995\teval-mlogloss:0.29426\n",
      "[136]\ttrain-mlogloss:0.14938\teval-mlogloss:0.29455\n",
      "[137]\ttrain-mlogloss:0.14874\teval-mlogloss:0.29499\n",
      "[138]\ttrain-mlogloss:0.14806\teval-mlogloss:0.29526\n",
      "[139]\ttrain-mlogloss:0.14739\teval-mlogloss:0.29535\n",
      "[140]\ttrain-mlogloss:0.14669\teval-mlogloss:0.29557\n",
      "[141]\ttrain-mlogloss:0.14601\teval-mlogloss:0.29602\n",
      "[142]\ttrain-mlogloss:0.14524\teval-mlogloss:0.29629\n",
      "[143]\ttrain-mlogloss:0.14469\teval-mlogloss:0.29672\n",
      "[144]\ttrain-mlogloss:0.14416\teval-mlogloss:0.29688\n",
      "[145]\ttrain-mlogloss:0.14365\teval-mlogloss:0.29745\n",
      "[146]\ttrain-mlogloss:0.14309\teval-mlogloss:0.29774\n",
      "[147]\ttrain-mlogloss:0.14244\teval-mlogloss:0.29788\n",
      "[148]\ttrain-mlogloss:0.14170\teval-mlogloss:0.29818\n",
      "[149]\ttrain-mlogloss:0.14130\teval-mlogloss:0.29824\n",
      "[150]\ttrain-mlogloss:0.14079\teval-mlogloss:0.29868\n",
      "[151]\ttrain-mlogloss:0.14027\teval-mlogloss:0.29891\n",
      "[152]\ttrain-mlogloss:0.13978\teval-mlogloss:0.29901\n",
      "[153]\ttrain-mlogloss:0.13914\teval-mlogloss:0.29914\n",
      "[154]\ttrain-mlogloss:0.13857\teval-mlogloss:0.29958\n",
      "[155]\ttrain-mlogloss:0.13800\teval-mlogloss:0.29983\n",
      "[156]\ttrain-mlogloss:0.13734\teval-mlogloss:0.30018\n",
      "[157]\ttrain-mlogloss:0.13673\teval-mlogloss:0.30030\n",
      "[158]\ttrain-mlogloss:0.13620\teval-mlogloss:0.30059\n",
      "[159]\ttrain-mlogloss:0.13560\teval-mlogloss:0.30107\n",
      "[160]\ttrain-mlogloss:0.13507\teval-mlogloss:0.30146\n",
      "[161]\ttrain-mlogloss:0.13447\teval-mlogloss:0.30187\n",
      "[162]\ttrain-mlogloss:0.13389\teval-mlogloss:0.30243\n",
      "[163]\ttrain-mlogloss:0.13339\teval-mlogloss:0.30265\n",
      "[164]\ttrain-mlogloss:0.13289\teval-mlogloss:0.30275\n",
      "[165]\ttrain-mlogloss:0.13231\teval-mlogloss:0.30308\n",
      "[166]\ttrain-mlogloss:0.13173\teval-mlogloss:0.30304\n",
      "[167]\ttrain-mlogloss:0.13133\teval-mlogloss:0.30301\n",
      "[168]\ttrain-mlogloss:0.13075\teval-mlogloss:0.30310\n",
      "[169]\ttrain-mlogloss:0.13020\teval-mlogloss:0.30364\n",
      "[170]\ttrain-mlogloss:0.12974\teval-mlogloss:0.30391\n",
      "[171]\ttrain-mlogloss:0.12928\teval-mlogloss:0.30397\n",
      "[172]\ttrain-mlogloss:0.12893\teval-mlogloss:0.30431\n",
      "[173]\ttrain-mlogloss:0.12840\teval-mlogloss:0.30462\n",
      "[174]\ttrain-mlogloss:0.12789\teval-mlogloss:0.30502\n",
      "[175]\ttrain-mlogloss:0.12743\teval-mlogloss:0.30524\n",
      "[176]\ttrain-mlogloss:0.12694\teval-mlogloss:0.30543\n",
      "[177]\ttrain-mlogloss:0.12635\teval-mlogloss:0.30582\n",
      "[178]\ttrain-mlogloss:0.12597\teval-mlogloss:0.30606\n",
      "[179]\ttrain-mlogloss:0.12556\teval-mlogloss:0.30628\n",
      "[180]\ttrain-mlogloss:0.12510\teval-mlogloss:0.30660\n",
      "[181]\ttrain-mlogloss:0.12470\teval-mlogloss:0.30673\n",
      "[182]\ttrain-mlogloss:0.12438\teval-mlogloss:0.30692\n",
      "[183]\ttrain-mlogloss:0.12392\teval-mlogloss:0.30707\n",
      "[184]\ttrain-mlogloss:0.12360\teval-mlogloss:0.30733\n",
      "[185]\ttrain-mlogloss:0.12323\teval-mlogloss:0.30761\n",
      "Stopping. Best iteration:\n",
      "[85]\ttrain-mlogloss:0.19415\teval-mlogloss:0.28596\n",
      "\n",
      "xgb now score is: [2.4376569647714494, 2.2161756049096586]\n",
      "[0]\ttrain-mlogloss:0.67049\teval-mlogloss:0.67113\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.64919\teval-mlogloss:0.65068\n",
      "[2]\ttrain-mlogloss:0.62924\teval-mlogloss:0.63192\n",
      "[3]\ttrain-mlogloss:0.61047\teval-mlogloss:0.61392\n",
      "[4]\ttrain-mlogloss:0.59259\teval-mlogloss:0.59698\n",
      "[5]\ttrain-mlogloss:0.57553\teval-mlogloss:0.58064\n",
      "[6]\ttrain-mlogloss:0.55961\teval-mlogloss:0.56527\n",
      "[7]\ttrain-mlogloss:0.54404\teval-mlogloss:0.55032\n",
      "[8]\ttrain-mlogloss:0.52933\teval-mlogloss:0.53634\n",
      "[9]\ttrain-mlogloss:0.51538\teval-mlogloss:0.52326\n",
      "[10]\ttrain-mlogloss:0.50219\teval-mlogloss:0.51082\n",
      "[11]\ttrain-mlogloss:0.48957\teval-mlogloss:0.49915\n",
      "[12]\ttrain-mlogloss:0.47782\teval-mlogloss:0.48811\n",
      "[13]\ttrain-mlogloss:0.46641\teval-mlogloss:0.47717\n",
      "[14]\ttrain-mlogloss:0.45545\teval-mlogloss:0.46683\n",
      "[15]\ttrain-mlogloss:0.44493\teval-mlogloss:0.45697\n",
      "[16]\ttrain-mlogloss:0.43495\teval-mlogloss:0.44772\n",
      "[17]\ttrain-mlogloss:0.42552\teval-mlogloss:0.43893\n",
      "[18]\ttrain-mlogloss:0.41653\teval-mlogloss:0.43073\n",
      "[19]\ttrain-mlogloss:0.40797\teval-mlogloss:0.42273\n",
      "[20]\ttrain-mlogloss:0.39967\teval-mlogloss:0.41511\n",
      "[21]\ttrain-mlogloss:0.39191\teval-mlogloss:0.40796\n",
      "[22]\ttrain-mlogloss:0.38429\teval-mlogloss:0.40098\n",
      "[23]\ttrain-mlogloss:0.37712\teval-mlogloss:0.39451\n",
      "[24]\ttrain-mlogloss:0.37023\teval-mlogloss:0.38824\n",
      "[25]\ttrain-mlogloss:0.36362\teval-mlogloss:0.38207\n",
      "[26]\ttrain-mlogloss:0.35723\teval-mlogloss:0.37617\n",
      "[27]\ttrain-mlogloss:0.35108\teval-mlogloss:0.37067\n",
      "[28]\ttrain-mlogloss:0.34514\teval-mlogloss:0.36540\n",
      "[29]\ttrain-mlogloss:0.33946\teval-mlogloss:0.36052\n",
      "[30]\ttrain-mlogloss:0.33392\teval-mlogloss:0.35565\n",
      "[31]\ttrain-mlogloss:0.32875\teval-mlogloss:0.35112\n",
      "[32]\ttrain-mlogloss:0.32374\teval-mlogloss:0.34679\n",
      "[33]\ttrain-mlogloss:0.31903\teval-mlogloss:0.34273\n",
      "[34]\ttrain-mlogloss:0.31433\teval-mlogloss:0.33845\n",
      "[35]\ttrain-mlogloss:0.30989\teval-mlogloss:0.33463\n",
      "[36]\ttrain-mlogloss:0.30559\teval-mlogloss:0.33093\n",
      "[37]\ttrain-mlogloss:0.30147\teval-mlogloss:0.32733\n",
      "[38]\ttrain-mlogloss:0.29754\teval-mlogloss:0.32398\n",
      "[39]\ttrain-mlogloss:0.29377\teval-mlogloss:0.32070\n",
      "[40]\ttrain-mlogloss:0.29021\teval-mlogloss:0.31766\n",
      "[41]\ttrain-mlogloss:0.28664\teval-mlogloss:0.31491\n",
      "[42]\ttrain-mlogloss:0.28330\teval-mlogloss:0.31207\n",
      "[43]\ttrain-mlogloss:0.28014\teval-mlogloss:0.30948\n",
      "[44]\ttrain-mlogloss:0.27705\teval-mlogloss:0.30692\n",
      "[45]\ttrain-mlogloss:0.27402\teval-mlogloss:0.30462\n",
      "[46]\ttrain-mlogloss:0.27121\teval-mlogloss:0.30239\n",
      "[47]\ttrain-mlogloss:0.26845\teval-mlogloss:0.30027\n",
      "[48]\ttrain-mlogloss:0.26553\teval-mlogloss:0.29817\n",
      "[49]\ttrain-mlogloss:0.26306\teval-mlogloss:0.29614\n",
      "[50]\ttrain-mlogloss:0.26035\teval-mlogloss:0.29420\n",
      "[51]\ttrain-mlogloss:0.25794\teval-mlogloss:0.29247\n",
      "[52]\ttrain-mlogloss:0.25561\teval-mlogloss:0.29072\n",
      "[53]\ttrain-mlogloss:0.25308\teval-mlogloss:0.28907\n",
      "[54]\ttrain-mlogloss:0.25074\teval-mlogloss:0.28764\n",
      "[55]\ttrain-mlogloss:0.24848\teval-mlogloss:0.28615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56]\ttrain-mlogloss:0.24643\teval-mlogloss:0.28475\n",
      "[57]\ttrain-mlogloss:0.24439\teval-mlogloss:0.28343\n",
      "[58]\ttrain-mlogloss:0.24220\teval-mlogloss:0.28229\n",
      "[59]\ttrain-mlogloss:0.24014\teval-mlogloss:0.28113\n",
      "[60]\ttrain-mlogloss:0.23819\teval-mlogloss:0.28004\n",
      "[61]\ttrain-mlogloss:0.23638\teval-mlogloss:0.27887\n",
      "[62]\ttrain-mlogloss:0.23461\teval-mlogloss:0.27762\n",
      "[63]\ttrain-mlogloss:0.23297\teval-mlogloss:0.27676\n",
      "[64]\ttrain-mlogloss:0.23134\teval-mlogloss:0.27580\n",
      "[65]\ttrain-mlogloss:0.22986\teval-mlogloss:0.27489\n",
      "[66]\ttrain-mlogloss:0.22819\teval-mlogloss:0.27425\n",
      "[67]\ttrain-mlogloss:0.22662\teval-mlogloss:0.27347\n",
      "[68]\ttrain-mlogloss:0.22509\teval-mlogloss:0.27270\n",
      "[69]\ttrain-mlogloss:0.22364\teval-mlogloss:0.27207\n",
      "[70]\ttrain-mlogloss:0.22213\teval-mlogloss:0.27149\n",
      "[71]\ttrain-mlogloss:0.22063\teval-mlogloss:0.27079\n",
      "[72]\ttrain-mlogloss:0.21918\teval-mlogloss:0.27005\n",
      "[73]\ttrain-mlogloss:0.21780\teval-mlogloss:0.26939\n",
      "[74]\ttrain-mlogloss:0.21630\teval-mlogloss:0.26874\n",
      "[75]\ttrain-mlogloss:0.21504\teval-mlogloss:0.26832\n",
      "[76]\ttrain-mlogloss:0.21385\teval-mlogloss:0.26795\n",
      "[77]\ttrain-mlogloss:0.21232\teval-mlogloss:0.26761\n",
      "[78]\ttrain-mlogloss:0.21116\teval-mlogloss:0.26726\n",
      "[79]\ttrain-mlogloss:0.21004\teval-mlogloss:0.26680\n",
      "[80]\ttrain-mlogloss:0.20875\teval-mlogloss:0.26645\n",
      "[81]\ttrain-mlogloss:0.20741\teval-mlogloss:0.26599\n",
      "[82]\ttrain-mlogloss:0.20620\teval-mlogloss:0.26537\n",
      "[83]\ttrain-mlogloss:0.20503\teval-mlogloss:0.26505\n",
      "[84]\ttrain-mlogloss:0.20380\teval-mlogloss:0.26453\n",
      "[85]\ttrain-mlogloss:0.20260\teval-mlogloss:0.26430\n",
      "[86]\ttrain-mlogloss:0.20137\teval-mlogloss:0.26412\n",
      "[87]\ttrain-mlogloss:0.20034\teval-mlogloss:0.26381\n",
      "[88]\ttrain-mlogloss:0.19920\teval-mlogloss:0.26362\n",
      "[89]\ttrain-mlogloss:0.19798\teval-mlogloss:0.26347\n",
      "[90]\ttrain-mlogloss:0.19676\teval-mlogloss:0.26320\n",
      "[91]\ttrain-mlogloss:0.19560\teval-mlogloss:0.26329\n",
      "[92]\ttrain-mlogloss:0.19460\teval-mlogloss:0.26338\n",
      "[93]\ttrain-mlogloss:0.19351\teval-mlogloss:0.26332\n",
      "[94]\ttrain-mlogloss:0.19249\teval-mlogloss:0.26338\n",
      "[95]\ttrain-mlogloss:0.19129\teval-mlogloss:0.26313\n",
      "[96]\ttrain-mlogloss:0.19023\teval-mlogloss:0.26307\n",
      "[97]\ttrain-mlogloss:0.18921\teval-mlogloss:0.26283\n",
      "[98]\ttrain-mlogloss:0.18830\teval-mlogloss:0.26265\n",
      "[99]\ttrain-mlogloss:0.18750\teval-mlogloss:0.26238\n",
      "[100]\ttrain-mlogloss:0.18651\teval-mlogloss:0.26220\n",
      "[101]\ttrain-mlogloss:0.18575\teval-mlogloss:0.26218\n",
      "[102]\ttrain-mlogloss:0.18481\teval-mlogloss:0.26200\n",
      "[103]\ttrain-mlogloss:0.18394\teval-mlogloss:0.26177\n",
      "[104]\ttrain-mlogloss:0.18301\teval-mlogloss:0.26159\n",
      "[105]\ttrain-mlogloss:0.18209\teval-mlogloss:0.26128\n",
      "[106]\ttrain-mlogloss:0.18136\teval-mlogloss:0.26115\n",
      "[107]\ttrain-mlogloss:0.18031\teval-mlogloss:0.26125\n",
      "[108]\ttrain-mlogloss:0.17944\teval-mlogloss:0.26128\n",
      "[109]\ttrain-mlogloss:0.17849\teval-mlogloss:0.26111\n",
      "[110]\ttrain-mlogloss:0.17777\teval-mlogloss:0.26115\n",
      "[111]\ttrain-mlogloss:0.17698\teval-mlogloss:0.26118\n",
      "[112]\ttrain-mlogloss:0.17609\teval-mlogloss:0.26141\n",
      "[113]\ttrain-mlogloss:0.17531\teval-mlogloss:0.26155\n",
      "[114]\ttrain-mlogloss:0.17443\teval-mlogloss:0.26173\n",
      "[115]\ttrain-mlogloss:0.17358\teval-mlogloss:0.26175\n",
      "[116]\ttrain-mlogloss:0.17284\teval-mlogloss:0.26171\n",
      "[117]\ttrain-mlogloss:0.17200\teval-mlogloss:0.26183\n",
      "[118]\ttrain-mlogloss:0.17110\teval-mlogloss:0.26193\n",
      "[119]\ttrain-mlogloss:0.17033\teval-mlogloss:0.26211\n",
      "[120]\ttrain-mlogloss:0.16946\teval-mlogloss:0.26203\n",
      "[121]\ttrain-mlogloss:0.16858\teval-mlogloss:0.26221\n",
      "[122]\ttrain-mlogloss:0.16775\teval-mlogloss:0.26189\n",
      "[123]\ttrain-mlogloss:0.16697\teval-mlogloss:0.26182\n",
      "[124]\ttrain-mlogloss:0.16625\teval-mlogloss:0.26190\n",
      "[125]\ttrain-mlogloss:0.16545\teval-mlogloss:0.26199\n",
      "[126]\ttrain-mlogloss:0.16469\teval-mlogloss:0.26217\n",
      "[127]\ttrain-mlogloss:0.16389\teval-mlogloss:0.26231\n",
      "[128]\ttrain-mlogloss:0.16318\teval-mlogloss:0.26242\n",
      "[129]\ttrain-mlogloss:0.16263\teval-mlogloss:0.26235\n",
      "[130]\ttrain-mlogloss:0.16195\teval-mlogloss:0.26233\n",
      "[131]\ttrain-mlogloss:0.16121\teval-mlogloss:0.26260\n",
      "[132]\ttrain-mlogloss:0.16053\teval-mlogloss:0.26264\n",
      "[133]\ttrain-mlogloss:0.15984\teval-mlogloss:0.26255\n",
      "[134]\ttrain-mlogloss:0.15908\teval-mlogloss:0.26278\n",
      "[135]\ttrain-mlogloss:0.15845\teval-mlogloss:0.26293\n",
      "[136]\ttrain-mlogloss:0.15785\teval-mlogloss:0.26282\n",
      "[137]\ttrain-mlogloss:0.15707\teval-mlogloss:0.26249\n",
      "[138]\ttrain-mlogloss:0.15627\teval-mlogloss:0.26262\n",
      "[139]\ttrain-mlogloss:0.15560\teval-mlogloss:0.26266\n",
      "[140]\ttrain-mlogloss:0.15493\teval-mlogloss:0.26259\n",
      "[141]\ttrain-mlogloss:0.15422\teval-mlogloss:0.26245\n",
      "[142]\ttrain-mlogloss:0.15358\teval-mlogloss:0.26239\n",
      "[143]\ttrain-mlogloss:0.15301\teval-mlogloss:0.26251\n",
      "[144]\ttrain-mlogloss:0.15246\teval-mlogloss:0.26266\n",
      "[145]\ttrain-mlogloss:0.15174\teval-mlogloss:0.26294\n",
      "[146]\ttrain-mlogloss:0.15131\teval-mlogloss:0.26285\n",
      "[147]\ttrain-mlogloss:0.15079\teval-mlogloss:0.26307\n",
      "[148]\ttrain-mlogloss:0.15024\teval-mlogloss:0.26290\n",
      "[149]\ttrain-mlogloss:0.14968\teval-mlogloss:0.26304\n",
      "[150]\ttrain-mlogloss:0.14903\teval-mlogloss:0.26325\n",
      "[151]\ttrain-mlogloss:0.14839\teval-mlogloss:0.26304\n",
      "[152]\ttrain-mlogloss:0.14772\teval-mlogloss:0.26295\n",
      "[153]\ttrain-mlogloss:0.14707\teval-mlogloss:0.26281\n",
      "[154]\ttrain-mlogloss:0.14630\teval-mlogloss:0.26283\n",
      "[155]\ttrain-mlogloss:0.14568\teval-mlogloss:0.26290\n",
      "[156]\ttrain-mlogloss:0.14502\teval-mlogloss:0.26286\n",
      "[157]\ttrain-mlogloss:0.14454\teval-mlogloss:0.26280\n",
      "[158]\ttrain-mlogloss:0.14400\teval-mlogloss:0.26258\n",
      "[159]\ttrain-mlogloss:0.14351\teval-mlogloss:0.26276\n",
      "[160]\ttrain-mlogloss:0.14297\teval-mlogloss:0.26282\n",
      "[161]\ttrain-mlogloss:0.14247\teval-mlogloss:0.26312\n",
      "[162]\ttrain-mlogloss:0.14209\teval-mlogloss:0.26302\n",
      "[163]\ttrain-mlogloss:0.14157\teval-mlogloss:0.26314\n",
      "[164]\ttrain-mlogloss:0.14089\teval-mlogloss:0.26321\n",
      "[165]\ttrain-mlogloss:0.14050\teval-mlogloss:0.26340\n",
      "[166]\ttrain-mlogloss:0.13991\teval-mlogloss:0.26319\n",
      "[167]\ttrain-mlogloss:0.13935\teval-mlogloss:0.26333\n",
      "[168]\ttrain-mlogloss:0.13881\teval-mlogloss:0.26320\n",
      "[169]\ttrain-mlogloss:0.13824\teval-mlogloss:0.26295\n",
      "[170]\ttrain-mlogloss:0.13772\teval-mlogloss:0.26292\n",
      "[171]\ttrain-mlogloss:0.13728\teval-mlogloss:0.26300\n",
      "[172]\ttrain-mlogloss:0.13679\teval-mlogloss:0.26330\n",
      "[173]\ttrain-mlogloss:0.13626\teval-mlogloss:0.26326\n",
      "[174]\ttrain-mlogloss:0.13586\teval-mlogloss:0.26330\n",
      "[175]\ttrain-mlogloss:0.13541\teval-mlogloss:0.26331\n",
      "[176]\ttrain-mlogloss:0.13493\teval-mlogloss:0.26333\n",
      "[177]\ttrain-mlogloss:0.13446\teval-mlogloss:0.26325\n",
      "[178]\ttrain-mlogloss:0.13395\teval-mlogloss:0.26328\n",
      "[179]\ttrain-mlogloss:0.13346\teval-mlogloss:0.26339\n",
      "[180]\ttrain-mlogloss:0.13313\teval-mlogloss:0.26335\n",
      "[181]\ttrain-mlogloss:0.13277\teval-mlogloss:0.26354\n",
      "[182]\ttrain-mlogloss:0.13239\teval-mlogloss:0.26350\n",
      "[183]\ttrain-mlogloss:0.13190\teval-mlogloss:0.26358\n",
      "[184]\ttrain-mlogloss:0.13149\teval-mlogloss:0.26368\n",
      "[185]\ttrain-mlogloss:0.13099\teval-mlogloss:0.26381\n",
      "[186]\ttrain-mlogloss:0.13062\teval-mlogloss:0.26404\n",
      "[187]\ttrain-mlogloss:0.13012\teval-mlogloss:0.26387\n",
      "[188]\ttrain-mlogloss:0.12957\teval-mlogloss:0.26421\n",
      "[189]\ttrain-mlogloss:0.12921\teval-mlogloss:0.26420\n",
      "[190]\ttrain-mlogloss:0.12865\teval-mlogloss:0.26435\n",
      "[191]\ttrain-mlogloss:0.12820\teval-mlogloss:0.26448\n",
      "[192]\ttrain-mlogloss:0.12785\teval-mlogloss:0.26449\n",
      "[193]\ttrain-mlogloss:0.12742\teval-mlogloss:0.26464\n",
      "[194]\ttrain-mlogloss:0.12693\teval-mlogloss:0.26499\n",
      "[195]\ttrain-mlogloss:0.12648\teval-mlogloss:0.26506\n",
      "[196]\ttrain-mlogloss:0.12603\teval-mlogloss:0.26508\n",
      "[197]\ttrain-mlogloss:0.12561\teval-mlogloss:0.26528\n",
      "[198]\ttrain-mlogloss:0.12521\teval-mlogloss:0.26537\n",
      "[199]\ttrain-mlogloss:0.12482\teval-mlogloss:0.26520\n",
      "[200]\ttrain-mlogloss:0.12441\teval-mlogloss:0.26531\n",
      "[201]\ttrain-mlogloss:0.12399\teval-mlogloss:0.26531\n",
      "[202]\ttrain-mlogloss:0.12356\teval-mlogloss:0.26554\n",
      "[203]\ttrain-mlogloss:0.12318\teval-mlogloss:0.26580\n",
      "[204]\ttrain-mlogloss:0.12276\teval-mlogloss:0.26589\n",
      "[205]\ttrain-mlogloss:0.12237\teval-mlogloss:0.26600\n",
      "[206]\ttrain-mlogloss:0.12191\teval-mlogloss:0.26610\n",
      "[207]\ttrain-mlogloss:0.12147\teval-mlogloss:0.26609\n",
      "[208]\ttrain-mlogloss:0.12114\teval-mlogloss:0.26628\n",
      "[209]\ttrain-mlogloss:0.12078\teval-mlogloss:0.26626\n",
      "Stopping. Best iteration:\n",
      "[109]\ttrain-mlogloss:0.17849\teval-mlogloss:0.26111\n",
      "\n",
      "xgb now score is: [2.4376569647714494, 2.2161756049096586, 2.4777412121277305]\n",
      "[0]\ttrain-mlogloss:0.67111\teval-mlogloss:0.67074\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.65030\teval-mlogloss:0.64960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-mlogloss:0.63069\teval-mlogloss:0.62953\n",
      "[3]\ttrain-mlogloss:0.61226\teval-mlogloss:0.61074\n",
      "[4]\ttrain-mlogloss:0.59477\teval-mlogloss:0.59300\n",
      "[5]\ttrain-mlogloss:0.57825\teval-mlogloss:0.57589\n",
      "[6]\ttrain-mlogloss:0.56270\teval-mlogloss:0.56027\n",
      "[7]\ttrain-mlogloss:0.54773\teval-mlogloss:0.54506\n",
      "[8]\ttrain-mlogloss:0.53347\teval-mlogloss:0.53067\n",
      "[9]\ttrain-mlogloss:0.51998\teval-mlogloss:0.51676\n",
      "[10]\ttrain-mlogloss:0.50721\teval-mlogloss:0.50389\n",
      "[11]\ttrain-mlogloss:0.49504\teval-mlogloss:0.49131\n",
      "[12]\ttrain-mlogloss:0.48332\teval-mlogloss:0.47934\n",
      "[13]\ttrain-mlogloss:0.47233\teval-mlogloss:0.46805\n",
      "[14]\ttrain-mlogloss:0.46167\teval-mlogloss:0.45712\n",
      "[15]\ttrain-mlogloss:0.45168\teval-mlogloss:0.44692\n",
      "[16]\ttrain-mlogloss:0.44209\teval-mlogloss:0.43709\n",
      "[17]\ttrain-mlogloss:0.43294\teval-mlogloss:0.42783\n",
      "[18]\ttrain-mlogloss:0.42416\teval-mlogloss:0.41864\n",
      "[19]\ttrain-mlogloss:0.41564\teval-mlogloss:0.41034\n",
      "[20]\ttrain-mlogloss:0.40765\teval-mlogloss:0.40206\n",
      "[21]\ttrain-mlogloss:0.39981\teval-mlogloss:0.39410\n",
      "[22]\ttrain-mlogloss:0.39242\teval-mlogloss:0.38675\n",
      "[23]\ttrain-mlogloss:0.38508\teval-mlogloss:0.37939\n",
      "[24]\ttrain-mlogloss:0.37836\teval-mlogloss:0.37258\n",
      "[25]\ttrain-mlogloss:0.37175\teval-mlogloss:0.36616\n",
      "[26]\ttrain-mlogloss:0.36551\teval-mlogloss:0.36001\n",
      "[27]\ttrain-mlogloss:0.35946\teval-mlogloss:0.35393\n",
      "[28]\ttrain-mlogloss:0.35366\teval-mlogloss:0.34818\n",
      "[29]\ttrain-mlogloss:0.34824\teval-mlogloss:0.34262\n",
      "[30]\ttrain-mlogloss:0.34293\teval-mlogloss:0.33741\n",
      "[31]\ttrain-mlogloss:0.33787\teval-mlogloss:0.33225\n",
      "[32]\ttrain-mlogloss:0.33290\teval-mlogloss:0.32742\n",
      "[33]\ttrain-mlogloss:0.32818\teval-mlogloss:0.32251\n",
      "[34]\ttrain-mlogloss:0.32367\teval-mlogloss:0.31822\n",
      "[35]\ttrain-mlogloss:0.31919\teval-mlogloss:0.31367\n",
      "[36]\ttrain-mlogloss:0.31478\teval-mlogloss:0.30971\n",
      "[37]\ttrain-mlogloss:0.31067\teval-mlogloss:0.30590\n",
      "[38]\ttrain-mlogloss:0.30672\teval-mlogloss:0.30208\n",
      "[39]\ttrain-mlogloss:0.30288\teval-mlogloss:0.29831\n",
      "[40]\ttrain-mlogloss:0.29934\teval-mlogloss:0.29500\n",
      "[41]\ttrain-mlogloss:0.29576\teval-mlogloss:0.29154\n",
      "[42]\ttrain-mlogloss:0.29253\teval-mlogloss:0.28817\n",
      "[43]\ttrain-mlogloss:0.28925\teval-mlogloss:0.28518\n",
      "[44]\ttrain-mlogloss:0.28604\teval-mlogloss:0.28223\n",
      "[45]\ttrain-mlogloss:0.28299\teval-mlogloss:0.27897\n",
      "[46]\ttrain-mlogloss:0.28010\teval-mlogloss:0.27629\n",
      "[47]\ttrain-mlogloss:0.27721\teval-mlogloss:0.27368\n",
      "[48]\ttrain-mlogloss:0.27435\teval-mlogloss:0.27133\n",
      "[49]\ttrain-mlogloss:0.27172\teval-mlogloss:0.26895\n",
      "[50]\ttrain-mlogloss:0.26912\teval-mlogloss:0.26667\n",
      "[51]\ttrain-mlogloss:0.26655\teval-mlogloss:0.26443\n",
      "[52]\ttrain-mlogloss:0.26398\teval-mlogloss:0.26214\n",
      "[53]\ttrain-mlogloss:0.26171\teval-mlogloss:0.26009\n",
      "[54]\ttrain-mlogloss:0.25932\teval-mlogloss:0.25823\n",
      "[55]\ttrain-mlogloss:0.25698\teval-mlogloss:0.25612\n",
      "[56]\ttrain-mlogloss:0.25487\teval-mlogloss:0.25422\n",
      "[57]\ttrain-mlogloss:0.25277\teval-mlogloss:0.25231\n",
      "[58]\ttrain-mlogloss:0.25067\teval-mlogloss:0.25050\n",
      "[59]\ttrain-mlogloss:0.24873\teval-mlogloss:0.24890\n",
      "[60]\ttrain-mlogloss:0.24673\teval-mlogloss:0.24722\n",
      "[61]\ttrain-mlogloss:0.24463\teval-mlogloss:0.24572\n",
      "[62]\ttrain-mlogloss:0.24276\teval-mlogloss:0.24396\n",
      "[63]\ttrain-mlogloss:0.24099\teval-mlogloss:0.24243\n",
      "[64]\ttrain-mlogloss:0.23918\teval-mlogloss:0.24089\n",
      "[65]\ttrain-mlogloss:0.23762\teval-mlogloss:0.23962\n",
      "[66]\ttrain-mlogloss:0.23574\teval-mlogloss:0.23851\n",
      "[67]\ttrain-mlogloss:0.23397\teval-mlogloss:0.23736\n",
      "[68]\ttrain-mlogloss:0.23243\teval-mlogloss:0.23637\n",
      "[69]\ttrain-mlogloss:0.23059\teval-mlogloss:0.23555\n",
      "[70]\ttrain-mlogloss:0.22926\teval-mlogloss:0.23440\n",
      "[71]\ttrain-mlogloss:0.22771\teval-mlogloss:0.23349\n",
      "[72]\ttrain-mlogloss:0.22651\teval-mlogloss:0.23259\n",
      "[73]\ttrain-mlogloss:0.22518\teval-mlogloss:0.23160\n",
      "[74]\ttrain-mlogloss:0.22355\teval-mlogloss:0.23051\n",
      "[75]\ttrain-mlogloss:0.22195\teval-mlogloss:0.22975\n",
      "[76]\ttrain-mlogloss:0.22044\teval-mlogloss:0.22909\n",
      "[77]\ttrain-mlogloss:0.21902\teval-mlogloss:0.22835\n",
      "[78]\ttrain-mlogloss:0.21781\teval-mlogloss:0.22769\n",
      "[79]\ttrain-mlogloss:0.21648\teval-mlogloss:0.22670\n",
      "[80]\ttrain-mlogloss:0.21545\teval-mlogloss:0.22609\n",
      "[81]\ttrain-mlogloss:0.21442\teval-mlogloss:0.22543\n",
      "[82]\ttrain-mlogloss:0.21311\teval-mlogloss:0.22461\n",
      "[83]\ttrain-mlogloss:0.21194\teval-mlogloss:0.22407\n",
      "[84]\ttrain-mlogloss:0.21080\teval-mlogloss:0.22350\n",
      "[85]\ttrain-mlogloss:0.20956\teval-mlogloss:0.22298\n",
      "[86]\ttrain-mlogloss:0.20849\teval-mlogloss:0.22247\n",
      "[87]\ttrain-mlogloss:0.20710\teval-mlogloss:0.22221\n",
      "[88]\ttrain-mlogloss:0.20619\teval-mlogloss:0.22162\n",
      "[89]\ttrain-mlogloss:0.20492\teval-mlogloss:0.22113\n",
      "[90]\ttrain-mlogloss:0.20375\teval-mlogloss:0.22075\n",
      "[91]\ttrain-mlogloss:0.20255\teval-mlogloss:0.22057\n",
      "[92]\ttrain-mlogloss:0.20142\teval-mlogloss:0.22028\n",
      "[93]\ttrain-mlogloss:0.20021\teval-mlogloss:0.21985\n",
      "[94]\ttrain-mlogloss:0.19935\teval-mlogloss:0.21956\n",
      "[95]\ttrain-mlogloss:0.19834\teval-mlogloss:0.21910\n",
      "[96]\ttrain-mlogloss:0.19720\teval-mlogloss:0.21894\n",
      "[97]\ttrain-mlogloss:0.19605\teval-mlogloss:0.21867\n",
      "[98]\ttrain-mlogloss:0.19500\teval-mlogloss:0.21835\n",
      "[99]\ttrain-mlogloss:0.19402\teval-mlogloss:0.21809\n",
      "[100]\ttrain-mlogloss:0.19330\teval-mlogloss:0.21781\n",
      "[101]\ttrain-mlogloss:0.19233\teval-mlogloss:0.21767\n",
      "[102]\ttrain-mlogloss:0.19125\teval-mlogloss:0.21749\n",
      "[103]\ttrain-mlogloss:0.19021\teval-mlogloss:0.21732\n",
      "[104]\ttrain-mlogloss:0.18924\teval-mlogloss:0.21692\n",
      "[105]\ttrain-mlogloss:0.18836\teval-mlogloss:0.21673\n",
      "[106]\ttrain-mlogloss:0.18753\teval-mlogloss:0.21646\n",
      "[107]\ttrain-mlogloss:0.18636\teval-mlogloss:0.21655\n",
      "[108]\ttrain-mlogloss:0.18536\teval-mlogloss:0.21639\n",
      "[109]\ttrain-mlogloss:0.18447\teval-mlogloss:0.21620\n",
      "[110]\ttrain-mlogloss:0.18387\teval-mlogloss:0.21613\n",
      "[111]\ttrain-mlogloss:0.18283\teval-mlogloss:0.21629\n",
      "[112]\ttrain-mlogloss:0.18189\teval-mlogloss:0.21599\n",
      "[113]\ttrain-mlogloss:0.18110\teval-mlogloss:0.21579\n",
      "[114]\ttrain-mlogloss:0.18026\teval-mlogloss:0.21566\n",
      "[115]\ttrain-mlogloss:0.17953\teval-mlogloss:0.21546\n",
      "[116]\ttrain-mlogloss:0.17864\teval-mlogloss:0.21546\n",
      "[117]\ttrain-mlogloss:0.17757\teval-mlogloss:0.21529\n",
      "[118]\ttrain-mlogloss:0.17660\teval-mlogloss:0.21545\n",
      "[119]\ttrain-mlogloss:0.17589\teval-mlogloss:0.21545\n",
      "[120]\ttrain-mlogloss:0.17512\teval-mlogloss:0.21545\n",
      "[121]\ttrain-mlogloss:0.17436\teval-mlogloss:0.21562\n",
      "[122]\ttrain-mlogloss:0.17361\teval-mlogloss:0.21548\n",
      "[123]\ttrain-mlogloss:0.17283\teval-mlogloss:0.21528\n",
      "[124]\ttrain-mlogloss:0.17202\teval-mlogloss:0.21551\n",
      "[125]\ttrain-mlogloss:0.17149\teval-mlogloss:0.21523\n",
      "[126]\ttrain-mlogloss:0.17072\teval-mlogloss:0.21526\n",
      "[127]\ttrain-mlogloss:0.16986\teval-mlogloss:0.21521\n",
      "[128]\ttrain-mlogloss:0.16918\teval-mlogloss:0.21517\n",
      "[129]\ttrain-mlogloss:0.16836\teval-mlogloss:0.21486\n",
      "[130]\ttrain-mlogloss:0.16753\teval-mlogloss:0.21485\n",
      "[131]\ttrain-mlogloss:0.16671\teval-mlogloss:0.21461\n",
      "[132]\ttrain-mlogloss:0.16613\teval-mlogloss:0.21436\n",
      "[133]\ttrain-mlogloss:0.16553\teval-mlogloss:0.21448\n",
      "[134]\ttrain-mlogloss:0.16474\teval-mlogloss:0.21466\n",
      "[135]\ttrain-mlogloss:0.16397\teval-mlogloss:0.21458\n",
      "[136]\ttrain-mlogloss:0.16329\teval-mlogloss:0.21467\n",
      "[137]\ttrain-mlogloss:0.16265\teval-mlogloss:0.21458\n",
      "[138]\ttrain-mlogloss:0.16191\teval-mlogloss:0.21454\n",
      "[139]\ttrain-mlogloss:0.16134\teval-mlogloss:0.21462\n",
      "[140]\ttrain-mlogloss:0.16059\teval-mlogloss:0.21462\n",
      "[141]\ttrain-mlogloss:0.15998\teval-mlogloss:0.21451\n",
      "[142]\ttrain-mlogloss:0.15922\teval-mlogloss:0.21449\n",
      "[143]\ttrain-mlogloss:0.15853\teval-mlogloss:0.21474\n",
      "[144]\ttrain-mlogloss:0.15789\teval-mlogloss:0.21486\n",
      "[145]\ttrain-mlogloss:0.15715\teval-mlogloss:0.21496\n",
      "[146]\ttrain-mlogloss:0.15655\teval-mlogloss:0.21512\n",
      "[147]\ttrain-mlogloss:0.15590\teval-mlogloss:0.21516\n",
      "[148]\ttrain-mlogloss:0.15533\teval-mlogloss:0.21515\n",
      "[149]\ttrain-mlogloss:0.15461\teval-mlogloss:0.21528\n",
      "[150]\ttrain-mlogloss:0.15386\teval-mlogloss:0.21545\n",
      "[151]\ttrain-mlogloss:0.15313\teval-mlogloss:0.21533\n",
      "[152]\ttrain-mlogloss:0.15259\teval-mlogloss:0.21532\n",
      "[153]\ttrain-mlogloss:0.15199\teval-mlogloss:0.21506\n",
      "[154]\ttrain-mlogloss:0.15149\teval-mlogloss:0.21540\n",
      "[155]\ttrain-mlogloss:0.15082\teval-mlogloss:0.21552\n",
      "[156]\ttrain-mlogloss:0.15022\teval-mlogloss:0.21554\n",
      "[157]\ttrain-mlogloss:0.14966\teval-mlogloss:0.21578\n",
      "[158]\ttrain-mlogloss:0.14901\teval-mlogloss:0.21600\n",
      "[159]\ttrain-mlogloss:0.14846\teval-mlogloss:0.21594\n",
      "[160]\ttrain-mlogloss:0.14789\teval-mlogloss:0.21593\n",
      "[161]\ttrain-mlogloss:0.14725\teval-mlogloss:0.21594\n",
      "[162]\ttrain-mlogloss:0.14668\teval-mlogloss:0.21588\n",
      "[163]\ttrain-mlogloss:0.14610\teval-mlogloss:0.21580\n",
      "[164]\ttrain-mlogloss:0.14544\teval-mlogloss:0.21598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165]\ttrain-mlogloss:0.14502\teval-mlogloss:0.21608\n",
      "[166]\ttrain-mlogloss:0.14458\teval-mlogloss:0.21613\n",
      "[167]\ttrain-mlogloss:0.14400\teval-mlogloss:0.21626\n",
      "[168]\ttrain-mlogloss:0.14353\teval-mlogloss:0.21624\n",
      "[169]\ttrain-mlogloss:0.14314\teval-mlogloss:0.21616\n",
      "[170]\ttrain-mlogloss:0.14267\teval-mlogloss:0.21612\n",
      "[171]\ttrain-mlogloss:0.14212\teval-mlogloss:0.21613\n",
      "[172]\ttrain-mlogloss:0.14155\teval-mlogloss:0.21598\n",
      "[173]\ttrain-mlogloss:0.14102\teval-mlogloss:0.21604\n",
      "[174]\ttrain-mlogloss:0.14051\teval-mlogloss:0.21627\n",
      "[175]\ttrain-mlogloss:0.14000\teval-mlogloss:0.21650\n",
      "[176]\ttrain-mlogloss:0.13951\teval-mlogloss:0.21658\n",
      "[177]\ttrain-mlogloss:0.13912\teval-mlogloss:0.21672\n",
      "[178]\ttrain-mlogloss:0.13868\teval-mlogloss:0.21675\n",
      "[179]\ttrain-mlogloss:0.13815\teval-mlogloss:0.21679\n",
      "[180]\ttrain-mlogloss:0.13776\teval-mlogloss:0.21685\n",
      "[181]\ttrain-mlogloss:0.13728\teval-mlogloss:0.21694\n",
      "[182]\ttrain-mlogloss:0.13692\teval-mlogloss:0.21684\n",
      "[183]\ttrain-mlogloss:0.13651\teval-mlogloss:0.21692\n",
      "[184]\ttrain-mlogloss:0.13616\teval-mlogloss:0.21691\n",
      "[185]\ttrain-mlogloss:0.13578\teval-mlogloss:0.21699\n",
      "[186]\ttrain-mlogloss:0.13535\teval-mlogloss:0.21693\n",
      "[187]\ttrain-mlogloss:0.13489\teval-mlogloss:0.21693\n",
      "[188]\ttrain-mlogloss:0.13434\teval-mlogloss:0.21703\n",
      "[189]\ttrain-mlogloss:0.13380\teval-mlogloss:0.21719\n",
      "[190]\ttrain-mlogloss:0.13338\teval-mlogloss:0.21723\n",
      "[191]\ttrain-mlogloss:0.13298\teval-mlogloss:0.21729\n",
      "[192]\ttrain-mlogloss:0.13259\teval-mlogloss:0.21725\n",
      "[193]\ttrain-mlogloss:0.13215\teval-mlogloss:0.21745\n",
      "[194]\ttrain-mlogloss:0.13172\teval-mlogloss:0.21727\n",
      "[195]\ttrain-mlogloss:0.13128\teval-mlogloss:0.21735\n",
      "[196]\ttrain-mlogloss:0.13091\teval-mlogloss:0.21757\n",
      "[197]\ttrain-mlogloss:0.13044\teval-mlogloss:0.21774\n",
      "[198]\ttrain-mlogloss:0.12999\teval-mlogloss:0.21794\n",
      "[199]\ttrain-mlogloss:0.12965\teval-mlogloss:0.21800\n",
      "[200]\ttrain-mlogloss:0.12922\teval-mlogloss:0.21813\n",
      "[201]\ttrain-mlogloss:0.12886\teval-mlogloss:0.21832\n",
      "[202]\ttrain-mlogloss:0.12858\teval-mlogloss:0.21847\n",
      "[203]\ttrain-mlogloss:0.12818\teval-mlogloss:0.21860\n",
      "[204]\ttrain-mlogloss:0.12777\teval-mlogloss:0.21873\n",
      "[205]\ttrain-mlogloss:0.12744\teval-mlogloss:0.21884\n",
      "[206]\ttrain-mlogloss:0.12710\teval-mlogloss:0.21908\n",
      "[207]\ttrain-mlogloss:0.12667\teval-mlogloss:0.21908\n",
      "[208]\ttrain-mlogloss:0.12634\teval-mlogloss:0.21922\n",
      "[209]\ttrain-mlogloss:0.12598\teval-mlogloss:0.21942\n",
      "[210]\ttrain-mlogloss:0.12557\teval-mlogloss:0.21950\n",
      "[211]\ttrain-mlogloss:0.12532\teval-mlogloss:0.21961\n",
      "[212]\ttrain-mlogloss:0.12504\teval-mlogloss:0.21961\n",
      "[213]\ttrain-mlogloss:0.12470\teval-mlogloss:0.21974\n",
      "[214]\ttrain-mlogloss:0.12431\teval-mlogloss:0.21977\n",
      "[215]\ttrain-mlogloss:0.12387\teval-mlogloss:0.21979\n",
      "[216]\ttrain-mlogloss:0.12357\teval-mlogloss:0.21972\n",
      "[217]\ttrain-mlogloss:0.12331\teval-mlogloss:0.21968\n",
      "[218]\ttrain-mlogloss:0.12287\teval-mlogloss:0.21962\n",
      "[219]\ttrain-mlogloss:0.12255\teval-mlogloss:0.21983\n",
      "[220]\ttrain-mlogloss:0.12226\teval-mlogloss:0.21991\n",
      "[221]\ttrain-mlogloss:0.12187\teval-mlogloss:0.21997\n",
      "[222]\ttrain-mlogloss:0.12150\teval-mlogloss:0.22008\n",
      "[223]\ttrain-mlogloss:0.12119\teval-mlogloss:0.22030\n",
      "[224]\ttrain-mlogloss:0.12087\teval-mlogloss:0.22045\n",
      "[225]\ttrain-mlogloss:0.12049\teval-mlogloss:0.22067\n",
      "[226]\ttrain-mlogloss:0.12019\teval-mlogloss:0.22066\n",
      "[227]\ttrain-mlogloss:0.11984\teval-mlogloss:0.22080\n",
      "[228]\ttrain-mlogloss:0.11955\teval-mlogloss:0.22090\n",
      "[229]\ttrain-mlogloss:0.11924\teval-mlogloss:0.22077\n",
      "[230]\ttrain-mlogloss:0.11889\teval-mlogloss:0.22094\n",
      "[231]\ttrain-mlogloss:0.11850\teval-mlogloss:0.22133\n",
      "[232]\ttrain-mlogloss:0.11815\teval-mlogloss:0.22127\n",
      "Stopping. Best iteration:\n",
      "[132]\ttrain-mlogloss:0.16613\teval-mlogloss:0.21436\n",
      "\n",
      "xgb now score is: [2.4376569647714494, 2.2161756049096586, 2.4777412121277305, 2.575522996112704]\n",
      "[0]\ttrain-mlogloss:0.67114\teval-mlogloss:0.67080\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.65054\teval-mlogloss:0.64996\n",
      "[2]\ttrain-mlogloss:0.63119\teval-mlogloss:0.63035\n",
      "[3]\ttrain-mlogloss:0.61251\teval-mlogloss:0.61183\n",
      "[4]\ttrain-mlogloss:0.59462\teval-mlogloss:0.59368\n",
      "[5]\ttrain-mlogloss:0.57798\teval-mlogloss:0.57687\n",
      "[6]\ttrain-mlogloss:0.56212\teval-mlogloss:0.56061\n",
      "[7]\ttrain-mlogloss:0.54691\teval-mlogloss:0.54520\n",
      "[8]\ttrain-mlogloss:0.53244\teval-mlogloss:0.53074\n",
      "[9]\ttrain-mlogloss:0.51887\teval-mlogloss:0.51729\n",
      "[10]\ttrain-mlogloss:0.50601\teval-mlogloss:0.50415\n",
      "[11]\ttrain-mlogloss:0.49392\teval-mlogloss:0.49173\n",
      "[12]\ttrain-mlogloss:0.48231\teval-mlogloss:0.47987\n",
      "[13]\ttrain-mlogloss:0.47130\teval-mlogloss:0.46890\n",
      "[14]\ttrain-mlogloss:0.46067\teval-mlogloss:0.45806\n",
      "[15]\ttrain-mlogloss:0.45049\teval-mlogloss:0.44790\n",
      "[16]\ttrain-mlogloss:0.44068\teval-mlogloss:0.43829\n",
      "[17]\ttrain-mlogloss:0.43137\teval-mlogloss:0.42887\n",
      "[18]\ttrain-mlogloss:0.42245\teval-mlogloss:0.41994\n",
      "[19]\ttrain-mlogloss:0.41395\teval-mlogloss:0.41150\n",
      "[20]\ttrain-mlogloss:0.40586\teval-mlogloss:0.40330\n",
      "[21]\ttrain-mlogloss:0.39799\teval-mlogloss:0.39542\n",
      "[22]\ttrain-mlogloss:0.39057\teval-mlogloss:0.38795\n",
      "[23]\ttrain-mlogloss:0.38343\teval-mlogloss:0.38076\n",
      "[24]\ttrain-mlogloss:0.37657\teval-mlogloss:0.37380\n",
      "[25]\ttrain-mlogloss:0.37005\teval-mlogloss:0.36723\n",
      "[26]\ttrain-mlogloss:0.36379\teval-mlogloss:0.36095\n",
      "[27]\ttrain-mlogloss:0.35764\teval-mlogloss:0.35483\n",
      "[28]\ttrain-mlogloss:0.35189\teval-mlogloss:0.34913\n",
      "[29]\ttrain-mlogloss:0.34628\teval-mlogloss:0.34361\n",
      "[30]\ttrain-mlogloss:0.34091\teval-mlogloss:0.33856\n",
      "[31]\ttrain-mlogloss:0.33574\teval-mlogloss:0.33333\n",
      "[32]\ttrain-mlogloss:0.33089\teval-mlogloss:0.32857\n",
      "[33]\ttrain-mlogloss:0.32593\teval-mlogloss:0.32362\n",
      "[34]\ttrain-mlogloss:0.32139\teval-mlogloss:0.31920\n",
      "[35]\ttrain-mlogloss:0.31721\teval-mlogloss:0.31498\n",
      "[36]\ttrain-mlogloss:0.31284\teval-mlogloss:0.31082\n",
      "[37]\ttrain-mlogloss:0.30892\teval-mlogloss:0.30676\n",
      "[38]\ttrain-mlogloss:0.30514\teval-mlogloss:0.30308\n",
      "[39]\ttrain-mlogloss:0.30141\teval-mlogloss:0.29959\n",
      "[40]\ttrain-mlogloss:0.29772\teval-mlogloss:0.29595\n",
      "[41]\ttrain-mlogloss:0.29432\teval-mlogloss:0.29261\n",
      "[42]\ttrain-mlogloss:0.29106\teval-mlogloss:0.28952\n",
      "[43]\ttrain-mlogloss:0.28774\teval-mlogloss:0.28654\n",
      "[44]\ttrain-mlogloss:0.28462\teval-mlogloss:0.28360\n",
      "[45]\ttrain-mlogloss:0.28151\teval-mlogloss:0.28067\n",
      "[46]\ttrain-mlogloss:0.27850\teval-mlogloss:0.27801\n",
      "[47]\ttrain-mlogloss:0.27547\teval-mlogloss:0.27516\n",
      "[48]\ttrain-mlogloss:0.27275\teval-mlogloss:0.27265\n",
      "[49]\ttrain-mlogloss:0.27002\teval-mlogloss:0.27026\n",
      "[50]\ttrain-mlogloss:0.26745\teval-mlogloss:0.26770\n",
      "[51]\ttrain-mlogloss:0.26491\teval-mlogloss:0.26540\n",
      "[52]\ttrain-mlogloss:0.26251\teval-mlogloss:0.26351\n",
      "[53]\ttrain-mlogloss:0.26037\teval-mlogloss:0.26160\n",
      "[54]\ttrain-mlogloss:0.25800\teval-mlogloss:0.25977\n",
      "[55]\ttrain-mlogloss:0.25579\teval-mlogloss:0.25789\n",
      "[56]\ttrain-mlogloss:0.25362\teval-mlogloss:0.25590\n",
      "[57]\ttrain-mlogloss:0.25156\teval-mlogloss:0.25423\n",
      "[58]\ttrain-mlogloss:0.24953\teval-mlogloss:0.25237\n",
      "[59]\ttrain-mlogloss:0.24742\teval-mlogloss:0.25067\n",
      "[60]\ttrain-mlogloss:0.24566\teval-mlogloss:0.24922\n",
      "[61]\ttrain-mlogloss:0.24401\teval-mlogloss:0.24753\n",
      "[62]\ttrain-mlogloss:0.24217\teval-mlogloss:0.24639\n",
      "[63]\ttrain-mlogloss:0.24045\teval-mlogloss:0.24497\n",
      "[64]\ttrain-mlogloss:0.23875\teval-mlogloss:0.24360\n",
      "[65]\ttrain-mlogloss:0.23719\teval-mlogloss:0.24227\n",
      "[66]\ttrain-mlogloss:0.23576\teval-mlogloss:0.24106\n",
      "[67]\ttrain-mlogloss:0.23432\teval-mlogloss:0.23999\n",
      "[68]\ttrain-mlogloss:0.23278\teval-mlogloss:0.23888\n",
      "[69]\ttrain-mlogloss:0.23117\teval-mlogloss:0.23788\n",
      "[70]\ttrain-mlogloss:0.22961\teval-mlogloss:0.23685\n",
      "[71]\ttrain-mlogloss:0.22802\teval-mlogloss:0.23597\n",
      "[72]\ttrain-mlogloss:0.22671\teval-mlogloss:0.23507\n",
      "[73]\ttrain-mlogloss:0.22523\teval-mlogloss:0.23408\n",
      "[74]\ttrain-mlogloss:0.22371\teval-mlogloss:0.23325\n",
      "[75]\ttrain-mlogloss:0.22257\teval-mlogloss:0.23244\n",
      "[76]\ttrain-mlogloss:0.22111\teval-mlogloss:0.23171\n",
      "[77]\ttrain-mlogloss:0.21957\teval-mlogloss:0.23106\n",
      "[78]\ttrain-mlogloss:0.21825\teval-mlogloss:0.23051\n",
      "[79]\ttrain-mlogloss:0.21719\teval-mlogloss:0.22976\n",
      "[80]\ttrain-mlogloss:0.21571\teval-mlogloss:0.22910\n",
      "[81]\ttrain-mlogloss:0.21433\teval-mlogloss:0.22844\n",
      "[82]\ttrain-mlogloss:0.21294\teval-mlogloss:0.22806\n",
      "[83]\ttrain-mlogloss:0.21162\teval-mlogloss:0.22748\n",
      "[84]\ttrain-mlogloss:0.21054\teval-mlogloss:0.22695\n",
      "[85]\ttrain-mlogloss:0.20927\teval-mlogloss:0.22617\n",
      "[86]\ttrain-mlogloss:0.20806\teval-mlogloss:0.22567\n",
      "[87]\ttrain-mlogloss:0.20708\teval-mlogloss:0.22503\n",
      "[88]\ttrain-mlogloss:0.20584\teval-mlogloss:0.22461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89]\ttrain-mlogloss:0.20463\teval-mlogloss:0.22418\n",
      "[90]\ttrain-mlogloss:0.20371\teval-mlogloss:0.22385\n",
      "[91]\ttrain-mlogloss:0.20268\teval-mlogloss:0.22354\n",
      "[92]\ttrain-mlogloss:0.20157\teval-mlogloss:0.22317\n",
      "[93]\ttrain-mlogloss:0.20053\teval-mlogloss:0.22282\n",
      "[94]\ttrain-mlogloss:0.19946\teval-mlogloss:0.22266\n",
      "[95]\ttrain-mlogloss:0.19868\teval-mlogloss:0.22222\n",
      "[96]\ttrain-mlogloss:0.19764\teval-mlogloss:0.22181\n",
      "[97]\ttrain-mlogloss:0.19659\teval-mlogloss:0.22142\n",
      "[98]\ttrain-mlogloss:0.19564\teval-mlogloss:0.22122\n",
      "[99]\ttrain-mlogloss:0.19453\teval-mlogloss:0.22087\n",
      "[100]\ttrain-mlogloss:0.19351\teval-mlogloss:0.22053\n",
      "[101]\ttrain-mlogloss:0.19256\teval-mlogloss:0.22022\n",
      "[102]\ttrain-mlogloss:0.19147\teval-mlogloss:0.22001\n",
      "[103]\ttrain-mlogloss:0.19055\teval-mlogloss:0.21976\n",
      "[104]\ttrain-mlogloss:0.18958\teval-mlogloss:0.21940\n",
      "[105]\ttrain-mlogloss:0.18865\teval-mlogloss:0.21935\n",
      "[106]\ttrain-mlogloss:0.18777\teval-mlogloss:0.21926\n",
      "[107]\ttrain-mlogloss:0.18667\teval-mlogloss:0.21919\n",
      "[108]\ttrain-mlogloss:0.18582\teval-mlogloss:0.21932\n",
      "[109]\ttrain-mlogloss:0.18491\teval-mlogloss:0.21922\n",
      "[110]\ttrain-mlogloss:0.18410\teval-mlogloss:0.21887\n",
      "[111]\ttrain-mlogloss:0.18306\teval-mlogloss:0.21870\n",
      "[112]\ttrain-mlogloss:0.18205\teval-mlogloss:0.21857\n",
      "[113]\ttrain-mlogloss:0.18116\teval-mlogloss:0.21861\n",
      "[114]\ttrain-mlogloss:0.18024\teval-mlogloss:0.21856\n",
      "[115]\ttrain-mlogloss:0.17939\teval-mlogloss:0.21853\n",
      "[116]\ttrain-mlogloss:0.17864\teval-mlogloss:0.21821\n",
      "[117]\ttrain-mlogloss:0.17785\teval-mlogloss:0.21794\n",
      "[118]\ttrain-mlogloss:0.17708\teval-mlogloss:0.21772\n",
      "[119]\ttrain-mlogloss:0.17624\teval-mlogloss:0.21746\n",
      "[120]\ttrain-mlogloss:0.17535\teval-mlogloss:0.21735\n",
      "[121]\ttrain-mlogloss:0.17463\teval-mlogloss:0.21708\n",
      "[122]\ttrain-mlogloss:0.17394\teval-mlogloss:0.21693\n",
      "[123]\ttrain-mlogloss:0.17326\teval-mlogloss:0.21689\n",
      "[124]\ttrain-mlogloss:0.17249\teval-mlogloss:0.21662\n",
      "[125]\ttrain-mlogloss:0.17172\teval-mlogloss:0.21652\n",
      "[126]\ttrain-mlogloss:0.17102\teval-mlogloss:0.21638\n",
      "[127]\ttrain-mlogloss:0.17027\teval-mlogloss:0.21612\n",
      "[128]\ttrain-mlogloss:0.16942\teval-mlogloss:0.21594\n",
      "[129]\ttrain-mlogloss:0.16862\teval-mlogloss:0.21582\n",
      "[130]\ttrain-mlogloss:0.16787\teval-mlogloss:0.21574\n",
      "[131]\ttrain-mlogloss:0.16708\teval-mlogloss:0.21561\n",
      "[132]\ttrain-mlogloss:0.16644\teval-mlogloss:0.21572\n",
      "[133]\ttrain-mlogloss:0.16585\teval-mlogloss:0.21565\n",
      "[134]\ttrain-mlogloss:0.16516\teval-mlogloss:0.21572\n",
      "[135]\ttrain-mlogloss:0.16436\teval-mlogloss:0.21555\n",
      "[136]\ttrain-mlogloss:0.16365\teval-mlogloss:0.21547\n",
      "[137]\ttrain-mlogloss:0.16323\teval-mlogloss:0.21530\n",
      "[138]\ttrain-mlogloss:0.16263\teval-mlogloss:0.21527\n",
      "[139]\ttrain-mlogloss:0.16191\teval-mlogloss:0.21532\n",
      "[140]\ttrain-mlogloss:0.16119\teval-mlogloss:0.21534\n",
      "[141]\ttrain-mlogloss:0.16054\teval-mlogloss:0.21557\n",
      "[142]\ttrain-mlogloss:0.15984\teval-mlogloss:0.21564\n",
      "[143]\ttrain-mlogloss:0.15918\teval-mlogloss:0.21575\n",
      "[144]\ttrain-mlogloss:0.15854\teval-mlogloss:0.21604\n",
      "[145]\ttrain-mlogloss:0.15793\teval-mlogloss:0.21605\n",
      "[146]\ttrain-mlogloss:0.15724\teval-mlogloss:0.21596\n",
      "[147]\ttrain-mlogloss:0.15674\teval-mlogloss:0.21582\n",
      "[148]\ttrain-mlogloss:0.15621\teval-mlogloss:0.21558\n",
      "[149]\ttrain-mlogloss:0.15564\teval-mlogloss:0.21533\n",
      "[150]\ttrain-mlogloss:0.15511\teval-mlogloss:0.21525\n",
      "[151]\ttrain-mlogloss:0.15453\teval-mlogloss:0.21530\n",
      "[152]\ttrain-mlogloss:0.15387\teval-mlogloss:0.21539\n",
      "[153]\ttrain-mlogloss:0.15317\teval-mlogloss:0.21557\n",
      "[154]\ttrain-mlogloss:0.15266\teval-mlogloss:0.21559\n",
      "[155]\ttrain-mlogloss:0.15214\teval-mlogloss:0.21573\n",
      "[156]\ttrain-mlogloss:0.15157\teval-mlogloss:0.21569\n",
      "[157]\ttrain-mlogloss:0.15109\teval-mlogloss:0.21574\n",
      "[158]\ttrain-mlogloss:0.15049\teval-mlogloss:0.21590\n",
      "[159]\ttrain-mlogloss:0.14988\teval-mlogloss:0.21608\n",
      "[160]\ttrain-mlogloss:0.14938\teval-mlogloss:0.21579\n",
      "[161]\ttrain-mlogloss:0.14882\teval-mlogloss:0.21576\n",
      "[162]\ttrain-mlogloss:0.14837\teval-mlogloss:0.21582\n",
      "[163]\ttrain-mlogloss:0.14780\teval-mlogloss:0.21584\n",
      "[164]\ttrain-mlogloss:0.14732\teval-mlogloss:0.21575\n",
      "[165]\ttrain-mlogloss:0.14690\teval-mlogloss:0.21563\n",
      "[166]\ttrain-mlogloss:0.14642\teval-mlogloss:0.21557\n",
      "[167]\ttrain-mlogloss:0.14589\teval-mlogloss:0.21560\n",
      "[168]\ttrain-mlogloss:0.14533\teval-mlogloss:0.21559\n",
      "[169]\ttrain-mlogloss:0.14476\teval-mlogloss:0.21547\n",
      "[170]\ttrain-mlogloss:0.14424\teval-mlogloss:0.21551\n",
      "[171]\ttrain-mlogloss:0.14368\teval-mlogloss:0.21547\n",
      "[172]\ttrain-mlogloss:0.14319\teval-mlogloss:0.21560\n",
      "[173]\ttrain-mlogloss:0.14280\teval-mlogloss:0.21561\n",
      "[174]\ttrain-mlogloss:0.14230\teval-mlogloss:0.21586\n",
      "[175]\ttrain-mlogloss:0.14183\teval-mlogloss:0.21590\n",
      "[176]\ttrain-mlogloss:0.14148\teval-mlogloss:0.21579\n",
      "[177]\ttrain-mlogloss:0.14093\teval-mlogloss:0.21582\n",
      "[178]\ttrain-mlogloss:0.14045\teval-mlogloss:0.21601\n",
      "[179]\ttrain-mlogloss:0.14002\teval-mlogloss:0.21628\n",
      "[180]\ttrain-mlogloss:0.13952\teval-mlogloss:0.21643\n",
      "[181]\ttrain-mlogloss:0.13908\teval-mlogloss:0.21648\n",
      "[182]\ttrain-mlogloss:0.13876\teval-mlogloss:0.21624\n",
      "[183]\ttrain-mlogloss:0.13830\teval-mlogloss:0.21635\n",
      "[184]\ttrain-mlogloss:0.13795\teval-mlogloss:0.21619\n",
      "[185]\ttrain-mlogloss:0.13747\teval-mlogloss:0.21619\n",
      "[186]\ttrain-mlogloss:0.13710\teval-mlogloss:0.21607\n",
      "[187]\ttrain-mlogloss:0.13672\teval-mlogloss:0.21608\n",
      "[188]\ttrain-mlogloss:0.13629\teval-mlogloss:0.21585\n",
      "[189]\ttrain-mlogloss:0.13591\teval-mlogloss:0.21588\n",
      "[190]\ttrain-mlogloss:0.13560\teval-mlogloss:0.21599\n",
      "[191]\ttrain-mlogloss:0.13522\teval-mlogloss:0.21583\n",
      "[192]\ttrain-mlogloss:0.13479\teval-mlogloss:0.21596\n",
      "[193]\ttrain-mlogloss:0.13433\teval-mlogloss:0.21608\n",
      "[194]\ttrain-mlogloss:0.13396\teval-mlogloss:0.21617\n",
      "[195]\ttrain-mlogloss:0.13357\teval-mlogloss:0.21618\n",
      "[196]\ttrain-mlogloss:0.13316\teval-mlogloss:0.21609\n",
      "[197]\ttrain-mlogloss:0.13280\teval-mlogloss:0.21610\n",
      "[198]\ttrain-mlogloss:0.13233\teval-mlogloss:0.21612\n",
      "[199]\ttrain-mlogloss:0.13191\teval-mlogloss:0.21616\n",
      "[200]\ttrain-mlogloss:0.13150\teval-mlogloss:0.21626\n",
      "[201]\ttrain-mlogloss:0.13107\teval-mlogloss:0.21613\n",
      "[202]\ttrain-mlogloss:0.13071\teval-mlogloss:0.21600\n",
      "[203]\ttrain-mlogloss:0.13038\teval-mlogloss:0.21607\n",
      "[204]\ttrain-mlogloss:0.13007\teval-mlogloss:0.21605\n",
      "[205]\ttrain-mlogloss:0.12968\teval-mlogloss:0.21596\n",
      "[206]\ttrain-mlogloss:0.12930\teval-mlogloss:0.21609\n",
      "[207]\ttrain-mlogloss:0.12883\teval-mlogloss:0.21631\n",
      "[208]\ttrain-mlogloss:0.12849\teval-mlogloss:0.21645\n",
      "[209]\ttrain-mlogloss:0.12812\teval-mlogloss:0.21640\n",
      "[210]\ttrain-mlogloss:0.12773\teval-mlogloss:0.21654\n",
      "[211]\ttrain-mlogloss:0.12746\teval-mlogloss:0.21643\n",
      "[212]\ttrain-mlogloss:0.12701\teval-mlogloss:0.21665\n",
      "[213]\ttrain-mlogloss:0.12659\teval-mlogloss:0.21650\n",
      "[214]\ttrain-mlogloss:0.12616\teval-mlogloss:0.21653\n",
      "[215]\ttrain-mlogloss:0.12585\teval-mlogloss:0.21662\n",
      "[216]\ttrain-mlogloss:0.12546\teval-mlogloss:0.21656\n",
      "[217]\ttrain-mlogloss:0.12507\teval-mlogloss:0.21680\n",
      "[218]\ttrain-mlogloss:0.12464\teval-mlogloss:0.21699\n",
      "[219]\ttrain-mlogloss:0.12433\teval-mlogloss:0.21704\n",
      "[220]\ttrain-mlogloss:0.12395\teval-mlogloss:0.21720\n",
      "[221]\ttrain-mlogloss:0.12363\teval-mlogloss:0.21721\n",
      "[222]\ttrain-mlogloss:0.12315\teval-mlogloss:0.21745\n",
      "[223]\ttrain-mlogloss:0.12274\teval-mlogloss:0.21760\n",
      "[224]\ttrain-mlogloss:0.12236\teval-mlogloss:0.21772\n",
      "[225]\ttrain-mlogloss:0.12204\teval-mlogloss:0.21782\n",
      "[226]\ttrain-mlogloss:0.12175\teval-mlogloss:0.21811\n",
      "[227]\ttrain-mlogloss:0.12147\teval-mlogloss:0.21815\n",
      "[228]\ttrain-mlogloss:0.12112\teval-mlogloss:0.21830\n",
      "[229]\ttrain-mlogloss:0.12081\teval-mlogloss:0.21831\n",
      "[230]\ttrain-mlogloss:0.12049\teval-mlogloss:0.21835\n",
      "[231]\ttrain-mlogloss:0.12018\teval-mlogloss:0.21824\n",
      "[232]\ttrain-mlogloss:0.11990\teval-mlogloss:0.21816\n",
      "[233]\ttrain-mlogloss:0.11957\teval-mlogloss:0.21819\n",
      "[234]\ttrain-mlogloss:0.11930\teval-mlogloss:0.21826\n",
      "[235]\ttrain-mlogloss:0.11903\teval-mlogloss:0.21821\n",
      "[236]\ttrain-mlogloss:0.11863\teval-mlogloss:0.21844\n",
      "[237]\ttrain-mlogloss:0.11839\teval-mlogloss:0.21846\n",
      "[238]\ttrain-mlogloss:0.11817\teval-mlogloss:0.21857\n",
      "[239]\ttrain-mlogloss:0.11785\teval-mlogloss:0.21880\n",
      "[240]\ttrain-mlogloss:0.11754\teval-mlogloss:0.21894\n",
      "[241]\ttrain-mlogloss:0.11724\teval-mlogloss:0.21899\n",
      "[242]\ttrain-mlogloss:0.11695\teval-mlogloss:0.21930\n",
      "[243]\ttrain-mlogloss:0.11672\teval-mlogloss:0.21932\n",
      "[244]\ttrain-mlogloss:0.11642\teval-mlogloss:0.21935\n",
      "[245]\ttrain-mlogloss:0.11613\teval-mlogloss:0.21952\n",
      "[246]\ttrain-mlogloss:0.11591\teval-mlogloss:0.21972\n",
      "[247]\ttrain-mlogloss:0.11568\teval-mlogloss:0.21983\n",
      "[248]\ttrain-mlogloss:0.11545\teval-mlogloss:0.21982\n",
      "[249]\ttrain-mlogloss:0.11512\teval-mlogloss:0.21983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttrain-mlogloss:0.11484\teval-mlogloss:0.21989\n",
      "Stopping. Best iteration:\n",
      "[150]\ttrain-mlogloss:0.15511\teval-mlogloss:0.21525\n",
      "\n",
      "xgb now score is: [2.4376569647714494, 2.2161756049096586, 2.4777412121277305, 2.575522996112704, 2.7253107116091995]\n",
      "xgb_score_list: [2.4376569647714494, 2.2161756049096586, 2.4777412121277305, 2.575522996112704, 2.7253107116091995]\n",
      "xgb_score_mean: 2.4864814979061487\n"
     ]
    }
   ],
   "source": [
    "#训练模型，获取stacking特征\n",
    "clf_list = clf_list\n",
    "column_list = []\n",
    "train_data_list=[]\n",
    "test_data_list=[]\n",
    "for clf in clf_list:\n",
    "    train_data,test_data,clf_name=clf(x_train, y_train, x_valid, kf, label_split=None)\n",
    "    train_data_list.append(train_data)\n",
    "    test_data_list.append(test_data)\n",
    "train_stacking = np.concatenate(train_data_list, axis=1)\n",
    "test_stacking = np.concatenate(test_data_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原时特征和stacking特征合并\n",
    "train = pd.DataFrame(np.concatenate([x_train, train_stacking], axis=1))\n",
    "test = np.concatenate([x_valid, test_stacking], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征重命名\n",
    "df_train_all = pd.DataFrame(train)\n",
    "df_train_all.columns = features_columns + clf_list_col\n",
    "df_test_all = pd.DataFrame(test)\n",
    "df_test_all.columns = features_columns + clf_list_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'merchant_id',\n",
       " 'age_range',\n",
       " 'gender',\n",
       " 'user_cnt',\n",
       " 'seller_nunique',\n",
       " 'cat_nunique',\n",
       " 'brand_nunique',\n",
       " 'item_nunique',\n",
       " 'time_stamp_nunique',\n",
       " 'action_type_nunique',\n",
       " 'time_stamp_max',\n",
       " 'time_stamp_min',\n",
       " 'time_stamp_std',\n",
       " 'time_stamp_range',\n",
       " 'seller_most_1',\n",
       " 'cat_most_1',\n",
       " 'brand_most_1',\n",
       " 'action_type_1',\n",
       " 'seller_most_1_cnt',\n",
       " 'cat_most_1_cnt',\n",
       " 'brand_most_1_cnt',\n",
       " 'action_type_1_cnt',\n",
       " 'user_cnt_0',\n",
       " 'user_cnt_1',\n",
       " 'user_cnt_2',\n",
       " 'user_cnt_3',\n",
       " 'seller_nunique_0',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'embeeding_0',\n",
       " 'embeeding_1',\n",
       " 'embeeding_2',\n",
       " 'embeeding_3',\n",
       " 'embeeding_4',\n",
       " 'embeeding_5',\n",
       " 'embeeding_6',\n",
       " 'embeeding_7',\n",
       " 'embeeding_8',\n",
       " 'embeeding_9',\n",
       " 'embeeding_10',\n",
       " 'embeeding_11',\n",
       " 'embeeding_12',\n",
       " 'embeeding_13',\n",
       " 'embeeding_14',\n",
       " 'embeeding_15',\n",
       " 'embeeding_16',\n",
       " 'embeeding_17',\n",
       " 'embeeding_18',\n",
       " 'embeeding_19',\n",
       " 'embeeding_20',\n",
       " 'embeeding_21',\n",
       " 'embeeding_22',\n",
       " 'embeeding_23',\n",
       " 'embeeding_24',\n",
       " 'embeeding_25',\n",
       " 'embeeding_26',\n",
       " 'embeeding_27',\n",
       " 'embeeding_28',\n",
       " 'embeeding_29',\n",
       " 'embeeding_30',\n",
       " 'embeeding_31',\n",
       " 'embeeding_32',\n",
       " 'embeeding_33',\n",
       " 'embeeding_34',\n",
       " 'embeeding_35',\n",
       " 'embeeding_36',\n",
       " 'embeeding_37',\n",
       " 'embeeding_38',\n",
       " 'embeeding_39',\n",
       " 'embeeding_40',\n",
       " 'embeeding_41',\n",
       " 'embeeding_42',\n",
       " 'embeeding_43',\n",
       " 'embeeding_44',\n",
       " 'embeeding_45',\n",
       " 'embeeding_46',\n",
       " 'embeeding_47',\n",
       " 'embeeding_48',\n",
       " 'embeeding_49',\n",
       " 'embeeding_50',\n",
       " 'embeeding_51',\n",
       " 'embeeding_52',\n",
       " 'embeeding_53',\n",
       " 'embeeding_54',\n",
       " 'embeeding_55',\n",
       " 'embeeding_56',\n",
       " 'embeeding_57',\n",
       " 'embeeding_58',\n",
       " 'embeeding_59',\n",
       " 'embeeding_60',\n",
       " 'embeeding_61',\n",
       " 'embeeding_62',\n",
       " 'embeeding_63',\n",
       " 'embeeding_64',\n",
       " 'embeeding_65',\n",
       " 'embeeding_66',\n",
       " 'embeeding_67',\n",
       " 'embeeding_68',\n",
       " 'embeeding_69',\n",
       " 'embeeding_70',\n",
       " 'embeeding_71',\n",
       " 'embeeding_72',\n",
       " 'embeeding_73',\n",
       " 'embeeding_74',\n",
       " 'embeeding_75',\n",
       " 'embeeding_76',\n",
       " 'embeeding_77',\n",
       " 'embeeding_78',\n",
       " 'embeeding_79',\n",
       " 'embeeding_80',\n",
       " 'embeeding_81',\n",
       " 'embeeding_82',\n",
       " 'embeeding_83',\n",
       " 'embeeding_84',\n",
       " 'embeeding_85',\n",
       " 'embeeding_86',\n",
       " 'embeeding_87',\n",
       " 'embeeding_88',\n",
       " 'embeeding_89',\n",
       " 'embeeding_90',\n",
       " 'embeeding_91',\n",
       " 'embeeding_92',\n",
       " 'embeeding_93',\n",
       " 'embeeding_94',\n",
       " 'embeeding_95',\n",
       " 'embeeding_96',\n",
       " 'embeeding_97',\n",
       " 'embeeding_98',\n",
       " 'embeeding_99',\n",
       " 'lgb_clf',\n",
       " 'xgb_clf']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_test_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据ID以及特征标签label\n",
    "df_train_all['label'] = all_data_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondad9bd0a7157c84fa7bace955ad09d0846"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
