{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file='./train.csv'\n",
    "eval_file='./eval.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(train_file)\n",
    "eval_df=pd.read_csv(eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop函数可以将dataFrame中的某个字段提出掉,同时指定某个变量去接受去掉的那个字段\n",
    "y_train=train_df.pop('survived')\n",
    "y_eval=eval_df.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22a7fb633d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['age'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22a044db1c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "#定义离散特征\n",
    "categorical_columns=['sex','n_siblings_spouses','parch','class','deck','embark_town','alone']\n",
    "#定义连续特征\n",
    "numeric_columns=['age','fare']\n",
    "feature_columns=[]\n",
    "#对离散值做one-hot编码\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab=train_df[categorical_column].unique() #取出离散特征中的离散值种类\n",
    "    print(categorical_column,vocab)\n",
    "    feature_columns.append(tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            categorical_column,vocab)))\n",
    "\n",
    "#对连续特征直接加入到feature_columns中去\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "    tf.feature_column.numeric_column(\n",
    "    categorical_column,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建一个dataset\n",
    "def make_dataset(data_df,label_df,epochs=10,shuffle=True,batch_size=32):\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))\n",
    "    if shuffle:\n",
    "        dataset=dataset.shuffle(10000)\n",
    "    dataset=dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用dataset\n",
    "train_dataset=make_dataset(train_df,y_train,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'female', b'male'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([30.5, 28. , 26. , 35. , 32. ])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 0, 0], dtype=int64)>, 'parch': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 0, 0], dtype=int64)>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([  8.05  ,   8.1125,   7.8958, 512.3292,  30.5   ])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'Third', b'Third', b'First', b'First'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'B'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'y', b'y', b'y', b'y'], dtype=object)>} tf.Tensor([0 1 0 1 1], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#遍历取出数据\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[ 28.       0.       1.       0.       0.       1.       0.       0.\n",
      "    0.       0.       0.       0.       0.       1.       0.       0.\n",
      "    1.       0.      12.35     0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    0.       1.    ]\n",
      " [ 27.       0.       1.       0.       1.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      30.5      0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 24.       1.       0.       0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       1.\n",
      "    0.       0.     247.5208   0.       1.       0.       0.       0.\n",
      "    0.       0.       0.       1.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 28.       0.       1.       0.       1.       0.       0.       0.\n",
      "    0.       1.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      26.       0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 28.       1.       0.       1.       0.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      16.1      1.       0.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]]\n"
     ]
    }
   ],
   "source": [
    "#keras.layers.DenseFeature\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "model=keras.models.Sequential([\n",
    "    #输出层\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    #全连接层\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    #输出层\n",
    "    keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "#定义激活函数\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int64>, 'parch': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int64>, 'fare': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'class': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'deck': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'embark_town': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'alone': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layer dense_features_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int64>, 'parch': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int64>, 'fare': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'class': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'deck': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'embark_town': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'alone': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 1.1902 - accuracy: 0.3750WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int64>, 'parch': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int64>, 'fare': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'class': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'deck': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'embark_town': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'alone': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 1.4270 - accuracy: 0.5953 - val_loss: 0.6563 - val_accuracy: 0.6602\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.6609 - val_loss: 0.6046 - val_accuracy: 0.6914\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6438 - val_loss: 0.6281 - val_accuracy: 0.6680\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6562 - val_loss: 0.5928 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6594 - val_loss: 0.5973 - val_accuracy: 0.6914\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6781 - val_loss: 0.5969 - val_accuracy: 0.6875\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6844 - val_loss: 0.5896 - val_accuracy: 0.6875\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7141 - val_loss: 0.6046 - val_accuracy: 0.6953\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6844 - val_loss: 0.5817 - val_accuracy: 0.6797\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6562 - val_loss: 0.5832 - val_accuracy: 0.6914\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6703 - val_loss: 0.5764 - val_accuracy: 0.6836\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7109 - val_loss: 0.5790 - val_accuracy: 0.6797\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.6875 - val_loss: 0.5689 - val_accuracy: 0.6953\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6766 - val_loss: 0.5730 - val_accuracy: 0.6914\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6969 - val_loss: 0.5931 - val_accuracy: 0.7070\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6734 - val_loss: 0.5988 - val_accuracy: 0.6992\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7188 - val_loss: 0.6045 - val_accuracy: 0.6758\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6984 - val_loss: 0.5897 - val_accuracy: 0.7148\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7047 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6797 - val_loss: 0.5885 - val_accuracy: 0.7031\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7156 - val_loss: 0.5492 - val_accuracy: 0.7109\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7063 - val_loss: 0.5645 - val_accuracy: 0.6992\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6734 - val_loss: 0.5848 - val_accuracy: 0.6406\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7219 - val_loss: 0.5849 - val_accuracy: 0.6992\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.6969 - val_loss: 0.6119 - val_accuracy: 0.7031\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7047 - val_loss: 0.5628 - val_accuracy: 0.7070\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7125 - val_loss: 0.5535 - val_accuracy: 0.6758\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7219 - val_loss: 0.5662 - val_accuracy: 0.7070\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7172 - val_loss: 0.5516 - val_accuracy: 0.6836\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7094 - val_loss: 0.5395 - val_accuracy: 0.7070\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6906 - val_loss: 0.5575 - val_accuracy: 0.7305\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7266 - val_loss: 0.6621 - val_accuracy: 0.6328\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7125 - val_loss: 0.6017 - val_accuracy: 0.7031\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7000 - val_loss: 0.5953 - val_accuracy: 0.6758\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7297 - val_loss: 0.5340 - val_accuracy: 0.7305\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7219 - val_loss: 0.5412 - val_accuracy: 0.7148\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7203 - val_loss: 0.5479 - val_accuracy: 0.7070\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7188 - val_loss: 0.6236 - val_accuracy: 0.7031\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7203 - val_loss: 0.5329 - val_accuracy: 0.7070\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7359 - val_loss: 0.5264 - val_accuracy: 0.7383\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.6984 - val_loss: 0.5336 - val_accuracy: 0.6836\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7406 - val_loss: 0.5499 - val_accuracy: 0.7070\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7516 - val_loss: 0.5238 - val_accuracy: 0.7148\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7031 - val_loss: 0.5251 - val_accuracy: 0.7422\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7266 - val_loss: 0.5451 - val_accuracy: 0.6992\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.6875 - val_loss: 0.5316 - val_accuracy: 0.7422\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7219 - val_loss: 0.5681 - val_accuracy: 0.7188\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7234 - val_loss: 0.9020 - val_accuracy: 0.4141\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7312 - val_loss: 0.6384 - val_accuracy: 0.6562\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7266 - val_loss: 0.5473 - val_accuracy: 0.7266\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7437 - val_loss: 0.5213 - val_accuracy: 0.7383\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7391 - val_loss: 0.5233 - val_accuracy: 0.7461\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7344 - val_loss: 0.5437 - val_accuracy: 0.7148\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7344 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7547 - val_loss: 0.5388 - val_accuracy: 0.7031\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7141 - val_loss: 0.5436 - val_accuracy: 0.7461\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7578 - val_loss: 0.5128 - val_accuracy: 0.7383\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7375 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7422 - val_loss: 0.5285 - val_accuracy: 0.7266\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7531 - val_loss: 0.6100 - val_accuracy: 0.6953\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7406 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7563 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7234 - val_loss: 0.5186 - val_accuracy: 0.7422\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7375 - val_loss: 0.5268 - val_accuracy: 0.7344\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7516 - val_loss: 0.5203 - val_accuracy: 0.7461\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7437 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7391 - val_loss: 0.5202 - val_accuracy: 0.7422\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7328 - val_loss: 0.5146 - val_accuracy: 0.7305\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7375 - val_loss: 0.5579 - val_accuracy: 0.7109\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7531 - val_loss: 0.5566 - val_accuracy: 0.7227\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7203 - val_loss: 0.5049 - val_accuracy: 0.7461\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7375 - val_loss: 0.5273 - val_accuracy: 0.7266\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7531 - val_loss: 0.5680 - val_accuracy: 0.7188\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7156 - val_loss: 0.5123 - val_accuracy: 0.7461\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7516 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7672 - val_loss: 0.5109 - val_accuracy: 0.7461\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7547 - val_loss: 0.5019 - val_accuracy: 0.7383\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7531 - val_loss: 0.5064 - val_accuracy: 0.7266\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7688 - val_loss: 0.5630 - val_accuracy: 0.7148\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7422 - val_loss: 0.5828 - val_accuracy: 0.7109\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7406 - val_loss: 0.5065 - val_accuracy: 0.7578\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7578 - val_loss: 0.4997 - val_accuracy: 0.7734\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7078 - val_loss: 0.5668 - val_accuracy: 0.7031\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7703 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7656 - val_loss: 0.5697 - val_accuracy: 0.7109\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7734 - val_loss: 0.5227 - val_accuracy: 0.7305\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7781 - val_loss: 0.5112 - val_accuracy: 0.7422\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7344 - val_loss: 0.5124 - val_accuracy: 0.7461\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7641 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7469 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7437 - val_loss: 0.5197 - val_accuracy: 0.7227\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7609 - val_loss: 0.6014 - val_accuracy: 0.6406\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7563 - val_loss: 0.5064 - val_accuracy: 0.7383\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7391 - val_loss: 0.5012 - val_accuracy: 0.7734\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7469 - val_loss: 0.6020 - val_accuracy: 0.7109\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7391 - val_loss: 0.4978 - val_accuracy: 0.7773\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7403 - val_loss: 0.5340 - val_accuracy: 0.7344\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - 0s 0s/step - loss: 0.5381 - accuracy: 0.7403 - val_loss: 0.5340 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "train_dataset=make_dataset(train_df,y_train,epochs=100)\n",
    "eval_dataset=make_dataset(eval_df,y_eval,epochs=1,shuffle=False)\n",
    "history=model.fit(train_dataset,\n",
    "                  validation_data=eval_dataset,\n",
    "                  steps_per_epoch=20,\n",
    "                  validation_steps=8,\n",
    "                  epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=keras.estimator.model_to_estimator(model)\n",
    "estimator.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondad9bd0a7157c84fa7bace955ad09d0846"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
