# Kafka笔记



## 一、安装

**1、将kafka的jar包通过FTP工具拉入到 /opt/module/software里面**

**2、解压，之后修改名称为kafka**

```
[xiongyuan@hadoop100 software]$ tar -zxvf kafka_2.11-0.11.0.0.tgz -C /opt/module/
```

```
[xiongyuan@hadoop100 module]$ mv kafka_2.11-0.11.0.0/ kafka
```

**3、在/opt/module/kafka 目录下创建 logs 文件夹**

```
[xiongyuan@hadoop100 kafka]$ mkdir logs
```

**4、修改配置文件**

```
[xiongyuan@hadoop100 kafka]$ cd config/
```

```
[xiongyuan@hadoop100 config]$ vim server.properties
```

输入以下内容：

```
#broker的全局唯一编号，不能重复 
broker.id=0 
#删除topic功能使能 
delete.topic.enable=true 
#处理网络请求的线程数量 
num.network.threads=3 
#用来处理磁盘IO的现成数量 
num.io.threads=8 
#发送套接字的缓冲区大小 
socket.send.buffer.bytes=102400 
#接收套接字的缓冲区大小 
socket.receive.buffer.bytes=102400 
#请求套接字的缓冲区大小 
socket.request.max.bytes=104857600 
#kafka运行日志存放的路径 
log.dirs=/opt/module/kafka/logs 
#topic在当前broker上的分区个数 
num.partitions=1 
#用来恢复和清理data下数据的线程数量 
num.recovery.threads.per.data.dir=1 
#segment文件保留的最长时间，超时将被删除 log.retention.hours=168 
#配置连接Zookeeper集群地址 
zookeeper.connect=192.168.138.100:2181,192.168.138.200:2181,192.168.138.138:2181

```

**5、配置环境变量**

```
[xiongyuan@hadoop100 module]$ sudo vi /etc/profile
```

```
#KAFKA_HOME 
export KAFKA_HOME=/opt/module/kafka export PATH=$PATH:$KAFKA_HOME/bin
```

```
#重新执行profile文件
[xiongyuan@hadoop100 ~]$ source /etc/profile
```

**6、分发kafka到hadoop200/hadoop300中**

```
[xiongyuan@hadoop100 module]$ xsync kafka/
```

**7、分发之后记得配置其他机器的环境变量** 

==分别在 hadoop200 和 hadoop300 上修改配置文件/opt/module/kafka/config/server.properties 中的 broker.id=1、broker.id=2，broker.id 不得重复== 

##  二、启动Kafka

1、**启动kafka之前要先启动zookeeper,必须三台服务器都启动（达到80%以上的启动数量）zookeeper才能启动成功所以需要一共启动三台服务器**

```
#启动zk
[xiongyuan@hadoop100 zookeeper-3.4.10]$ bin/zkServer.sh start
```

```
#停止zk
[xiongyuan@hadoop100 zookeeper-3.4.10]$ bin/zkServer.sh stop
```

```
#重启zk
[xiongyuan@hadoop100 zookeeper-3.4.10]$ bin/zkServer.sh restart
```

```
#查看zk状态
[xiongyuan@hadoop100 zookeeper-3.4.10]$ bin/zkServer.sh status
```

2、**然后再启动kafka**

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties
```

![image-20210102221157080](C:\Users\xiongyuan\AppData\Roaming\Typora\typora-user-images\image-20210102221157080.png)

3、**其他几台集群也要开启kafka**

```
[xiongyuan@hadoop200 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties

[xiongyuan@hadoop200 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties
```

## 三、命令行操作

**1、创建topic**

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-topics.sh --create --topic first --partitions 3 --replication-factor 2 --zookeeper hadoop100:2181
```

--create : 创建

--zookeeper:用zookeeper保存数据

--hadoop100:2181：服务器名称

--topic first:本次新创建的topic名称

--partitions:分区数量

--replication-factor：副本数量

**2、查询topic**

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-topics.sh --list --zookeeper hadoop100:2181
```

**3、查看topic的详情**

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-topics.sh --describe --topic first --zookeeper hadoop100:2181
```

--topic first：是topic的名称

**4、删除topic**

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-topics.sh --delete --topic first --zookeeper hadoop100:2181
```

**5、发送消息**

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-console-producer.sh --topic first --broker-list hadoop100:9092
```

**6、接收消息**

可以打开另外一台hadoop200服务器，在里面输入以下代码，这样hadoop100里面发送的内容就可以在hadoop200里面接收到

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-console-consumer.sh --topic first --bootstrap-server hadoop100:9092
```

**7、当消费者不在线时接受消息**

多了一个--from-beginning参数

```
[xiongyuan@hadoop100 kafka]$ bin/kafka-console-consumer.sh --topic first --bootstrap-server hadoop100:9092 --from-beginning
```

